function populate_articles_Jcdl(){
	var articles_data = {"08_p001": {"abstract": " This work shows how the content of a digital library can be enhanced to better satisfy its users＊ needs. Missing content is identified by findingmissing content topics in the system＊s query log or in a pre-defined taxonomy of required knowl- edge. The collection is then enhanced with new relevant knowledge, which is extracted from external sources that satisfy those missing content topics. Experiments we con- ducted measure the precision of the system before and after content enhancement. The results demonstrate a significant improvement in the system effectiveness as a result of con- tent enhancement and the superiority of the missing content enhancement policy over several other possible policies. ", "authors": "David Carmel, Elad Yom-Tov, Haggai Roitman IBM Haifa Research Lab University Campus Haifa 31905 Israel {carmel,yomtov,haggai}@il.ibm.com ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms ", "id": "08_p001", "keywords": " Content analysis, Query difficulty, crawling policy ", "title": "Enhancing Digital Libraries Using Missing Content Analysis\n"}, "08_p011": {"abstract": " We describe here in detail our work toward creating a dy- namic lexicon from the texts in a large digital library. By leveraging a small structured knowledge source (a 30,457 word treebank), we are able to extract selectional prefer- ences for words from a 3.5 million word Latin corpus. This is promising news for low-resource languages and digital col- lections seeking to leverage a small human investment into much larger gain. The library architecture in which this work is developed allows us to query customized subcorpora to report on lexical usage by author, genre or era and allows us to continually update the lexicon as new texts are added to the collection. ", "authors": "David Bamman The Perseus Project Tufts University Medford, MA david.bamman@tufts.edu Gregory Crane The Perseus Project Tufts University Medford, MA gregory.crane@tufts.edu ", "categories": " H.3.7 [Information Systems: Information Storage and Retrieval]: digital libraries General Terms Design, Documentation, Performance ", "id": "08_p011", "keywords": " Lexicography, syntactic parsing, digital libraries ", "title": "Building a Dynamic Lexicon from a Digital Library\n"}, "08_p021": {"abstract": " We propose and evaluate a ※content-driven search keyword suggester§ for keyword-based search in literature digital libraries. Suggesting search keywords at an early stage, i.e., while the user is entering search terms, is helpful for constructing more accurate, less ambiguous, and focused search keywords for queries. Our search keyword suggestion approach is based on an a priori analysis of the publication collection in the digital library at hand, and consists of the following steps. We (i) parse the document collection using the Link Grammar parser, a syntactic parser of English, (ii) group publications based on their ※most-specific§ research topics, (iii) use the parser output to build a hierarchical structure of simple and compound tokens to be used to suggest search terms, (iv) use TextRank, a text summarization tool, to assign topic-sensitive scores to keywords, and (v) use the identified research-topics to help user aggregate search keywords prior to the actual search query execution. We experimentally show that the proposed framework, which is optimized to work on literature digital libraries, promises a more scalable, high quality, and user-friendly search-keyword suggester when compared to its competitors. We validate our proposal experimentally using a subset of the ACM SIGMOD Anthology digital library as a testbed, and by employing the research- pyramid model to identify the ※most-specific§ research topics. ", "authors": "Sulieman Bani-Ahmad EECS Department Case Western Reserve University, Cleveland, Ohio 44106, USA +1 (216) 368.2802 sulieman@case.edu  Gultekin Ozsoyoglu EECS Department Case Western Reserve University, Cleveland, Ohio 44106, USA +1 (216) 368.2802 tekin@case.edu   ", "categories": " H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval; H.3.7 Digital Libraries. General Terms Performance, Experimentation ", "id": "08_p021", "keywords": " Search-Keyword Suggester, Literature Digital Libraries. ", "title": "On Content-Driven Search-Keyword Suggesters for Literature Digital Libraries \n"}, "08_p025": {"abstract": " This paper reports the further development of machine learning techniques for semantic markup of biodiversity literature, especially morphological descriptions of living organisms such as those hosted at efloras.org and algaebase.org. Syntactic parsing and supervised machine learning techniques have been explored by earlier research. Limitations of these techniques promoted our investigation of an unsupervised learning approach that combines the strength of earlier techniques and avoids the limitations. Semantic markup at the organ and character levels is discussed. Research on semantic markup of natural heritage literature has direct impact on the development of semantic-based access in biodiversity digital libraries.  ", "authors": "Hong Cui School of Information Resources and Library Science, University of Arizona.  hongcui@email.arizona.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 collection, systems issues.  General Terms Algorithms, Design, Performance, Experimentation ", "id": "08_p025", "keywords": " Semantic markup, Semantic annotation, natural heritage literature, morphological description, biodiversity informatics, unsupervised machine learning, XML, tagging ", "title": "Unsupervised Semantic Markup of Literature for Biodiversity Digital Libraries \n"}, "08_p029": {"abstract": " There are opposing views on whether readers gain any advantage from using a computer model of a 3D physical book. There is enough evidence, both anecdotal and from formal user studies, to suggest that the usual HTML or PDF presentation of documents is not always the most convenient, or the most comfortable, for the reader. On the other hand it is quite clear that while 3D book models have been prototyped and demonstrated, none are in routine use in today＊s digital libraries. And how do 3D book models compare with actual books? This paper reports on a user study designed to compare the performance of a practical Realistic Book implementation with conventional formats (HTML and PDF) and with physical books. It also evaluates the annotation features that the implementation provides. ", "authors": "Veronica Liesaputra and Ian H. Witten Department of Computer Science University of Waikato Hamilton, New Zealand +64 7 838 4246 {vl6, ihw}@cs.waikato.ac.nz ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries User issues; H.5.2 [Information Interfaces and Presentation]: User interfaces Evaluation/methodology, graphical user interfaces, interaction style General Terms Design, Experimentation, Human Factors, Performance. ", "id": "08_p029", "keywords": " Electronic book, Flash application. ", "title": "Seeking Information in Realistic Books: A user study\n"}, "08_p039": {"abstract": " We report on our user study on the information seeking behavior of cultural heritage experts and the sources they use to carry out search tasks. Seventeen experts from nine cultural heritage institutes in the Netherlands were interviewed and asked to answer questionnaires about their daily search activities. The interviews helped us to bet- ter understand their search motivations, types, sources and tools. A key finding of our study is that the majority of search tasks involve relatively complex information gathering. This is in contrast to the relatively simple fact-finding oriented support provided by current tools. We describe a number of strategies that experts have devel- oped to overcome the inadequacies of their tools. Finally, based on the analysis, we derive general trends of cultural heritage experts＊ information seeking needs and discuss our preliminary experiences with potential solutions. ", "authors": "Alia Amin, Jacco van Ossenbruggen, Lynda Hardman ? CWI P.O. Box 94079 1090 GB Amsterdam The Netherlands firstname.lastname@cwi.nl Annelies van Nispen Digitaal Erfgoed Nederland (DEN) P.O. Box 90407 2509 LK Den Haag The Netherlands annelies.vannispen@den.nl ", "categories": " H.3.3 [Information Search and Retrieval] General Terms Human Factors ", "id": "08_p039", "keywords": " cultural heritage experts, information seeking ", "title": "Understanding Cultural Heritage Experts＊ Information Seeking Needs\n"}, "08_p048": {"abstract": " The ubiquitous within-document text search feature (Ctrl- F ) is considered by users to be a key advantage in electronic information seeking [1]. However what people say they do and what they actually do are not always consistent. It is necessary to understand, acknowledge and identify the cause of this inconsistency. We must identify the physical and cog- nitive factors to develop better methods and tools, assisting with the search process. This paper discusses the limitations and myths of Ctrl-f in information seeking. A prototype sys- tem for within-document search is introduced. Three user studies portray shared behaviour and attitudes, common be- tween participants regarding within-document searching. ", "authors": "Fernando Loizides Future Interaction Technologies Lab Computer Science Department Swansea University csfernando@swan.ac.uk George Buchanan Future Interaction Technologies Lab Computer Science Department Swansea University g.r.buchanan@swan.ac.uk ", "categories": " H.0 [Information Systems]: General; H.m [Information Systems]: Miscellaneous General Terms Experimentation, Human Factors ", "id": "08_p048", "keywords": " Information Triage, Digital Libraries, Information Seeking, Within-Document Searching ", "title": "The Myth of Find: User Behaviour and Attitudes Towards the Basic Search Feature\n"}, "08_p052": {"abstract": " Digital libraries are concerned with improving the access to collections to make their service more effective and valuable to users. In this paper, we present the results of a four-week longitudinal study investigating the use of both exploratory and keyword forms of search within an online video archive, where both forms of search were available concurrently in a single user interface. While we expected early use to be more exploratory and subsequent use to be directed, over the whole period there was a balance of exploratory and keyword searches and they were often used together. Further, to support the notion that facets support exploration, there were more than five times as many facet clicks than more complex forms of keyword search (boolean and advanced). From these results, we can conclude that there is real value in investing in exploratory search support, which was shown to be both popular and useful for extended use of the system. ", "authors": "Max L. Wilson, mc schraefel School of Electronics and Computer Science University of Southampton, UK {mlw05r, mc}@ecs.soton.ac.uk  ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering, Query formulation, Search Process. H.3.7 [Digital Libraries] User issues. H.5.2 [User Interfaces]: Evaluation/methodology, Interaction Styles.  General Terms Measurement, Design, Human Factors, Verification. ", "id": "08_p052", "keywords": " Faceted, Search, Keyword, mSpace, Browsing, Longitudinal, User, Study. ", "title": "A Longitudinal Study of Exploratory and Keyword Search \n"}, "08_p057": {"abstract": " The growing availability of online K-12 curriculum is increasing the need for meaningful alignment of this curriculum with state-specific standards. Promising automated and semi-automated alignment tools have recently become available. Unfortunately, recent alignment evaluation studies report low inter-rater reliability, e.g., 32% with two raters and 35 documents. While these results are in line with studies in other domains, low reliability makes it difficult to accurately train automatic systems and complicates comparison of different services. We propose that inter-rater reliability of broadly defined, abstract concepts such as ＆alignment＊ or ＆relevance＊ must be expected to be low due to the real-world complexity of teaching and the multidimensional nature of the curricular documents. Hence, we suggest decomposing these concepts into less abstract, more precise measures anchored in the daily practice of teaching. This article reports on the integration of automatic alignment results into the interface of the TeachEngineering collection and on an evaluation methodology intended to produce more consistent document relevance ratings. Our results (based on 14 raters x 6 documents) show high inter-rater reliability (61 - 95%) on less abstract relevance dimensions while scores on the overall ＆relevance＊ concept are (as expected) lower (64%). Despite a relatively small sample size, regression analysis of our data resulted in an explanatory (R2 = .75) and statistically stable (p-values < .05) model for overall relevance as indicated by matching concepts, related background material, adaptability to grade level, and anticipated usefulness of exercises. Our results suggest that more detailed relevance evaluation which includes several dimensions of relevance would produce better data for comparing and training alignment tools. ", "authors": " Ren谷 Reitsma College of Business Oregon State University Corvallis, OR reitsmar@bus.oregegonstate.edu Byron Marshall College of Business Oregon State University Corvallis, O OR byron.marshall@bus.oregegonstate.edu  Michael Dalton College of Education Oregon State University Corvallis, OR michael.dalton@oregonstate.edu Martha Cyr K-12 Outreach Worcester Pol. Institute Worcester, MA mcyr@wpi.edu ", "categories": " K.3.1 [Computer Uses in Education]  General Terms: Measurement, Design, Reliability, Experimentation, Human Factors, Theory. ", "id": "08_p057", "keywords": ": Curriculum-standard alignment, Inter-rater reliability, Relevance, Digital library, Social science theory, Reification, Context-specific measurement.  ", "title": "Exploring Educational Standard Alignment: In Search of ＆Relevance＊ \n"}, "08_p066": {"abstract": " NSDL is a premier provider of digital educational collections and services, which has been supported by NSF for eight years. As a mature program, NSDL has reached a point where it could either change direction or wind down.  In this paper we argue there are reasons to continue the program and we outline several possible new program directions. These build on NSDL＊s learning platform, and they also look towards NSF＊s emerging interest in supporting work at the intersection of cyberinfrastructure and education. We consider NSDL＊s potential roles in several grand challenges that confront education, including: tailoring educational resources to students＊ needs, providing educators with a cyber-teaching environment, developing a cyber-workbench for researchers, and integrating education research and practice. ", "authors": "     David J. McArthur GoH LLC 4201 Wilson Blvd.  Arlington, VA 22230 1 919 601 5836      dmcarthur1@nc.rr.com          Lee L. Zia NSF 4201 Wilson Blvd.  Arlington, VA 22230 1 702 292 5140 lzia@nsf.gov  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 standards, system issues, user issues. General Terms Design, Experimentation, Performance, Standardization, Theory. ", "id": "08_p066", "keywords": " Cyberinfrastructure, Digital Libraries, Education, Learning, Teaching. ", "title": "From NSDL 1.0 to NSDL 2.0: Towards a Comprehensive Cyberinfrastructure for Teaching and Learning\n"}, "08_p070": {"abstract": " This paper discusses a digital library designed to help undergraduate students draw connections across disciplines, beginning with introductory discipline-specific science courses (including chemistry, materials science, and biophysics). The collection serves as the basis for a design experiment for interdisciplinary educational libraries and is discussed in terms of the three models proposed by Sumner and Marlino. As a cognitive tool, the library is organized around recurring patterns in molecular science, with one such pattern being developed for this initial design experiment. As a component repository, the library resources support learning of these patterns and how they appear in different disciplines. As a knowledge network, the library integrates design with use and assessment. ", "authors": "D. J. Yaron, J. L. Davenport,   M. Karabinos, G. L Leinhardt Department of Chemistry;  Pittsburgh Science of Learning Center Carnegie Mellon University Pittsburgh, PA 15213 1-412-268-1351 {yaron, jdavenport, mk7} @cmu.edu; gaea+@pitt.edu L. M. Bartolo, J. J. Portman, C. S. Lowe Center for Materials Informatics;  Department of Physics Kent State University Kent, OH 44242 1-330-672-1691 {lbartolo, jportman, clowe}@kent.edu D. R. Sadoway, W. C. Carter,  C. Ashe Department of Materials Science  & Engineering Massachusetts Institute of Technology  Cambridge, MA 02139 USA +1.617.253.3487 {dsadoway, ccarter, cashe}   @mit.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 collection, dissemination, user issues; J.2 [Physical Sciences and Engineering]: Chemistry, Engineering, Physics; J.3 [Life and Medical Sciences] Biology and genetics. General Terms Measurement, Experimentation, Human Factors. ", "id": "08_p070", "keywords": " Evaluation, Digital Library, Introductory Science courses. ", "title": "Cross-Disciplinary Molecular Science Education in Introductory Science Courses: An NSDL MatDL Collection\n"}, "08_p074": {"abstract": " This paper describes the design and implementation of a curriculum overlay model for the representation of adaptable curriculum using educational digital library resources. We focus on representing curriculum to enable the incorporation of digital resources into curriculum and curriculum sharing and customization by educators. We defined this model as a result of longitudinal studies on educators＊ development and customization of curriculum and user interface design studies of prototypes representing curriculum. Like overlay journals or the information network overlay model, our curriculum overlay model defines curriculum as a compound object with internal semantic relationships and relationships to digital library metadata describing resources. We validated this model by instantiating the model using science curriculum which uses digital library resources and using this instantiation within an application that, built on FEDORA, supports curriculum customization. Findings from this work can support the design of digital library services for customizing curriculum which embeds digital resources.  ", "authors": "Huda Khan, Keith Maull, Tamara Sumner Institute of Cognitive Science Department of Computer Science University of Colorado at Boulder, Boulder, CO 80309 huda.khan, keith.maull, tamara.sumner@colorado.edu ", "categories": " H.1.2 [Models and Principles]: User/Machine Systems; H3.7 [Information Storage and Retrieval]: Digital Libraries 每 User issues; K.3.1. [Computers and Education]: Computer Users in Education 每 Computer-assisted instruction. General Terms: Design, Human Factors. ", "id": "08_p074", "keywords": " Personalization, digital libraries, curriculum, FEDORA, content models, lessons, Teaching Boxes. ", "title": "Curriculum Overlay Model for Embedding Digital Resources \n"}, "08_p085": {"abstract": " Geolocalized databases are becoming necessary in a wide variety of application domains. Thus far, the creation of such databases has been a costly, manual process. This drawback has stimulated interest in automating their construction, for example, by mining geographical information from the Web. Here we present and evaluate a new automated technique for creating and enriching a geographical gazetteer, called Gazetiki. Our technique merges disparate information from Wikipedia, Panoramio, and web search engines in order to identify geographical names, categorize these names, find their geographical coordinates and rank them. The information produced in Gazetiki enhances and complements the Geonames database, using a similar domain model. We show that our method provides a richer structure and an improved coverage compared to another known attempt at automatically building a geographic database and, where possible, we compare our Gazetiki to Geonames.  ", "authors": "Adrian Popescu CEA LIST 18 Route du Panorama 92260 Fontenay aux Roses, France +33146548013 adrian.popescu@cea.fr Gregory Grefenstette CEA LIST 18 Route du Panorama 92260 Fontenay aux Roses, France +33146549617 gregory.grefenstette@cea.fr  Pierre-Alain Mo?llic CEA LIST 18 Route du Panorama 92260 Fontenay aux Roses, France +33146549617 pierre-alain.moellic@cea.fr   ", "categories": " H.3.1 Content Analysis and Indexing General Terms Algorithms, Experimentation. ", "id": "08_p085", "keywords": " Geographic gazetteer, thesaurus, information extraction, data mining, Wikipedia, Panoramio. ", "title": "Gazetiki: Automatic Creation of a Geographical Gazetteer \n"}, "08_p094": {"abstract": " In this paper, we consider the problem of discovering GIS data sources on the web. Source discovery queries for GIS data are specified using keywords and a region of interest. A source is considered relevant if it contains data that matches the keywords in the specified region. Existing techniques simply rely on textual metadata accompanying such datasets to compute relevance to user-queries. Such approaches re- sult in poor search results, often missing the most relevant sources on the web. We address this problem by developing more meaningful summaries of GIS datasets that preserve the spatial distribution of keywords. We conduct experi- ments showing the effectiveness of proposed summarization techniques by significantly improving the quality of query results over baseline approaches, while guaranteeing scala- bility and high performance. ", "authors": "Ramaswamy Hariharan, Bijit Hore, and Sharad Mehrotra Donald Bren School of Information and Computer Sciences University of California, Irvine Irvine, CA 92697 {rharihar,bhore,sharad}@ics.uci.edu ", "categories": " H.3 [Information Storage and Retrieval]: General General Terms Algorithms, Performance ", "id": "08_p094", "keywords": " GIS, histograms, search engine, index structures, query process- ing ", "title": "Discovering GIS Sources on the Web using Summaries\n"}, "08_p104": {"abstract": " Web 2.0 promises rich opportunities for information sharing, electronic commerce, and new modes of social interaction, all centered around the※social Web§of user-contributed con- tent, social annotations, and person-to-person social connec- tions. But the increasing reliance on this ※social Web§ also places individuals and their computer systems at risk, cre- ating opportunities for malicious participants to exploit the tight social fabric of these networks. With these problems in mind, we propose the SocialTrust framework for tamper- resilient trust establishment in online communities. Social- Trust provides community users with dynamic trust values by (i) distinguishing relationship quality from trust; (ii) in- corporating a personalized feedback mechanism for adapting as the community evolves; and (iii) tracking user behavior. We experimentally evaluate the SocialTrust framework using real online social networking data consisting of mil- lions of MySpace profiles and relationships. We find that So- cialTrust supports robust trust establishment even in the presence of large-scale collusion by malicious participants. ", "authors": "James Caverlee Dep＊t of Computer Science Texas A&M University College Station, TX 77843 caverlee@cs.tamu.edu Ling Liu College of Computing Georgia Tech Atlanta, GA 30332 lingliu@cc.gatech.edu Steve Webb College of Computing Georgia Tech Atlanta, GA 30332 webb@cc.gatech.edu ", "categories": ": H.3.5 Information Storage and Retrieval: Online Information Services General Terms: Algorithms, Experimentation ", "id": "08_p104", "keywords": "", "title": "SocialTrust: Tamper-Resilient Trust Establishment in Online Communities\n"}, "08_p115": {"abstract": " Digital objects require appropriate measures for digital preser- vation to ensure that they can be accessed and used in the near and far future. While heritage institutions have been addressing the challenges posed by digital preservation needs for some time, private users and SOHOs (Small Office/Home Office) are less prepared to handle these challenges. Yet, both have increasing amounts of data that represent consid- erable value, be it office documents or family photographs. Backup, common practice of home users, avoids the phys- ical loss of data, but it does not prevent the loss of the ability to render and use the data in the long term. Re- search and development in the area of digital preservation is driven by memory institutions and large businesses. The available tools, services and models are developed to meet the demands of these professional settings. This paper analyses the requirements and challenges of preservation solutions for private users and SOHOs. Based on the requirements and supported by available tools and services, we are designing and implementing a home archiv- ing system to provide digital preservation solutions specifi- cally for digital holdings in the small office and home envi- ronment. It hides the technical complexity of digital preser- vation challenges and provides simple and automated ser- vices based on established best practice examples. The sys- tem combines bitstream preservation and logical preserva- tion strategies to avoid loss of data and the ability to access and use them. A first software prototype, called Hoppla, is presented in this paper. ", "authors": "Stephan Strodl, Florian Motlik, Kevin Stadler, Andreas Rauber Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/dp ", "categories": " H.3 [Information Storage and Retrieval]: H.3.7 Digital Libraries General Terms Design, Documentation, Experimentation, Reliability, The- ory ", "id": "08_p115", "keywords": " Personal Archiving, Home Archiving, Home User, SOHO, Digital Preservation, Long Term Access ", "title": "Personal & SOHO Archiving\n"}, "08_p124": {"abstract": " Our previous research has shown that the collective behavior of search engine caches (e.g., Google, Yahoo, Live Search) and web archives (e.g., Internet Archive) results in the un- coordinated but large-scale refreshing and migrating of web resources. Interacting with these caches and archives, which we call the Web Infrastructure (WI), allows entire websites to be reconstructed in an approach we call lazy preservation. Unfortunately, the WI only captures the client-side view of a web resource. While this may be useful for recovering much of the content of a website, it is not helpful for restoring the scripts, web server configuration, databases, and other server-side components responsible for the construction of the website＊s resources. This paper proposes a novel technique for storing and re- covering the server-side components of a website from the WI. Using erasure codes to embed the server-side compo- nents as HTML comments throughout the website, we can effectively reconstruct all the server components of a web- site when only a portion of the client-side resources have been extracted from the WI. We present the results of a preliminary study that baselines the lazy preservation of ten EPrints repositories and then examines the preservation of an EPrints repository that uses the erasure code technique to store the server-side EPrints software throughout the web- site. We found nearly 100% of the EPrints components were recoverable from the WI just two weeks after the repository came online, and it remained recoverable four months after it was ※lost§. ", "authors": "Frank McCown Harding University Computer Science Department Searcy, Arkansas, USA 72149 fmccown@harding.edu Michael L. Nelson Old Dominion University Computer Science Department Norfolk, Virginia, USA 23529 mln@cs.odu.edu ", "categories": ": H.3.5 [Informa- tion Storage and Retrieval] Online Information Services: Web- based services; H.3.7 [Information Storage and Retrieval] Digital Libraries: Collection General Terms: Design, Experimentation, Measurement ", "id": "08_p124", "keywords": ": backup, digital preservation, search engine caches, web archiving, web server ", "title": "Recovering a Website＊s Server Components from the Web Infrastructure\n"}, "08_p134": {"abstract": " The National Geospatial Digital Archive, one of eight initial projects funded under the Library of Congress＊s NDIIPP program, has been researching how geospatial data can be preserved on a national scale and be made available to future generations. In this paper we describe an archive architecture that provides a minimal approach to the long-term preservation of digital objects based on co-archiving of object semantics, uniform representation of objects and semantics, explicit storage of all objects and semantics as files, and abstraction of the underlying storage system. This architecture ensures that digital objects can be easily migrated from archive to archive over time and that the objects can, in principle, be made usable again at any point in the future; its primary benefit is that it serves as a fallback strategy against, and as a foundation for, more sophisticated (and costly) preservation strategies. We describe an implementation of this architecture in a protoype archive running at UCSB that also incorporates a suite of ingest and access components. ", "authors": "Greg Jan谷e Map & Imagery Laboratory University of California, Santa Barbara +1 (805) 893-8453 gjanee@alexandria.ucsb.edu Justin Mathena Map & Imagery Laboratory University of California, Santa Barbara +1 (805) 893-5452 mathena@library.ucsb.edu James Frew Donald Bren School of Environmental Science and Management University of California, Santa Barbara +1 (805) 893-7356 frew@bren.ucsb.edu   ", "categories": " H.3.7 [Digital Libraries]: Systems issues; E.2 [Data Storage Representations]: Object representation. General Terms Design, Standardization. ", "id": "08_p134", "keywords": " long-term preservation; curation ", "title": "A Data Model and Architecture for Long-term Preservation\n"}, "08_p145": {"abstract": " Data visualization has historically been accessible only to the elite in academia, business, and government. It is ※serious§ technology done by experts for experts. But in recent years web-based visualizations〞ranging from political art projects to news stories〞have reached audiences of millions. Unfortunately, while lay users can view many sophisticated visualizations, they have few ways to create them. In order to ※democratize§ visualization and data analysis, we have built Many Eyes, a web site where people may upload their own data, create interactive visualizations, and carry on conversations. By making these tools available to anyone on the web, the site fosters a social style of data analysis that empowers users to engage with public data through discussion and collaboration. Political discussions, citizen activism, religious conversations, game playing, and educational exchanges are all happening on Many Eyes. As we will discuss in this talk, the public nature of these visualizations provide users with a transformative path to information literacy. ", "authors": "Fernanda Vi谷gas IBM Research Cambridge, MA, USA viegasf@us.ibm.com  Martin Wattenberg IBM Research Cambridge, MA, USA mwatten@us.ibm.com ", "categories": ": Information Systems, Information Storage and Retrieval, Online Information Services, Web-based services General Terms: Algorithms, Design, Experimentation, Human Factors. ", "id": "08_p145", "keywords": "", "title": "Shakespeare, God, and Lonely Hearts: Transforming Data Access with Many Eyes \n"}, "08_p147": {"abstract": " Collaborative, social tagging and annotation systems have exploded on the Internet as part of the Web 2.0 phenomenon. Systems such as Flickr, Del.icio.us, Technorati, Connotea and LibraryThing, provide a community-driven approach to classifying information and resources on the Web, so that they can be browsed, discovered and re-used. Although social tagging sites provide simple, user-relevant tags, there are issues associated with the quality of the metadata and the scalability compared with conventional indexing systems. In this paper we propose a hybrid approach that enables authoritative metadata generated by traditional cataloguing methods to be merged with community annotations and tags. The HarvANA (Harvesting and Aggregating Networked Annotations) system uses a standardized but extensible RDF model for representing the annotations/tags and OAI-PMH to harvest the annotations/tags from distributed community servers. The harvested annotations are aggregated with the authoritative metadata in a centralized metadata store. This streamlined, interoperable, scalable approach enables libraries, archives and repositories to leverage community enthusiasm for tagging and annotation, augment their metadata and enhance their discovery services. This paper describes the HarvANA system and its evaluation through a collaborative testbed with the National Library of Australia using architectural images from PictureAustralia. ", "authors": "Jane Hunter, Imran Khan, Anna Gerber University of Queensland St Lucia, Queensland, Australia (617) 33654311 {jane, imrank, agerber}@itee.uq.edu.au   ", "categories": " H.3.5 [Online Information services]: Web-based services H 3.1 [Content Analysis and Indexing]: Indexing methods H 3.7 [Digital Libraries]: Dissemination, User issues General Terms Performance, Design, Standardization ", "id": "08_p147", "keywords": " Social Tagging, Annotation, Harvesting, Metadata, Digital Collections, Ontology, Folksonomy ", "title": "HarvANA 每 Harvesting Community Tags to Enrich Collection Metadata \n"}, "08_p157": {"abstract": " In this paper we present a system called paperBase that aids users in entering metadata for preprints. PaperBase extracts metadata from the preprint. Using a Dublin-Core based REST API, third-party repository software populates a web form that the user can then proofread and complete. Paper- Base also predicts likely keywords for the preprints, based on a controlled vocabulary of keywords that the archive uses and a Bayesian classifier. We have tested the system on 12 individuals, and mea- sured the time that it took them to enter data, and the accuracy of the entered metadata. We find that our sys- tem appears to be faster than manual entry, but a larger sample needs to be tested before it can be deemed statisti- cally significant. All but two participants perceived it to be faster. Some metadata, in particular the title of preprints, contains significantly fewer mistakes when entered automat- ically; even though the automatic system is not perfect, people tend to correct mistakes that paperBase makes, but would leave their own mistakes in place. ", "authors": "Emma Tonkin UKOLN University of Bath, UK tonkin@cs.bris.ac.uk Henk L. Muller Department of Computer Science University of Bristol henkm@cs.bris.ac.uk ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing〞Abstracting methods; I.7.3 [Document and Text Processing]: Index Generation General Terms Human Factors ", "id": "08_p157", "keywords": " Metadata, Preprints Archives, Keyword Extraction ", "title": "Semi Automated Metadata Extraction for Preprints Archives\n"}, "08_p167": {"abstract": " Large scale digitization projects have been conducted at digital libraries to preserve cultural artifacts and to provide permanent access. The increasing amount of digitized resources, including scanned books and scientific publications, requires development of tools and methods that will efficiently analyze and manage large collections of digitized resources. In this work, we tackle the problem of extracting metadata from scanned volumes of journals. Our goal is to extract information describing internal structures and content of scanned volumes, which is necessary for providing effective content access functionalities to digital library users. We propose methods for automatically generating volume level, issue level, and article level metadata based on format and text features extracted from OCRed text. We show the performance of our system on scanned bound historical documents nearly two centuries old. We have developed the system and integrated it into an operational digital library, the Internet Archive, for real- world usage. ", "authors": "Xiaonan Lu1, Brewster Kahle2, James Z. Wang1?, and C. Lee Giles1 1The Pennsylvania State University, University Park, PA 2Internet Archive, San Francisco, CA xlu@cse.psu.edu, brewster@archive.org, jwang@ist.psu.edu, giles@ist.psu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries〞Collection, Systems issues; H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing General Terms Algorithms, Design, Experimentation ", "id": "08_p167", "keywords": " Metadata Generation, Scanned Journal ?J. Wang is also affiliated with Carnegie Mellon University, Pittsburgh, Pennsylvania. ", "title": "A Metadata Generation System for Scanned Scientific Volumes\n"}, "08_p177": {"abstract": " Key Ideas is a technique for exploring digital libraries by navigating passages that repeat across multiple books. From these popular passages emerge quotations that authors have copied from book to book because they capture an idea particularly well: Jefferson on liberty; Stanton on women＊s rights; and Gibson on cyberpunk. We augment Popular Pas- sages by extracting key terms from the surrounding context and computing sets of related key terms. We then create an interaction model where readers fluidly explore the library by viewing popular quotations on a particular key term, and follow links to quotations on related key terms. In this paper we describe our vision and motivation for Key Ideas, present an implementation running over a massive, real-world dig- ital library consisting of over a million scanned books, and describe some of the technical and design challenges. The principal contribution of this paper is the interaction model and prototype system for browsing digital libraries of books using key terms extracted from the aggregate context of pop- ularly quoted passages. ", "authors": "Bill N. Schilit and Okan Kolak Google Research 1600 Amphitheatre Parkway, Mountain View, CA 95054 {schilit,okan}@google.com ", "categories": " H.5.4 [Information Interfaces and Presentation]: Hy- pertext/Hypermedia; J.5 [Arts and Humanities]: Litera- ture; H.4.3 [Information Systems Applications]: Com- munications Applications〞Information browsers General Terms Algorithms, Design, Human Factors ", "id": "08_p177", "keywords": " digital libraries; quotations; humanities research; data min- ing; key phrases; hypertext; great ideas. ", "title": "Exploring a Digital Library through Key Ideas\n"}, "08_p187": {"abstract": " We report on the user requirements study and preliminary imple- mentation phases in creating a digital library that indexes and re- trieves educational materials on math. We first review the current approaches and resources for math retrieval, then report on the in- terviews of a small group of potential users to properly ascertain their needs. While preliminary, the results suggest that meta-search and resource categorization are two basic requirements for a math search engine. In addition, we implement a prototype categoriza- tion system and show that the generic features work well in identi- fying the math contents from the webpage but perform less well at categorizing them. We discuss our long term goals, where we plan to investigate how math expressions and text search may be best integrated. ", "authors": "Jin Zhao Department of Computer Science, School of Computing National University of Singapore Singapore, 117590 zhaojin@comp.nus.edu.sg Min-Yen Kan Department of Computer Science, School of Computing National University of Singapore Singapore, 117590 kanmy@comp.nus.edu.sg Yin Leng Theng Division of Information Studies, Wee Kim Wee School of Communication & Information Nanyang Technological University Singapore, 637718 tyltheng@ntu.edu.sg ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; A.1 [General Literature]: Introductory and Sur- vey; J.2 [Computer Applications]: Physical Science and Engi- neering〞Mathematics and statistics General Terms Algorithm, Performance ", "id": "08_p187", "keywords": " Math Information Retrieval, Web Classification, Niche search en- gines, User requirement analysis, Interaction histories ", "title": "Math Information Retrieval: User Requirements and Prototype Implementation\n"}, "08_p197": {"abstract": " Most information workers query digital libraries many times a day. Yet people have little opportunity to hone their skills in a controlled environment, or compare their performance with others in an objective way. Conversely, although search engine logs record how users evolve queries, they lack crucial information about the user＊s intent. This paper describes an environment for exploratory query expansion that pits users against each other and lets them compete, and practice, in their own time and on their own workstation. The system captures query evolution behavior on predetermined information-seeking tasks. It is publicly available, and the code is open source so that others can set up their own competitive environments. ", "authors": "David N. Milne, David M. Nichols and Ian H. Witten Department of Computer Science University of Waikato Hamilton, New Zealand +64 7 838-4246 {dnk2, dmn, ihw}@cs.waikato.ac.nz  ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - query formulation, search process. General Terms Design, Human Factors. ", "id": "08_p197", "keywords": " Query Expansion, game ", "title": "A Competitive Environment for Exploratory Query Expansion \n"}, "08_p201": {"abstract": " At present very little is known about how people locate and view videos ＆in the wild＊. This study draws a rich picture of everyday video seeking strategies and video information needs, based on an ethnographic study of New Zealand university students. These insights into the participants＊ activities and motivations suggest potentially useful facilities for a video digital library.  ", "authors": "Sally Jo Cunningham Dept of Computer Science Waikato University Hamilton, New Zealand +64 7 838 4402 sallyjo@cs.waikato.ac.nz David M. Nichols Dept of Computer Science Waikato University Hamilton, New Zealand +64 7 838 5130 dmn@cs.waikato.ac.nz  ", "categories": " H.3.7 [Digital Libraries]: User issues; H.1.2 [User/Machine Systems] Human information processing General Terms Design, Human Factors ", "id": "08_p201", "keywords": " Video retrieval, qualitative research, user study. ", "title": "How People Find Videos \n"}, "08_p211": {"abstract": " Digital curators are faced with decisions about what part of the ever-growing, ever-evolving space of digital information to collect and preserve. The recent explosion of web video on sites such as YouTube presents curators with an even greater challenge 每 how to sort through and filter a large amount of information to find, assess and ultimately preserve important, relevant, and interesting video. In this paper, we describe research conducted to help inform digital curation of on-line video. Since May 2007, we have been monitoring the results of 57 queries on YouTube related to the 2008 U.S. presidential election. We report results comparing these data to blogs that point to candidate videos on YouTube and discuss the effects of query-based harvesting as a collection development strategy. ", "authors": "Robert G. Capra, Christopher A. Lee, Gary Marchionini, Terrell Russell, Chirag Shah, Fred Stutzman School of Information and Library Science University of North Carolina at Chapel Hill 100 Manning Hall rcapra3@unc.edu, callee@email.unc.edu, march@ils.unc.edu, unc@terrellrussell.com,chirag@unc.edu, fred@metalab.unc.edu  ", "categories": " H.3.7 Information Storage and Retrieval: Digital Libraries, H5.m. Information Interfaces and Presentation (e.g. HCI): Miscellaneous. General Terms Measurement, Human Factors ", "id": "08_p211", "keywords": " Digital curation, collection management, video, blogs ", "title": "Selection and Context Scoping for Digital Video Collections: An Investigation of YouTube and Blogs \n"}, "08_p221": {"abstract": " Awareness of another's activity is an important aspect of facilitating collaboration between users, enabling an ※understanding of the activities of others§ [1]. Techniques such as collaborative filtering enable a form of asynchronous awareness, providing recommendations generated from the past activity of a community of users. In this paper we investigate the role of awareness and its effect on search behavior in collaborative multimedia retrieval. We focus on the scenario where two users are searching at the same time on the same task, and via the interface, can see the activity of the other user. The main research question asks: does awareness of another searcher aid a user when carrying out a multimedia search session? To encourage awareness, an experimental study was designed where two users were asked to find as many relevant video shots as possible under different awareness conditions. These were individual search (no awareness of each other), mutual awareness (where both user's could see each other's search screen), and unbalanced awareness (where one user is able to see the other's screen, but not vice-versa). Twelve pairs of users were recruited, and the four worst performing TRECVID 2006 search topics were used as search tasks, under four different awareness conditions. We present the results of this study, followed by a discussion of the implications for multimedia digital library systems. ", "authors": "Robert Villa Department of Computing Science University of Glasgow Glasgow, Scotland, UK villar@dcs.gla.ac.uk Nicholas Gildea Department of Computing Science University of Glasgow Glasgow, Scotland, UK ngildea@dcs.gla.ac.uk Joemon Jose Department of Computing Science University of Glasgow Glasgow, Scotland, UK jj@dcs.gla.ac.uk   ", "categories": " H.3.3 [Information Search and Retrieval], H.3.1 Content Analysis and Indexing, H.3.7 Digital Libraries General Terms Human Factors, Design, Experimentation ", "id": "08_p221", "keywords": " Multimedia retrieval, collaboration, awareness ", "title": "A Study of Awareness in Multimedia Search \n"}, "08_p241": {"abstract": " A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers is used to investigate the role of motion video for users of recorded life oral histories. Stories in the library are presented in one of two ways in two within- subjects experiments: either as audio accompanied by a single still photographic image per story, or as the same audio within a motion video of the interviewee speaking. Twenty-four participants given a treasure-hunt fact-finding task, i.e., very directed search, showed no significant preference for either the still or video treatment, and no difference in task performance.  Fourteen participants in a second study worked on an exploratory task in the same within-subjects experimental framework, and showed a significant preference for video. For exploratory work, video has a positive effect on user satisfaction. Implications for use of video in collecting and accessing recorded life oral histories, in student assignments and more generally, are discussed, along with reflections on long term user studies to complement the ones presented here. ", "authors": "Michael G. Christel CS Department and HCI Institute Carnegie Mellon University Pittsburgh, PA 15213 1-412-268-7799 christel@cs.cmu.edu Michael H. Frisch Departments of History & American Studies University at Buffalo, SUNY Buffalo, NY 14260 1-716-639-1047 mfrisch@buffalo.edu ", "categories": " H.3.7: Digital Libraries 每 user issues; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems 每 evaluation, video; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Experimentation, Human Factors ", "id": "08_p241", "keywords": " Oral histories, video retrieval, exploratory search ", "title": "Evaluating the Contributions of Video Representation for a Life Oral History Collection \n"}, "08_p251": {"abstract": " This paper reports the results of a qualitative field study of the scholarly writing, collaboration, information management, and long-term archiving practices of researchers in five related subdisciplines. The study focuses on the kinds of artifacts the researchers create in the process of writing a paper, how they exchange and store materials over the short term, how they handle references and bibliographic resources, and the strategies they use to guarantee the long term safety of their scholarly materials. The findings reveal: (1) the adoption of a new CIM infrastructure relies crucially on whether it compares favorably to email along six critical dimensions; (2) personal scholarly archives should be maintained as a side-effect of collaboration and the role of ancillary material such as datasets remains to be worked out; and (3) it is vital to consider agency when we talk about depositing new types of scholarly materials into disciplinary repositories. ", "authors": "      Catherine C. Marshall Microsoft Research Silicon Valley 1288 Pear Avenue Mountain View, CA 94043 +1 650 693 1308 cathymar@microsoft.com        ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 system issues, user issues General Terms Design, Documentation, Human Factors ", "id": "08_p251", "keywords": " digital archiving, collaboration, scholarly publishing, qualitative study, personal information management, scholarly repositories ", "title": "From Writing and Analysis to the Repository: Taking the Scholars＊ Perspective on Scholarly Archiving \n"}, "08_p261": {"abstract": " Today＊s scientific datasets are growing into Petabytes. A similar transition is happening in industry and society. Web search companies have to deal routinely with tens of Petabytes, a substantial fraction of the world＊s computers go into data warehouses of the Big 5. Scientists, librarians and publishers are just beginning to grasp the magnitude and multi-faceted nature of the problems facing us. Every step of the usual scientific process will need to change and change soon. Science in the 21st century will require a different set of skills than previously, more computational and algorithmic thinking and more interdisciplinary interaction will be hallmarks of a successful scientist. The talk will present the challenges and trends in this ＆brave new world＊. ", "authors": " Alexander S. Szalay The Johns Hopkins University Baltimore, MD, USA szalay@jhu.edu  ", "categories": ": Digital Libraries 每 Dissemination, Online Information Systems 每 Data Sharing General Terms: Algorithms, Performance, Design, Economics, Experimentation. ", "id": "08_p261", "keywords": "", "title": "Keynote Talk Scientific Publishing in the Era of Petabyte Data \n"}, "08_p263": {"abstract": " We describe a user-assisted framework for correcting ink- bleed in old handwritten documents housed at the National Archives of Singapore (NAS). Our approach departs from traditional correction techniques that strive for full automa- tion. Fully-automated approaches make assumptions about ink-bleed characteristics that are not valid for all inputs. Furthermore, fully-automated approaches often have to set algorithmic parameters that have no meaning for the end- user. In our system, the user needs only to provide sim- ple examples of ink-bleed, foreground ink, and background. These training examples are used to classify the remaining pixels in the document to produce a computer-generated re- sult that is equal to or better than existing fully-automated approaches. To offer a complete system, we also provide tools that allow any errors in the computer-generated results to be quickly※cleaned up§by the user. The initial training markup, together with the computer-generated results, and manual edits are all recorded with the final output, allowing subse- quent viewers to see how a corrected document was created and to make changes or updates. While an ongoing project, our feedback from the NAS staff has been overwhelmingly positive that this user-assisted framework is a practical way to address the ink-bleed problem. ", "authors": "Yi Huang Nanyang Technological University School of Computer Engineering Republic of Singapore hu0005yi@ntu.edu.sg Michael S. Brown National University of Singapore School of Computing Republic of Singapore brown@comp.nus.edu.sg ", "categories": " J.2 [Computer Applications]: J.5 Arts and Humanities; I.4 [Image Processing and Computer Vision]: I.4.4 Restoration General Terms Algorithm, Experimentation ", "id": "08_p263", "keywords": " Ink-bleed, restoration, document processing, user-assisted systems (a) (b) Figure 1: (a) Sections from three different docu- ments (circa 1820-1860) from the National Archives of Singapore. (b) Our goal is to help the user signif- icantly reduced ink-bleed interference. ", "title": "User-Assisted Ink-Bleed Correction for Handwritten Documents\n"}, "08_p272": {"abstract": " Authors' names are a critical bibliographic element when searching or browsing academic articles stored in digital libraries. Therefore, those creating metadata for digital libraries would appreciate an automatic method to extract such bibliographic data from printed documents. In this paper, we describe an automatic author name tagger for academic articles scanned with optical character recognition (OCR) mark-up. The method uses conditional random fields (CRF) for labeling the unsegmented character strings in authors＊ blocks as those of either an author or a delimiter. We applied the tagger to Japanese academic articles. The results of the experiments showed that it correctly labeled more than 99% of the author name strings, which compares favorably with the under 96% correct rate of our previous tagger based on a hidden Markov model (HMM).  ", "authors": "Manabu Ohta Okayama University 3-1-1 Tsushima-naka, Okayama-shi, Okayama 700-8530, Japan ohta@de.it.okayama-u.ac.jp Atsuhiro Takasu National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan takasu@nii.ac.jp   ", "categories": " I.7.5 [Document and Text Processing]: Document Capture 每 document analysis, optical character recognition (OCR) General Terms Design, Experimentation ", "id": "08_p272", "keywords": " Conditional Random Fields (CRF), Digital Libraries, Information Extraction ", "title": "CRF-Based Authors＊ Name Tagging for Scanned Documents \n"}, "08_p276": {"abstract": " Most search engines index the textual content of documents in digital libraries. However, scholarly articles frequently report im- portant findings in figures for visual impact and the contents of these figures are not indexed. These contents are often invaluable to the researcher in various fields, for the purposes of direct com- parison with their own work. Therefore, searching for figures and extracting figure data are important problems. To the best of our knowledge, there exists no tool to automatically extract data from figures in digital documents. If we can extract data from these images automatically and store them in a database, an end-user can query and combine data from multiple digital documents si- multaneously and efficiently. We propose a framework based on image analysis and machine learning to extract information from 2-D plot images and store them in a database. The proposed algorithm identifies a 2-D plot and extracts the axis labels, leg- end and the data points from the 2-D plot. We also segregate overlapping shapes that correspond to different data points. We demonstrate performance of individual algorithms, using a com- bination of generated and real-life images. ", "authors": "William Browuer Pennsylvania State University wjb19@psu.edu Saurabh Kataria Pennsylvania State University saurabh@psu.edu Sujatha Das Pennsylvania State University gud111@psu.edu Prasenjit Mitra Pennsylvania State University pmitra@ist.psu.edu C. Lee Giles Pennsylvania State University giles@ist.psu.edu ", "categories": " Data Mining/Extraction [Information Systems Appli- cations]: General Terms Algorithms, Design, Experimentation ", "id": "08_p276", "keywords": "", "title": "Segregating and Extracting Overlapping Data Points in Two-dimensional Plots\n"}, "08_p280": {"abstract": " This paper describes a simple method for extracting meta- data fields from citations using hidden Markov models. The method is easy to implement and can achieve levels of preci- sion and recall for heterogeneous citations comparable to or greater than other HMM-based methods. The method con- sists largely of string manipulation and otherwise depends only on an implementation of the Viterbi algorithm, which is widely available, and so can be implemented by diverse digital library systems. ", "authors": "Erik Hetzner California Digital Library 415 20th St Oakland, CA 94720 erik.hetzner@ucop.edu ", "categories": " H.3.7 [Information storage and retrieval]: Digital Li- braries〞systems issues General Terms Algorithms ", "id": "08_p280", "keywords": " Citation Management, Metadata Extraction ", "title": "A Simple Method for Citation Metadata Extraction using Hidden Markov Models\n"}, "08_p285": {"abstract": " We have developed a method for determining whether data found on the Web are for the same or different objects that takes into account the possibility of changes in their at- tribute values over time. Specifically, we estimate the proba- bility that observed data were generated for the same object that has undergone changes in its attribute values over time and the probability that the data are for different objects, and we define similarities between observed data using these probabilities. By giving a specific form to the distributions of time-varying attributes, we can calculate the similarity between given data and identify objects by using agglomer- ative clustering on the basis of the similarity. Experiments in which we compared identification accuracies between our proposed method and a method that regards all attribute values as constant showed that the proposed method im- proves the precision and recall of object identification. ", "authors": "Satoshi Oyama oyama@i.kyoto-u.ac.jp Kenichi Shirasuna shirasuna@dl.kuis.kyoto- u.ac.jp Katsumi Tanaka ktanaka@i.kyoto-u.ac.jp Department of Social Informatics, Graduate School of Informatics, Kyoto University Yoshida-Honmachi, Sakyo, Kyoto 606-8501, Japan ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval〞clustering ; I.5.3 [Pattern Recogni- tion]: Clustering〞algorithms, similarity measures General Terms Algorithms, Experimentation ", "id": "08_p285", "keywords": " Object Identification, Object-Level Search, Temporal Data ", "title": "Identification of Time-Varying Objects on the Web\n"}, "08_p295": {"abstract": " Citations to publication venues in the form of journal, con- ference and workshop contain spelling variants, acronyms, abbreviated forms and misspellings, all of which make more difficult to retrieve the item of interest. The task of discov- ering and reconciling these variant forms of bibliographic references is known as authority work. The key goal is to create the so called authority files, which maintain, for any given bibliographic item, a list of variant labels (i.e., variant strings) used as a reference to it. In this paper we propose to use information available on the Web to create high quality publication venue authority files. Our idea is to recognize (and extract) references to publication venues in the text snippets of the answers returned by a search engine. Ref- erences to a same publication venue are then reconciled in an authority file. Each entry in this file is composed of a canonical name for the venue, an acronym, the venue type (i.e., journal, conference, or workshop), and a mapping to various forms of writing its name in bibliographic citations. Experimental results show that our Web-based method for creating authority files is superior to previous work based on straight string matching techniques. Considering the av- erage precision in finding correct venue canonical names, we observe gains up to 41.7%. ", "authors": "Denilson Alves Pereira1 Berthier Ribeiro-Neto1 2 Nivio Ziviani1 Alberto H. F. Laender1 1Computer Science Department Federal University of Minas Gerais Belo Horizonte, Brazil {denilson,berthier,nivio, laender}@dcc.ufmg.br 2Google Engineering Belo Horizonte, Brazil berthier@google.com ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.7 [Information Storage and Retrieval]: Digital Libraries General Terms Algorithms, Experimentation ", "id": "08_p295", "keywords": " Authority File, Publication Venue, Canonical Name, Bibli- ographic Citation ", "title": "Using Web Information for Creating Publication Venue Authority Files\n"}, "08_p305": {"abstract": " Information on the Internet, especially blog content, changes rapidly. Users of information collections, such as the blogs hosted by technorati.com, have little, if any, control over the content or frequency of these changes. However, it is important for users to be able to monitor content for deviations in the expected pattern of change. If a user is interested in political blogs and a blog switches subjects to a literary review blog, the user would want to know of this change in behavior. Since pages may change too frequently for manual inspection for ※unwanted§ changes, an automated approach is wanted. In this paper, we explore methods for indentifying unexpected change by using Kalman filters to model blog behavior over time. Using this model, we examine the history of several blogs and determine methods for flagging the significance of a blog's change from one time step to the next. We are able to predict large deviations in blog content, and allow user-defined sensitivity parameters to tune a statistical threshold of significance for deviation from expectation.  ACM ", "authors": "Paul Logasa Bogen II, Joshua Johnston, Unmil P. Karadkar,  Richard Furuta, Frank Shipman Center for the Study of Digital Libraries  and Department of Computer Science Texas A&M University College Station, TX 77843-3112 USA walden@csdl.tamu.edu ", "categories": " H.3.7 [Digital Libraries]: collection, systems issues, user issues. H.3.3 [Information Search and Retrieval]: Information filtering. H.5.4 [Hypertext/Hypermedia]: User issues. General Terms Design, Human Factors, Experimentation, Management. ", "id": "08_p305", "keywords": " Distributed Collection Management, Kalman Filters. ", "title": "Application of Kalman Filters to Identify Unexpected Change in Blogs\n"}, "08_p313": {"abstract": " NCore is an open source architecture and software platform for creating flexible, collaborative digital libraries. NCore was developed by the National Science Digital Library (NSDL) project, and it serves as the central technical infrastructure for NSDL. NCore consists of a central Fedora-based digital repository, a specific data model, an API, and a set of backend services and frontend tools that create a new model for collaborative, contributory digital libraries. This paper describes NCore, presents and analyzes its architecture, tools and services; and reports on the experience of NSDL in building and operating a major digital library on it over the past year and the experience of the Digital Library for Earth Systems Education in porting their existing digital library and tools to the NCore platform.  ", "authors": "Dean B. Krafft Cornell University  301 College Ave. Ithaca, NY 14850 607-255-9214 dean@cs.cornell.edu Aaron Birkland Cornell University 301 College Ave. Ithaca, NY 14850 607-254-5587 birkland@cs.cornell.edu Ellen J. Cramer Cornell University 301 College Ave. Ithaca, NY 14850 607-254-8952 elly@cs.cornell.edu  ", "categories": " H.3.7 [Information Systems]: Digital Libraries 每 Collection, Dissemination, Systems Issues, User Issues. General Terms Management, Design, Reliability, Human Factors. ", "id": "08_p313", "keywords": " Digital library, education, NSDL, Fedora, aggregations, architecture, interoperability. ", "title": "NCore: Architecture and Implementation of a Flexible, Collaborative Digital Library\n"}, "08_p323": {"abstract": " University libraries in Developing Countries (DCs), hampered by developmental problems, find it hard to provide electronic services. Donor communities have come in to bridge this technology gap by providing funds to university libraries for information technology infrastructure, enabling these university libraries to provide electronic library services to patrons. However, for these services to be utilized effectively, library end- users must accept and use them. To investigate this process in Uganda, this study modifies ※The Unified Theory of Acceptance and Use of Technology§ (UTAUT) by replacing ※effort expectancy§ and ※voluntariness§ with ※relevancy§, ※awareness§ and ※benefits§ factors. In so doing, we developed the Service Oriented UTAUT (SOUTAUT) model whose dependent constructs predict 133% of the variances in user acceptance and use of e-library services. The study revealed that relevancy moderated by awareness plays a major factor in acceptance and use of e-library services in DCs. ", "authors": "Prisca K. G. Tibenderana Faculty of CIT, Makerere University Kampala, Uganda. Tel. +256-772-537171 ptiben@cit.mak.ac.ug Patrick J. Ogao Faculty of CIT, Makerere University Kampala, Uganda Tel. +256-782-714019 ogao@cit.mak.ac.ug  ", "categories": " H.3.7 Digital Libraries: user issues,  H.1.1 Systems and Information Theory General Terms Design, Human Factors ", "id": "08_p323", "keywords": " End-users, hybrid library services, technology acceptance, UTAUT, Uganda ", "title": "Acceptance and Use of Electronic Library Services in Ugandan Universities\n"}, "08_p333": {"abstract": " This paper describes the facilities we built to run a self-contained digital library on an iPod. The digital library software used was the open source package Greenstone, and the paper highlights the technical problems that were encountered and solved. It attempts to convey a feeling for the kind of issues that must be faced when adapting standard DL software for non-standard, leading-edge devices. ", "authors": " David Bainbridge,? Steve Jones,? Sam McIntosh,? Matt Jones? and Ian H. Witten? ?Department of Computer Science University of Waikato Hamilton, New Zealand {davidb, stevej, sjm64, ihw}@cs.waikato.ac.nz ?Department of Computer Science University of Swansea Swansea, U.K. matt.jones@swansea.ac.uk   ", "categories": " H.3.7 Digital Libraries, H.5.2 User Interfaces. General Terms Design, Experimentation. ", "id": "08_p333", "keywords": " Mobile Digital Libraries, Open Source, iPod, Greenstone. ", "title": "Portable Digital Libraries on an iPod \n"}, "08_p337": {"abstract": " This paper analyzes problems encountered by our team while creating an educational digital library of program examples. We present approaches to resolving these problems, and evaluations of the suggested approaches.  ", "authors": " Peter Brusilovsky  University of Pittsburgh School of Information Sciences Pittsburgh, PA 15260 peterb@pitt.edu    I-Han Hsiao University of Pittsburgh School of Information Sciences Pittsburgh, PA 15260 ihh4@pitt.edu   Michael Yudelson University of Pittsburgh School of Information Sciences Pittsburgh, PA 15260 mvy3@ pitt.edu    ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval 每 Search process, Selection Process; .H.5.1 [Information Interfaces and Presentation]: Hypertext/Hypermedia 每 Navigation;. H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 User issues General Terms Design, Experimentation, Human Factors, Languages. ", "id": "08_p337", "keywords": " Examples, annotations, navigation support, peer-review, user study. ", "title": "Annotated Program Examples as First Class Objects in an Educational Digital Library \n"}, "08_p341": {"abstract": " Recent initiatives like the Million Book Project and Google Print Library Project have already archived several million books in digital format, and within a few years a significant fraction of world＊s books will be online. While the majority of the data will naturally be text, there will also be tens of millions of pages of images. Many of these images will defy automation annotation for the foreseeable future, but a considerable fraction of the images may be amiable to automatic annotation by algorithms that can link the historical image with a modern contemporary, with its attendant metatags. In order to perform this linking we must have a suitable distance measure which appropriately combines the relevant features of shape, color, texture and text. However the best combination of these features will vary from application to application and even from one manuscript to another. In this work we propose a simple technique to learn the distance measure by perturbing the training set in a principled way. We show the utility of our ideas on archives of manuscripts containing images from natural history and cultural artifacts.  ", "authors": "Xiaoyue Wang Lexiang Ye Eamonn Keogh Christian Shelton    Department of Computer Science and Engineering University of California Riverside Riverside, California {xwang,lexiangy,eamonn,cshelton}@cs.ucr.edu    ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval models  General Terms Algorithms ", "id": "08_p341", "keywords": " Historical Digital Libraries, Historical Manuscripts, Image Annotation, Information Extraction  ", "title": "Annotating Historical Archives of Images \n"}, "08_p351": {"abstract": " A novel technique for semi-automatic photo annotation is proposed and evaluated. The technique, sLab, uses face processing algorithms and a simplified user interface for labeling family photos. A user study compared our system with two others. One was Adobe Photoshop Element. The other was an in-house implementation of a face clustering interface recently proposed in the research community. Nine participants performed an annotation task with each system on faces extracted from a set of 150 images from their own family photo albums. As the faces were all well known to participants, accuracy was near perfect with all three systems. On annotation time, sLab was 25% faster than Photoshop Element and 16% faster than the face clustering interface.  ", "authors": " Ehsan Fazl-Ersi, I. Scott MacKenzie, and John K. Tsotsos Dept. of Computer Science and Engineering  York University Toronto, ON, Canada  {efazl,mack,tsotsos}@cse.yorku.ca  ", "categories": " D.0 General General Terms Algorithms, Performance, Design, Experimentation ", "id": "08_p351", "keywords": " Photo annotation, face detection and recognition, face ranking and clustering ", "title": "sLab: Smart Labeling of Family Photos Through an Interactive Interface \n"}, "08_p355": {"abstract": " Text search on libraries of 3D models has traditionally worked poorly, as text annotations on 3D models are often unreli- able or incomplete. We attempt to improve the recall of text search by automatically assigning appropriate tags to models. Our algorithm finds relevant tags by appealing to a large corpus of partially labeled example models, which does not have to be preclassified or otherwise prepared. For this purpose we use a copy of Google 3DWarehouse, a library of user contributed models which is publicly available on the Internet. Given a model to tag, we find geometrically sim- ilar models in the corpus, based on distances in a reduced dimensional space derived from Zernike descriptors. The la- bels of these neighbors are used as tag candidates for the model with probabilities proportional to the degree of geo- metric similarity. We show experimentally that text based search for 3D models using our computed tags can approach the quality of geometry based search. Finally, we describe our 3D model search engine that uses this algorithm. ", "authors": "Corey Goldfeder Department of Computer Science Columbia University New York, NY coreyg@cs.columbia.edu Peter Allen Department of Computer Science Columbia University New York, NY allen@cs.columbia.edu ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing〞Indexing Methods General Terms Algorithms, Experimentation ", "id": "08_p355", "keywords": "", "title": "Autotagging to Improve Text Search for 3D Models\n"}, "08_p359": {"abstract": " We consider the task of automatic slide image retrieval, in which slide images are ranked for relevance against a textual query.  Our implemented system, SLIDIR caters specifically for this task using features specifically designed for synthetic images embedded within slide presentation. We show promising results in both the ranking and binary relevance task and analyze the contribution of different features in the task performance.  ", "authors": "Guo Min Liew Department of Computer Science School of Computing National University of Singapore liewguom@comp.nus.edu.sg Min-Yen Kan Department of Computer Science School of Computing National University of Singapore kanmy@comp.nus.edu.sg ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval 每 retrieval models.  General Terms Algorithms, Measurement, Human Factors ", "id": "08_p359", "keywords": " SLIDIR, presentations, slides, synthetic images, image retrieval ", "title": "Slide Image Retrieval: A Preliminary Study \n"}, "08_p363": {"abstract": " A novel online news extraction approach based on human perception is presented in this paper. The approach simulates how a human perceives and identifies online news content. It first detects news areas based on content function, space continuity, and formatting continuity of news information. It further identifies detailed news content based on the position, format, and semantic of detected news areas. Experiment results show that our approach achieves much better performance (in average more than 99% in terms of F1 Value) compared to previous approaches such as Tree Edit Distance and Visual Wrapper based approaches. Furthermore, our approach does not assume the existence of Web templates in the tested Web pages as required by Tree Edit Distance based approach, nor does it need training sets as required in Visual Wrapper based approach. The success of our approach demonstrates the strength of the perception-oriented Web information extraction methodology and represents a promising approach for automatic information extraction from sources with presentation design for humans. ", "authors": "Jinlin Chen Computer Science Department Queens College City University of New York Flushing, NY 11367, USA jchen@cs.qc.edu Keli Xiao Computer Science Department Queens College City University of New York Flushing, NY 11367, USA keli.xiao@gmail.com  ", "categories": " H.3.m [Miscellaneous]: Information extraction, Web  General Terms: Algorithms, Experimentation  ", "id": "08_p363", "keywords": ": Information extraction, online news, Web  ", "title": "Perception-oriented Online News Extraction \n"}, "08_p367": {"abstract": " The fast changes of technologies in today＊s information land- scape have considerably shortened the lifespan of digital ob- jects. Digital preservation has become a pressing challenge. Different strategies such as migration and emulation have been proposed; however, the decision for a specific tool e.g. for format migration or an emulator is very complex. The process of evaluating potential solutions against specific re- quirements and building a plan for preserving a given set of objects is called preservation planning. So far, it is a mainly manual, sometimes ad-hoc process with little or no tool sup- port. This paper presents a service-oriented architecture and decision support tool that implements a solid preser- vation planning process and integrates services for content characterisation, preservation action and automatic object comparison to provide maximum support for preservation planning endeavours. ", "authors": "Christoph Becker, Hannes Kulovits, Andreas Rauber Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/dp Hans Hofman Nationaal Archief The Hague, The Netherlands www.nationaalarchief.nl ", "categories": " H.3 [Information Storage and Retrieval]: H.3.7 Digital Libraries General Terms Design, Experimentation, Measurement, Standardization ", "id": "08_p367", "keywords": " Digital Preservation, Preservation Planning, decision sup- port system, service oriented architecture ", "title": "Plato: A Service Oriented Decision Support System for Preservation Planning\n"}, "08_p371": {"abstract": " The Web is increasingly the medium by which information is published today, but due to its ephemeral nature, web pages and sometimes entire websites are often ※lost§ due to server crashes, viruses, hackers, run-ins with the law, bankruptcy and loss of interest. When a website is lost and backups are unavailable, an individual or third party can use War- rick to recover the website from several search engine caches and web archives (the Web Infrastructure). In this short paper, we present Warrick usage data obtained from Brass, a queueing system for Warrick hosted at Old Dominion Uni- versity and made available to the public for free. Over the last six months, 520 individuals have reconstructed more than 700 websites with 800K resources from the Web In- frastructure. Sixty-two percent of the static web pages were recovered, and 41% of all website resources were recovered. The Internet Archive was the largest contributor of recov- ered resources (78%). ", "authors": "Frank McCown Harding University Computer Science Department Searcy, Arkansas, USA 72149 fmccown@harding.edu Michael L. Nelson Old Dominion University Computer Science Department Norfolk, Virginia, USA 23529 mln@cs.odu.edu ", "categories": ": H.3.5 [Informa- tion Storage and Retrieval] Online Information Services: Web- based services; H.3.7 [Information Storage and Retrieval] Digital Libraries: Collection General Terms: Measurement ", "id": "08_p371", "keywords": ": digital preservation, search engine caches, web archiving ", "title": "Usage Analysis of a Public Website Reconstruction Tool\n"}, "08_p375": {"abstract": " We discuss the use of web metrics at four digital libraries, the Instructional Architect, the Library of Congress, the National Science Digital Library, and WGBH Teachers＊ Domain. We describe practical issues involved in implementing and using web metrics to track web site performance. We also report on the focused data mining of web metrics. Using session length as our example, we recommend that this metric, which was developed to track e-commerce, be reconsidered when applied in non-e- commerce settings, such as digital libraries. We conclude by discussing some of the limitations and possibilities in using web metrics to analyze and evaluate digital library use and impact. ", "authors": "Michael Khoo The iSchool at Drexel University Philadelphia, PA 19104-2875 +1.215.895.2474 michael.khoo@ischool.drexel.edu Mimi Recker Utah State University Logan, UT 84322-2830 +1.435.797.2688 mimi.recker@usu.edu  Joe Pagano The Library of Congress Washington, D.C. 20540 +1.202.707.2488 jpag@loc.gov Bart Palmer Utah State University Logan, UT 84322-2830 +1.435.797.2688 bart.palmer@usu.edu  Anne L. Washington The Library of Congress Washington, D.C. 20052 +1.202.707.5520 annew@crs.loc.gov Robert A. Donahue WGBH Educational Foundation Boston, MA 02135 +1.617.300.3638 bob_donahue@wgbh.org  ", "categories": " H.3.7 Digital Libraries: system issues, user issues General Terms Management, Measurement, Documentation, Performance, Design, Human Factors ", "id": "08_p375", "keywords": " evaluation, usability, usage, web analytics, web metrics ", "title": "Using Web Metrics to Analyze Digital Libraries\n"}, "08_p385": {"abstract": " We describe a Web-based metadata quality tool that provides statistical descriptions and visualisations of Dublin Core metadata harvested via the OAI protocol. The lightweight nature of development allows it to be used to gather contextualized requirements and some initial user feedback is discussed. ", "authors": "David M. Nichols,  Chu-Hsiang Chan,  David Bainbridge  Department of Computer Science University of Waikato Hamilton, New Zealand +64 (7) 8585130 {dmn,cc108,davidb}@cs.waikato.ac.nz Dana McKay University Library Swinburne University of Technology Hawthorn, VIC 3122  Australia +61 (3) 9214 5023 dmckay@swin.edu.au Michael B. Twidale Graduate School of Library  and Information Science University of Illinois Champaign, IL 61820, USA +1 (217) 265-0510 twidale@uiuc.edu ", "categories": " H.3.7 [Digital Libraries]: user issues, systems issues. General Terms: Measurement, Human Factors. ", "id": "08_p385", "keywords": " Metadata quality, OAI, Visualization, Dublin Core, Prototyping ", "title": "A Lightweight Metadata Quality Tool \n"}, "08_p389": {"abstract": " This paper investigates novel interactions for supporting within每 document navigation. We focus on one specific interaction: the following of figure references. Through this interaction we illuminate factors also found in other forms of naviga- tion. Three alternative interactions for supporting figure navigation are described and evaluated through a user study. Experimentation proves the advantages of our interaction design, and the degree to which the interaction of existing reader software can be improved. ", "authors": "George Buchanan Future Interaction Laboratory Swansea University Swansea, UK g.r.buchanan@swansea.ac.uk Thomas Owen Future Interaction Laboratory Swansea University Swansea, UK cstomo@swansea.ac.uk ", "categories": " H.3.7 [Information storage and retrieval]: Digital Li- braries〞User issues General Terms Human Factors ", "id": "08_p389", "keywords": " Document Readers, Computer-Human Interaction ", "title": "Improving Navigation Interaction in Digital Documents\n"}, "08_p393": {"abstract": " We describe a novel interface by which a user can browse, bookmark and retrieve previously used working environments, i.e., desktop status, enabling the retention of the history of use of various sets of information. Significant tasks often require reuse of (sets of) information that was used earlier. Particularly, if a task involves extended interaction, then the task＊s environment has been through a lot of changes and can get complex. Under the current prevailing desktop-based computing environment, after an interruption to the task users can gain little assistance to get back to the context that they previously worked on. A user thus encounters increased discontinuity in continuing extended tasks. ACM ", "authors": "Youngjoo Park and Richard Furuta Center for the Study of Digital Libraries and Department of Computer Science Texas A&M University College Station, TX 77843-3112, USA {yjoo9317,furuta}@cs.tamu.edu  ", "categories": " H.5.2 [Information Interfaces and Presentations]: User Interfaces.  General Terms Design, Human Factors. ", "id": "08_p393", "keywords": " Context, context browser, continuity, desktop, narrative, task. ", "title": "Keeping Narratives of a Desktop to Enhance Continuity of On-going Tasks \n"}, "08_p397": {"abstract": " Our research develops note-taking applications for educational environments. Previous studies found that while copy-pasting notes can be more efficient than typing, for some users it reduces attention and learning. This paper presents two studies aimed at designing and evaluating interfaces that encourage focusing. While we were able to produce interfaces that increased desirable behaviors and improved satisfaction, the new interfaces did not improve learning. We suggest design recommendations derived from these studies, and describe a ※selecting-to-read§ behavior we encountered, which has implications for the design of reading and note-taking applications.  ", "authors": "Aaron Bauer Kenneth R. Koedinger Carnegie Mellon University 5000 Forbes Ave Pittsburgh, PA 15213 1- 412-268-9095 {abauer, koedinger}@cmu.edu   ", "categories": " H.5.4 Hypertext/Hypermedia: Miscellaneous. K.3 Computers and Education General Terms Design, Experimentation, Human Factors ", "id": "08_p397", "keywords": " Annotation, Note-Taking, Education, Copy-Paste, Design ", "title": "Note-Taking, Selecting, and Choice: Designing Interfaces That Encourage Smaller Selections \n"}, "08_p407": {"abstract": " The Fedora content management system embodies a power- ful and flexible digital object model. This paper describes a new open-source software front-end that enables end-user librarians to transfer documents and metadata in a variety of formats into a Fedora repository. The main graphical fa- cility that Fedora itself provides for this task operates on one document at a time and is not librarian-friendly. A batch driven alternative is possible, but requires documents to be converted beforehand into the XML format used by the repository, necessitating a need for programming skills. In contrast, our new scheme allows arbitrary collections of documents residing on the user＊s computer (or the web at large) to be ingested into a Fedora repository in one opera- tion, without a need for programming expertise. Provision is also made for editing existing documents and metadata, and adding new ones. The documents can be in a wide va- riety of different formats, and the user interface is suitable for practicing librarians. The design capitalizes on our ex- perience in building the Greenstone librarian interface and participating in dozens of workshops with librarians world- wide. ", "authors": "David Bainbridge and Ian H. Witten University of Waikato Hillcrest Road Hamilton, NZ {davidb,ihw}@cs.waikato.ac.nz ", "categories": " H.3.7 Digital Libraries, H.5.2 User Interfaces. General Terms Design, Human Factors. ", "id": "08_p407", "keywords": " Graphical User Interface, End-user Collection Building, Fe- dora Digital Repository ", "title": "A Fedora Librarian Interface\n"}, "09_p001": {"abstract": " A three-part study of teachers＊ use of online resources and of the Digital Library for Earth System Education (DLESE) was conducted from 2004 through summer 2006. The first two phases were qualitative and informed a survey administered to 622 science teachers across the U.S., one-fifth of whom had used DLESE. The findings present a profile of teachers and their access to Internet-connected computers and other hardware/electronic media devices in their classrooms; and teachers＊ preferences for resource formats (e.g., customizability) and educational web site features (e.g., tagged reading level). Analysis of variance showed that teachers with more than one working computer and teachers with more other devices valued the Internet more highly for teaching than did their less equipped peers. DLESE users valued the Internet more highly for their teaching, had more years teaching experience, and valued customizable resources more than their non-DLESE using peers. Most believed that resources catalogued in DLESE were scientifically accurate. Teachers used DLESE most often for finding hands-on activities, still images and other visual aids, and hand-outs; they were least likely to seek people, games, or assessment tools. The findings provide guidance for developers of K12 educational resources. ", "authors": "Lecia J. Barker School of Information University of Texas at Austin Austin, TX 78712-0390 +1 512 232 8364 Lecia@ischool.utexas.edu   ", "categories": " H.3.7 [Digital Libraries]: User issues General Terms Human Factors ", "id": "09_p001", "keywords": " K12, teaching, empirical, mixed-method, educational digital libraries, evaluation ", "title": "Science Teachers＊ Use of Online Resources and the Digital Library for Earth System Education\n"}, "09_p011": {"abstract": " Enhancing the experience of digital library users depends, in part, on recognizing and understanding user tasks. In the context of K-12 educational libraries this means that we must understand how K-12 teachers interact with such libraries and how they assess the relevance of documents found or encountered. This paper presents the results of an experiment in which K-12 teachers scored the relevance of curriculum they found themselves and the relevance of documents their colleagues found and recommended. We found that teachers apply a significantly more detailed notion of relevance, both qualitatively and quantitatively, when searching for as compared to evaluating recommended curricula. Differences were observed in both relevance judgments and system interaction logs. These variations may be useful in identifying user intent and in dynamically adapting the behavior of digital libraries of educational material.  ", "authors": " Byron Marshall College of Business Oregon State University Corvallis, OR byron.marshall@bus.oregegonstate.edu Ren谷 Reitsma College of Business Oregon State University Corvallis, OR reitsmar@bus.oregegonstate.edu Malinda Zarske College of Engineering University of Colorado at Boulder Boulder, CO Malinda.zarske@colorado.edu ", "categories": " K.3.1 [Computer Uses in Education]  General Terms Measurement, Reliability, Experimentation, Human Factors. ", "id": "09_p011", "keywords": " Curriculum-standard alignment, Inter-rater reliability, Relevance, Digital library, Context-specific measurement.  ", "title": "Dimensional Standard Alignment in K-12 Digital Libraries: Assessment of Self-found vs. Recommended Curriculum \n"}, "09_p015": {"abstract": " The problem of information fragmentation is especially acute for today＊s college students who manage and assimilate information in various forms while completing many of their academic tasks, and who must do so within the confines of standard software applications. The goal of this research is to provide students with a novel information assimilation and notetaking tool that helps them more efficiently manage their electronic information and overcome some of the fragmentation challenges they routinely experience. Our Global Information Gatherer prototype allows students to view, edit and store files of different types from within a single interface, and provides an integrated web browser and notetaking functionality.  ", "authors": "Yolanda Jacobs Reimer, Melissa Bubnash, Matthew Hagedal, Peter Wolf University of Montana Computer Science Department Social Sciences Building, Room 401 Missoula, MT 59812 {yolanda.reimer, melissa.bubnash, matthew.hagedal, peter.wolf}@umontana.edu     ", "categories": " H5.2 [Information interfaces and presentation]: User Interfaces. - Graphical user interfaces. General Terms Design. ", "id": "09_p015", "keywords": " Information fragmentation, information assimilation, notetaking, PIM, user interface design, students in higher education. ", "title": "Helping Students with Information Fragmentation, Assimilation and Notetaking \n"}, "09_p019": {"abstract": " Recent years have seen the rise of subject-themed digital li- braries, such as the NSDL pathways and the Digital Library for Earth System Education (DLESE). These libraries often need to manually verify that contributed resources cover top- ics that fit within the theme of the library. We show that such scope judgments can be automated using a combination of text classification techniques and topic modeling. Our models address two significant challenges in making scope judgments: only a small number of out-of-scope resources are typically available, and the topic distinctions required for digital libraries are much more subtle than classic text classification problems. To meet these challenges, our mod- els combine support vector machine learners optimized to different performance metrics and semantic topics induced by unsupervised statistical topic models. Our best model is able to distinguish resources that belong in DLESE from resources that don＊t with an accuracy of around 70%. We see these models as the first steps towards increasing the scalability of digital libraries and dramatically reducing the workload required to maintain them. ", "authors": "Steven Bethard Stanford University 353 Serra Mall Stanford, CA 94305, USA bethard@stanford.edu Soumya Ghosh University of Colorado 430 UCB Boulder, CO 80309, USA soumya.ghosh@ colorado.edu James H. Martin University of Colorado 430 UCB Boulder, CO 80309, USA james.martin@ colorado.edu Tamara Sumner University of Colorado 430 UCB Boulder, CO 80309, USA tamara.sumner@ colorado.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries; I.2.7 [Artificial Intelligence]: Natural Language Processing General Terms Algorithms ", "id": "09_p019", "keywords": " digital libraries, scope, relevance, topics, machine learning ", "title": "Topic Model Methods for Automatically Identifying Out-of-Scope Resources\n"}, "09_p029": {"abstract": " A major challenge for content management in intranets and other large scale document storage and retrieval services is the generation of high quality metadata. Manual generation of metadata is resource demanding and is often viewed by collection managers and document authors as inefficient use of their time, and there is a desire for other ways to create the needed metadata. Automatic Metadata Generation (AMG) is methods for generating metadata without manual interaction using computer program(s) to interpret the document and possibly the document context. Current AMG research has been limited to collection of similarly formatted documents. The research presented in this paper expands the field of AMG by presenting an approach that is independent of a common visualization scheme; AMG based on document code analysis. This is done by showing AMG possibilities from Latex, Word and PowerPoint documents and how this approach can significantly increase the quality of the generated metadata. This by avoiding common quality reducing factors as missing completeness, low accuracy, logical consistency and coherence and timeliness by giving AMG algorithms direct access to the user specified intellectual content and the file formatting. This research shows how this AMG approach can be combined with other AMG approaches, drawing on their strengths in order to achieve the desired high quality metadata entities.  ", "authors": " Lars Fredrik H?imyr Edvardsen Intelligent Communication AS /  Norwegian University of Science and Technology  Kristian Augusts gate 14 NO-0164 Oslo +47 908 41 765 lars.edvardsen@intelcom.no Ingeborg Torvik S?lvberg Norwegian University of Science and Technology  Sem S?lands vei 7-9 NO-7491 Trondheim +47 73 59 60 27 ingeborg.solvberg@idi.ntnu.no Trond Aalberg Norwegian University of Science and Technology  Sem S?lands vei 7-9 NO-7491 Trondheim +47 73 59 79 52 trond.aalberg@idi.ntnu.no Hallvard Tr?tteberg Norwegian University of Science and Technology Sem S?lands vei 7-9 NO-7491 Trondheim +47 73 59 34 43 hal@idi.ntnu.no   ", "categories": " H 3.1 [Information Systems] Content Analysis and Indexing 每 abstracting methods, indexing methods H 3.7 [Information Systems] Digital Libraries - collection General Terms Algorithms, Reliability, Experimentation, Verification. ", "id": "09_p029", "keywords": " Automatic Metadata Generation, Harvesting, Extraction, Document Code, Metadata Quality, Latex, Word, PowerPoint, PDF, OpenXML. ", "title": "Automatically Generating High Quality Metadata by Analyzing the Document Code of Common File Types \n"}, "09_p039": {"abstract": " Users of digital libraries usually want to know the exact au- thor or authors of an article. But different authors may share the same names, either as full names or as initials and last names (complete name change examples are not considered here). In such a case, the user would like the digital library to differentiate among these authors. Name disambigua- tion can help in many cases; one being a user in a search of all articles written by a particular author. Disambigua- tion also enables better bibliometric analysis by allowing a more accurate counting and grouping of publications and citations. In this paper, we describe an algorithm for pair- wise disambiguation of author names based on a machine learning classification algorithm, random forests. We define a set of similarity profile features to assist in author disam- biguation. Our experiments on the Medline database show that the random forest model outperforms other previously proposed techniques such as those using support-vector ma- chines (SVM). In addition, we demonstrate that the vari- able importance produced by the random forest model can be used in feature selection with little degradation in the disambiguation accuracy. In particular, the inverse docu- ment frequency of author last name and the middle name＊s similarity alone achieves an accuracy of almost 90%. ", "authors": "Pucktada Treeratpituk Information Sciences and Technology Pennslyvania State University University Park, PA, 16802, USA pxt162@ist.psu.edu C.Lee Giles Information Sciences and Technology Computer Science and Engineering Pennslyvania State University University Park, PA, 16802, USA giles@ist.psu.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation ", "id": "09_p039", "keywords": " Author Disambiguation, Medline, Random Forests ", "title": "Disambiguating Authors in Academic Publications using Random Forests\n"}, "09_p049": {"abstract": " In digital libraries, ambiguous author names may occur due to the existence of multiple authors with the same name (polysemes) or different name variations for the same au- thor (synonyms). We proposed here a new method that uses information available on the Web to deal with both problems at the same time. Our idea consists of gather- ing information from input citations and submitting queries to a Web search engine, aiming at finding curricula vitae and Web pages containing publications of the ambiguous authors. From the content of documents in the answer sets returned by the Web search engine, useful information that can help in the disambiguation process is extracted. Using this information, author names are disambiguated by lever- aging a hierarchical clustering method that groups citations in the same document together in a bottom-up fashion. Ex- perimental results show that the our method yields results that outperform those of two state-of-the-art unsupervised methods and are statistically comparable with those of a su- pervised one, but requiring no training. We observe gains of up to 65.2% in the pairwise F1 metric when compared with our best unsupervised baseline method. ", "authors": "Denilson Alves Pereira1 Berthier Ribeiro-Neto1 2 Nivio Ziviani1 Alberto H. F. Laender1 Marcos Andr谷 Gon?alves1 Anderson A. Ferreira1 1Department of Computer Science Federal University of Minas Gerais Belo Horizonte, Brazil {denilson,berthier,nivio,laender, mgoncalv,ferreira}@dcc.ufmg.br 2Google Engineering Belo Horizonte, Brazil berthier@google.com ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.7 [Information Storage and Retrieval]: Digital Libraries General Terms Algorithms, Experimentation ", "id": "09_p049", "keywords": " Author Name Disambiguation, Search Engine, Bibliographic Citation ", "title": "Using Web Information for Author Name Disambiguation\n"}, "09_p059": {"abstract": " The amount of scientific material available electronically is forever increasing. This makes reading the published litera- ture, whether to stay up-to-date on a topic or to get up to speed on a new topic, a difficult task. Yet, this is an activity in which all researchers must be engaged on a regular basis. Based on a user requirements analysis, we developed a new research tool, called the Citation-Sensitive In-Browser Sum- mariser (CSIBS), which supports researchers in this brows- ing task. CSIBS enables readers to obtain information about a citation at the point at which they encounter it. This infor- mation is aimed at enabling the reader to determine whether or not to invest the time in exploring the cited article fur- ther, thus alleviating information overload. CSIBS builds a summary of the cited document, bringing together meta- data about the document and a citation-sensitive preview that exploits the citation context to retrieve the sentences from the cited document that are relevant at this point. This paper briefly presents our user requirements analysis, then describes the system and, finally, discusses the observations from an initial pilot study. We found that CSIBS facilitates the relevancy judgment task, by increasing the users＊ self- reported confidence in making such judgements. ", "authors": "Stephen Wan, C谷cile Paris ICT Centre CSIRO Sydney, Australia {Stephen.Wan|Cecile.Paris}@csiro.au Robert Dale Centre for Language Technology Faculty of Science Macquarie University, Australia rdale@science.mq.edu.au ", "categories": " H.2.8 [Database Applications]: Scientific databases; H.5.2 [User Interfaces]: Natural language, User-centered design; H.5.4 [Hypertext/ Hypermedia]: Navigation, User issues General Terms Design, Human Factors ", "id": "09_p059", "keywords": " Information needs; Information browsing; Scientific Litera- ture; Biomedical Researchers; User Modeling and Interac- tive IR; Summarization ", "title": "Whetting the Appetite of Scientists: Producing Summaries Tailored to the Citation Context\n"}, "09_p069": {"abstract": " We propose a generative model based on latent Dirichlet allocation for mining distinct topics in document collections by integrating the temporal ordering of documents into the generative process. The document collection is divided into time segments where the discovered topics in each segment is propagated to influence the topic discovery in the subsequent time segments. We conduct experiments on the collection of academic papers from CiteSeer repository. We augment the text corpus with the addition of user queries and tags and integrate the citation graph to boost the weight of the topical terms. The experiment results show that segmented topic model can effectively detect distinct topics and their evolution over time. ", "authors": "Levent Bolelli1, Seyda Ertekin2, Ding Zhou3, C. Lee Giles2 1Google Inc. 76 Nineth Ave New York, NY 10011 levent@google.com 2The Pennsylvania State University University Park, PA 16802 sertekin@cse.psu.edu giles@ist.psu.edu 3Facebook Inc. 285 Hamilton Avenue Palo Alto, CA 94301 dzhou@psu.edu ", "categories": " H.2.8 [Database Management]: Database Applications〞 data mining General Terms Algorithms, Design, Experimentation ", "id": "09_p069", "keywords": "", "title": "Finding Topic Trends in Digital Libraries\n"}, "09_p073": {"abstract": " Bibliographic information is essential for many digital library applications, such as citation analysis, academic searching and topic discovery. And bibliographic data extraction has attracted a great deal of attention in recent years. In this paper, we address the problem of automatic extraction of bibliographic data in Chinese electronic book and propose a tool called CEBBIP* for the task, which includes three main systems: data preprocessing, data parsing and data postprocessing. In the data preprocessing system, the tool adopts a rules-based method to locate citation data in a book and to segment citation data into citation strings of individual referencing literature. And a learning-based approach, Conditional Random Fields (CRF), is employed to parse citation strings in the data parsing system. Finally, the tool takes advantage of document intrinsic local format consistency to enhance citation data segmentation and parsing through clustering techniques. CEBBIP has been used in a commercial E-book production system. Experimental results show that CEBBIP＊s precision rate is very high. More specially, adopting the document intrinsic local format consistency obviously improves the citation data segmenting and parsing accuracy. ", "authors": "Liangcai Gao, Zhi Tang            Xiaofan Lin Institute of Computer Science & Technology,            Vobile Inc. Peking University, Beijing, China          Santa Clara, California, USA   86-10-82179680                 1-4082175013 {gaoliangcai, tangzhi}@icst.pku.edu.cn      xiaofan@vobileinc.com                ", "categories": " H.3.7 [Information Storage And Retrieval]: Digital Libraries; H.3.3 [Information Systems]: Information Search and Retrieval General Terms Algorithms ", "id": "09_p073", "keywords": " Metadata extraction, Digital Library, Chinese Electronic Book, Bibliography, Machine learning ", "title": "CEBBIP: A Parser of Bibliographic Information in Chinese Electronic Books \n"}, "09_p077": {"abstract": " Video is increasingly important to digital libraries and archives as both primary content and as context for the primary objects in collections. Services like YouTube not only offer large numbers of videos but also usage data such as comments and ratings that may help curators today make selections and aid future generations to interpret those selections. A query-based harvesting strategy is presented and results from daily harvests for six topics defined by 145 queries over a 20-month period are discussed with respect to, query specification parameters, topic, and contribution patterns. The limitations of the strategy and these data are considered and suggestions are offered for curators who wish to use query-based harvesting. ", "authors": "Gary Marchionini, Chirag Shah, Christopher A. Lee, Robert Capra School of Information & Library Science University of North Carolina Chapel Hill, NC 27599-3360 {march, chirag, callee, rcapra}@ils.unc.edu ", "categories": " H.3.7 Information Storage and Retrieval: Digital Libraries, H5.m. Information Interfaces and Presentation (e.g. HCI): Miscellaneous. General Terms Management, Documentation, Design. ", "id": "09_p077", "keywords": " Digital curation, harvesting, video mining. ", "title": "Query Parameters for Harvesting Digital Video and Associated Contextual Information \n"}, "09_p087": {"abstract": " In this paper, we present ViGOR (Video Grouping, Organisation and Retrieval) a video retrieval system that allows users to group videos in order to facilitate video retrieval tasks. In this way users are able to visualise and conceptualise many aspects of their search tasks and carry out a localised search in order to solve a more global search problem. The main objective of this work is to aid users while carrying out explorative video retrieval tasks; these tasks can be often ambiguous and multi-faceted. Two user evaluations were carried out in order to evaluate the usefulness of this grouping paradigm for assisting users. The first evaluation involved users carrying out broad tasks on YouTube, and gave insights into the application of our interface to a vast online video collection. The second evaluation involved users carrying out focused tasks on the TRECVID 2007 video collection, allowing a comparison over a local collection, on which we could extract a number of content-based features. The results of our evaluations show that the use of the ViGOR system results in an increase in user performance and user satisfaction, showing the potential of a grouping paradigm for video search for various tasks in a variety of diverse video collections. ", "authors": "Martin Halvey David Vallet David Hannah Joemon M. Jose  Department of Computing Science, University of Glasgow, Glasgow, Scotland, United Kingdom, G12 8QQ. {halvey, dvallet, davidh, jj} @ dcs.gla.ac.uk   ", "categories": ": H.5.1 Multimedia Information Systems, H.5.3 Group and Organization Interfaces General Terms: Management, Design, Experimentation, Human Factors. ", "id": "09_p087", "keywords": ": Video, search, visualisation, user studies. ", "title": "ViGOR: A Grouping Oriented Interface for Search and Retrieval in Video Libraries \n"}, "09_p097": {"abstract": " This article describes the process and challenges of developing a content model that can support the content and metadata present in a complex media archive. Media archives have some of the most diverse requirements in an effort to catalog, preserve, and make accessible a wide range of content with multifaceted relationships between works. We focus particularly on the design and implementation of the WGBH Media Library and Archives＊ Fedora digital access repository for scholars, educational users and the public. It is our hope that the process and findings from this work can support the architecture and development of other media archives. ", "authors": "Christopher A. Beer WGBH Interactive chris_beer@wgbh.org Peter D. Pinch WGBH Interactive peter_pinch@wgbh.org Karen Cariani WGBH Media Library and Archives karen_cariani@wgbh.org ", "categories": " H.3.7 [Digital Libraries]: Systems issues; E.2 [Data Storage Representations]: Object representation. General Terms Design, Standardization. ", "id": "09_p097", "keywords": " Media, digital libraries, FEDORA, content model ", "title": "Developing a Flexible Content Model for Media Repositories: A Case Study\n"}, "09_p101": {"abstract": " Music retrieval systems for Western tonal music digital li- braries have to consider rhythmic, timbral, melodic and har- monic information. Most existing retrieval systems only take into account melodies. Melody comparison may induce er- rors since two musical pieces can be very similar whereas their melodies may differ in a significant way. In this paper, we propose to investigate and experiment a retrieval system based on the comparison of chord progressions. The defini- tion of chords may be ambiguous but their properties can be precisely described and represented. We detail the adap- tations of alignment algorithms, successfully applied for the estimation of symbolic melodic similarity, for chord progres- sion retrieval. Several experiments, performed on symbolic databases, show that the system described is robust to vari- ations and outperforms a recent chord retrieval system. ", "authors": " Pierre Hanna, Matthias Robine and Thomas Rocher ? LaBRI - Universit谷 de Bordeaux F-33405 Talence cedex, France firstname.name@labri.fr ", "categories": " H.5.5 [Information Systems]: HCI〞Sound and Music Computing General Terms Experimentation ", "id": "09_p101", "keywords": "", "title": "An Alignment Based System for Chord Sequence Retrieval \n"}, "09_p105": {"abstract": " Users of text retrieval systems input only a few keywords or sometimes just one keyword to the systems even if they had complex information needs. Due to the lack of query keywords, it becomes hard to return relevant search results that satisfy the demands of each user. Because digital doc- uments, in contrast to queries, are generally composed of many kinds of keywords, it is also difficult to estimate the main topic or grasp the inherent intentions of the docu- ments. In this paper, we present techniques to represent users＊ search intentions and the intentions that digital docu- ments can satisfy by making use of clicked titles and snippets acquired from a click log analysis. We then present a method to match these intentions to boost search result rankings. Through experiments that use click logs and indexes of a commercial search engine, we verified our method＊s capabil- ity of significantly improving search precision. ", "authors": "Masaya Murata, Hiroyuki Toda, Yumiko Matsuura, and Ryoji Kataoka NTT Cyber Solutions Laboratories, NTT Corporation 1-1 Hikari-no-oka, Yokosuka-shi, Kanagawa 239-0847, Japan {murata.masaya, toda.hiroyuki, matsuura.yumiko, kataoka.ryoji}@lab.ntt.co.jp ", "categories": " H.3 [Information Storage and Retrieval]: Miscellaneous; H.3.3 [Information Search and Retrieval]: Metrics〞 Search process, Relevance feedback General Terms Algorithms, Experimentation ", "id": "09_p105", "keywords": " Search result rankings, implicit relevance feedback, click logs analysis, representation of intention ", "title": "Query-Page Intention Matching using Clicked Titles and Snippets to Boost Search Rankings\n"}, "09_p115": {"abstract": " A lot of future-related information is available in news articles or Web pages. This information can however differ to large extent and may fluctuate over time. It is therefore difficult for users to manually compare and aggregate it, and to re-construct the most probable course of future events. In this paper we approach a problem of automatically generating summaries of future events related to queries using data obtained from news archive collections or from the Web. We propose two methods, explicit and implicit future-related information detection. The former is based on analyzing the context of future temporal expressions in documents, while the latter relies on detecting periodical patterns in historical document collections. We present a graph-based visualization of future-related information and demonstrate its usefulness through several examples.  ", "authors": "Adam Jatowt, Kensuke Kanazawa, Satoshi Oyama and Katsumi Tanaka  Graduate School of Informatics, Kyoto University  Yoshida-honmachi, Sakyo-ku, Kyoto, Japan Phone: +81-75-7535969 {adam,kanazawa,oyama,tanaka}@dl.kuis.kyoto-u.ac.jp  ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms ", "id": "09_p115", "keywords": " Future-related information retrieval, event prediction, temporal information analysis  ", "title": "Supporting Analysis of Future-related Information in News Archives and the Web \n"}, "09_p125": {"abstract": " Faceted metadata and navigation have become major topics in library science, information retrieval and Human-Computer Inter- action (HCI). This work surveys a range of extant approaches in this design space, classifying systems along several relevant di- mensions. We use that survey to analyze the organization of data and its querying within faceted browsing systems. We contribute formal entity-relationship (ER) and relational data models that explain that organization and relational query models that explain systems＊ browsing functionality. We use these types of models since they are widely used to conceptualize data and to model back-end data stores. Their structured nature also suggests ways in which both the models and faceted systems might be extended.  ", "authors": "Edward C. Clarkson 1 , Shamkant B. Navathe 2 and James D. Foley 1 1 School of Interactive Computing and GVU Center Georgia Institute of Technology 85 5 th Street NW, Atlanta, GA 30332-0760 {edward.clarkson,foley}@cc.gatech.edu 2 School of Computer Science Georgia Institute of Technology 801 Atlantic Drive, Atlanta, GA 30332-0280 sham@cc.gatech.edu ", "categories": " H.2.1 [Logical Design]: Data models.  General Terms Design ", "id": "09_p125", "keywords": "", "title": "Generalized Formal Models for Faceted User Interfaces \n"}, "09_p135": {"abstract": " We describe the implementation of a statewide system for managing and preserving electronic theses and dissertations (ETDs) from Texas universities. We further explain the theoretical, technical and political issues that arose during the implementation of this system. These issues range from technical components developed by TDL〞such as a customized workflow management application and adding OAI-ORE capabilities to DSpace〞to human-centered issues such as stakeholder engagement and participation. Our experiences reflect the challenges, expected and unexpected, that others will face when attempting to build digital library applications to scale. ", "authors": "Adam Mikeal, James Creel, Alexey Maslov, Scott Phillips, John Leggett, Mark McFarland1 Texas A&M University Libraries 5000 TAMU College Station, TX USA +1 (979) 862-3887 {adam, jcreel, alexey, scott, leggett}@library.tamu.edu The University of Texas Libraries1 1 University Station S5400 Austin, TX USA +1 (512) 495-4129 mcfarland@austin.utexas.edu  ", "categories": " H.3.7 [Information Systems: Information Storage and Retrieval]: Digital Libraries〞dissemination, standards, systems issues, user issues.  General Terms: Design, Human Factors. ", "id": "09_p135", "keywords": " Electronic theses and dissertations, scalable systems, digital library architecture, electronic document workflow ", "title": "Large-scale ETD repositories: A case study of a digital library application \n"}, "09_p145": {"abstract": " There are lots of digitized calligraphy works written by ancient famous calligraphists in CADAL (China-America Digital Academic Library) digital library. To make use of these resources, users want to generate a tablet or a piece of calligraphic works written by some ancient famous calligraphist. But some characters in the tablet or the calligraphic work hadn＊t been written by the calligraphist or though were ever written but are hard to read because of long time weathering. In this paper, a novel approach is proposed to synthesize Chinese calligraphic characters which are in the same style of some calligraphist, and a corresponding system is developed for calligraphy works generation and tablets design.  Calligraphic character is represented by a three-level hierarchical model. A novel approach for determining the character structure is proposed, which takes advantage of both the structure of the same characters of different styles and the structure of similar characters of the same style. A style evaluation model (SEM) is presented to evaluate whether the calligraphic character generated is in the same style of the specified calligraphist and to adjust the calligraphic character generated. Our experiments show that this system is effective.  ", "authors": "Kai Yu College of Computer Science Zhejiang University Hangzhou, China, 310027 +8657187952300 stephan@zju.edu.cn Jiangqin Wu* College of Computer Science Zhejiang University Hangzhou, China, 310027 +8657187951225 wujq@zju.edu.cn Yueting Zhuang College of Computer Science Zhejiang University Hangzhou, China, 310027 +8657187951225 yzhuang@zju.edu.cn   ", "categories": " I.3.m [Computer Graphics]: Miscellaneous J.5 [Computer Application]: Arts and Humanities 每 fine arts General Terms Design, Experimentation, Verification. ", "id": "09_p145", "keywords": " Style-consistency calligraphy synthesis, Structure determination, Style evaluation model (SEM) ", "title": " Style-Consistency Calligraphy Synthesis System in Digital Library\n"}, "09_p153": {"abstract": " ※Data fusion§ refers to the problem in information retrieval (IR) where several lists of documents ranked against a query are to be merged into a single ranked list for presentation to a user. Data fusion is also known as ※metasearch.§ In a dig- ital library setting data fusion may support operations such as federated search based on multiple repository represen- tations. This paper presents a novel approach to the fusion problem: generative model-based Metasearch (GeM). We suggest viewing the appearance of documents in a return set as the outcome of a probabilistic process; some documents are likely to occur in the model, while others are unlikely. Using Bayesian parameter estimation to fit a multinomial distribution based on the return sets to be merged, GeM achieves a final ranking by listing documents in decreasing probability of generation under the induced model. We also introduce what we call ※the impatient reader§ approach to normalizing document ranks in service to the fusion opera- tion. We report results from several experiments on TREC data suggesting that GeM, informed with impatient reader document scores, operates at state-of-the-art levels of effec- tiveness. ", "authors": "Miles Efron School of Information University of Texas 1 University Station D7000 Austin, TX 78712 miles@ischool.utexas.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.7 [Digital Libraries]: Systems Issues General Terms Algorithms, Experimentation, Performance ", "id": "09_p153", "keywords": " Information Retrieval, Digital Libraries, Metasearch, Data Fusion, Probabilistic Models, Generative Models ", "title": "Generative Model-Based MetaSearch for Data Fusion in Information Retrieval\n"}, "09_p163": {"abstract": " The EnTag (Enhanced Tagging for Discovery) project investigated the effect on indexing and retrieval when using only social tagging versus when using social tagging in combination with suggestions from a controlled vocabulary. Two different contexts were explored: tagging by readers of a digital collection and tagging by authors in an institutional repository; also two different controlled vocabularies were examined, Dewey Decimal Classification and ACM Computing Classification Scheme. For each context a separate demonstrator was developed and a user study conducted. The results showed the importance of controlled vocabulary suggestions for both indexing and retrieval: to help produce ideas of tags to use, to make it easier to find focus for the tagging, as well as to ensure consistency and increase the number of access points in retrieval. The value and usefulness of the suggestions proved to be dependent on the quality of the suggestions, both in terms of conceptual relevance to the user and in appropriateness of the terminology. The participants themselves could also see the advantages of controlled vocabulary terms for retrieval if the terms used were from an authoritative source.  ", "authors": "Koraljka Golub UKOLN, University of Bath  BA2 7AY  Bath, United Kingdom  +44 (0)1225 383691 k.golub@ukoln.ac.uk Catherine Jones, Brian Matthews,  Bart\u0001omiej Puzo\u0003 STFC Rutherford Appleton Laboratory  OX11 0QX  Chilton, Didcot, United Kingdom +44 (0)1235 446648 {catherine.jones,brian.matthews}@stfc.ac.uk Jim Moon, Douglas Tudhope Faculty of Advanced Technology,  University of Glamorgan CF37 1DL Pontypridd, United Kingdom +44 (0)1443 482271 {jnjmoon,dstudhope @glam.ac.uk} Marianne Lykke Nielsen Royal School of Library and Information Science Fredrik Bajers Vej 7K  9220 Aalborg ?st, Denmark  +45 (0)98 157922 mln@db.dk   ", "categories": "  H.3.1 [INFORMATION STORAGE AND RETRIEVAL]: Content Analysis and Indexing 每 indexing methods, thesauruses.  H.3.3 [INFORMATION STORAGE AND RETRIEVAL]: Information Search and Retrieval H.3.7 [INFORMATION STORAGE AND RETRIEVAL]: Digital Libraries General Terms Design, Experimentation, Performance. ", "id": "09_p163", "keywords": " Social tagging, folksonomies, subject indexing, controlled vocabularies, Dewey Decimal Classification, ACM Computing Classification Scheme, Intute, digital collection, institutional repository, retrieval. ", "title": "EnTag: Enhancing Social Tagging for Discovery \n"}, "09_p173": {"abstract": " Book reviews contributed by readers in social sites contain valuable information on books＊ content, style and merit, many informative words in which can be used to enrich metadata of books in China-Us Million Book Digital Li- brary. In this paper, we present a system for review-oriented metadata enrichment and propose an Book-Centric Diverse Random Walk algorithm on a four-partite graph contain- ing three kinds of relations among authors, books, reviews and words, in order to produce highly relevant as well as diverse keywords for a book. Experimental results of a user study show that our approach significantly outperforms other methods in terms of relevance and diversity. The metadata generated by our approach also has a large over- lap with popular social tags and brief introductions from DouBan for books in the coverage experiments. ", "authors": "Liang Zhang College of Computer Science Zhejiang University Hangzhou, China tensor.zhang@gmail.com Jiangqin Wu College of Computer Science Zhejiang University Hangzhou, China wujq@zju.edu.cn Yueting Zhuang College of Computer Science Zhejiang University Hangzhou, China yzhuang@zju.edu.cn Yin Zhang College of Computer Science Zhejiang University Hangzhou, China zhangyin98@zju.edu.cn Chenxing Yang College of Computer Science Zhejiang University Hangzhou, China chenxing.yang@gmail.com ", "categories": " H.3.1 [Content Analysis and Indexing]: Abstracting methods; H.3.3 [Information Search and Retrieval]: In- formation filtering; H.3.7 [Digital Libraries]: System Is- sues General Terms Algorithms, Experimentation ", "id": "09_p173", "keywords": " Book Review, Graph-based Scoring, Metadata, Metadata Enrichment, Digital Libraries, Diversity, Keyword Extrac- tion ", "title": "Review-Oriented MetaData Enrichment: A Case Study\n"}, "09_p183": {"abstract": " Due to temporary access restrictions, embargoed data can- not be refreshed to unlimited parties during the embargo time interval. A solution to mitigate the risk of data loss has been developed that uses a data dissemination frame- work, the Timed-Locked Embargo Framework (TLEF), that allows data refreshing of encrypted instances of embargoed content in an open, unrestricted scholarly community. TLEF exploits implementations of existing technologies to ※time- lock§ data using timed-release cryptology so that TLEF can be deployed as digital resources encoded in a complex ob- ject format suitable for metadata harvesting. The frame- work successfully demonstrates dynamic record identifica- tion, time-lock puzzle encryption, encapsulation and dissem- ination as XML documents. We implement TLEF and pro- vide a quantitative analysis of its successful data harvest of time-locked embargoed data with minimum time overhead without compromising data security and integrity. ", "authors": "Rabia Haq Department of Computer Science Old Dominion University Norfolk, VA, 23529 rhaq@cs.odu.edu Michael L. Nelson Department of Computer Science Old Dominion University Norfolk, VA, 23529 mln@cs.odu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: [Digital Li- braries] General Terms Algorithms, Measurement, Design, Performance ", "id": "09_p183", "keywords": " Repositories, Time Lock, Timed Release, Cryptography ", "title": "Using Timed-Release Cryptography to Mitigate the Preservation Risk of Embargo Periods\n"}, "09_p193": {"abstract": " Assessing the quality of scientific conferences is an important and useful service that can be provided by digital libraries and similar systems. This is specially true for fields such as Computer Science and Electric Engineering, where con- ference publications are crucial. However, the majority of the existing approaches for assessing the quality of publica- tion venues has been proposed for journals. In this paper, we characterize a large number of features that can be used as criteria to assess the quality of scientific conferences and study how these several features can be automatically com- bined by means of machine learning techniques to effectively perform this task. Within the features studied are citations, submission and acceptance rates, tradition of the confer- ence, and reputation of the program committee members. Among our several findings, we can cite that: (1) separat- ing high quality conferences from medium and low quality ones can be performed quite effectively, but separating the last two types is a much harder task; and (2) citation fea- tures followed by those associated with the tradition of the conference are the most important ones for the task. ", "authors": "Waister Silva Martins, Marcos Andr谷 Gon?alves, Alberto H. F. Laender, Gisele L. Pappa Computer Science Department Federal University of Minas Gerais 31270-901 Belo Horizonte, Brazil {waister,mgoncalv,laender,glpappa}@dcc.ufmg.br ", "categories": " H.4 [Information Systems Applications]: Miscellaneous General Terms Algorithms, Experimentation, Measurement ", "id": "09_p193", "keywords": " Machine Learning, Classification, Digital Library, Confer- ence Assessment ", "title": "Learning to Assess the Quality of Scientific Conferences: A Case Study in Computer Science\n"}, "09_p203": {"abstract": " A recommender system is useful for a digital library to sug- gest the books that are likely preferred by a user. Most rec- ommender systems using collaborative filtering approaches leverage the explicit user ratings to make personalized rec- ommendations. However, many users are reluctant to pro- vide explicit ratings, so ratings-oriented recommender sys- tems do not work well. In this paper, we present a recom- mender system for CADAL digital library, namely CARES, which makes recommendations using a ranking-oriented col- laborative filtering approach based on users＊ access logs, avoiding the problem of the lack of user ratings. Our ap- proach employs mean AP correlation coefficients for com- puting similarities among users＊ implicit preference models and a random walk based algorithm for generating a book ranking personalized for the individual. Experimental re- sults on real access logs from the CADAL web site show the effectiveness of our system and the impact of different values of parameters on the recommendation performance. ", "authors": "Chenxing Yang College of Computer Science Zhejiang University Hangzhou, Zhejiang, China chenxing.yang@gmail.com Baogang Wei College of Computer Science Zhejiang University Hangzhou, Zhejiang, China wbg@zju.edu.cn Jiangqin Wu College of Computer Science Zhejiang University Hangzhou, Zhejiang, China wujq@zju.edu.cn Yin Zhang College of Computer Science Zhejiang University Hangzhou, Zhejiang, China zhangyin98@zju.edu.cn Liang Zhang College of Computer Science Zhejiang University Hangzhou, Zhejiang, China tensor.zhang@gmail.com ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering; H.3.7 [Digital Libraries]: System Issues General Terms Experimentation ", "id": "09_p203", "keywords": " Collaborative Filtering, Recommendation System, Digital Library ", "title": "CARES: A Ranking-Oriented CADAL Recommender System\n"}, "09_p213": {"abstract": " Recommender systems have demonstrated commercial success in multiple industries. In digital libraries they have the potential to be used as a support tool for traditional information retrieval functions. Among the major recommendation algorithms, the successful collaborative filtering (CF) methods explore the use of user-item interactions to infer user interests. Based on the finding that transitive user-item associations can alleviate the data sparsity problem in CF, multiple heuristic algorithms were designed to take advantage of the user-item interaction networks with both direct and indirect interactions. However, the use of such graph representation was still limited in learning-based algorithms. In this paper, we propose a graph kernel-based recommendation framework. For each user-item pair, we inspect its associative interaction graph (AIG) that contains the users, items, and interactions n steps away from the pair. We design a novel graph kernel to capture the AIG structures and use them to predict possible user-item interactions. The framework demonstrates improved performance on an online bookstore dataset, especially when a large number of suggestions are needed.  ", "authors": "Xin Li Department of Information Systems,  City University of Hong Kong  83 Tat Chee Avenue, Kowloon Tong, Hong Kong  xinli.is@acm.org Hsinchun Chen Department of Management Information Systems, University of Arizona  1130 East Helen St., Rm. 430, Tucson, AZ, USA hchen@eller.arizona.edu  ", "categories": " H.1.2 [Information Systems]: User/machine systems每 Human information processing; H.3.3 [Information Search and Retrieval]: Information Search and Retrieval 每 Retrieval models General Terms Algorithms, Design, Experimentation. ", "id": "09_p213", "keywords": " Recommender system, Kernel methods, Collaborative filtering. ", "title": "Recommendation as Link Prediction: A Graph Kernel-based Machine Learning Approach\n"}, "09_p217": {"abstract": " Interactive Query Expansion (IQE) presents suggested terms to the user during their search to enable better Information Retrieval (IR). However, IQE terms are poorly used, and tend to lack information meaningful to the user. The lack of cognitive and functional support during query refinement is a well documented problem, and despite the work carried out, it is still an under researched area. This stagnation in progress has been partly due to the long held belief that users are able to make good IQE term selections, and that the de facto way IQE terms are presented is effective. In this paper, we introduce a novel method to improve the presenta- tion of IQE terms by providing supplementary information alongside them. We describe a user study that compared our novel polyrepresentational approach to IQE against a con- ventional IQE system and a baseline system. Our findings have shown that a polyrepresentational approach to IQE can address the ambiguity and uncertainty surrounding IQE, and improve the perceived usefulness of the terms. ", "authors": "Abdigani Diriye? Ann Blandford? Anastasios Tombros? ?University College London Interaction Centre, University College London, UK ?Department of Computer Science, Queen Mary University London, UK {a.diriye, a.blandford}@ucl.ac.uk, tassos@dcs.qmul.ac.uk ", "categories": " H.3.3 [Information Storage and Retrieval]: Query For- mulation, Relevance Feedback General Terms Experimentation, Human Factors ", "id": "09_p217", "keywords": " Interactive Query Expansion, Query Formulation ", "title": "A Polyrepresentational Approach to Interactive Query Expansion\n"}, "09_p221": {"abstract": " With the rise of community-generated web content, the need for automatic characterization of resource quality has grown, particularly in the realm of educational digital libraries. We demonstrate how identifying concrete factors of quality for web-based educational resources can make machine learning approaches to automating quality characterization tractable. Using data from several previous studies of quality, we gath- ered a set of key dimensions and indicators of quality that were commonly identified by educators. We then performed a mixed-method study of digital library curation experts, showing that our characterization of quality captured the subjective processes used by the experts when assessing re- source quality for classroom use. Using key indicators of quality selected from a statistical analysis of our expert study data, we developed a set of annotation guidelines and annotated a corpus of 1000 digital resources for the pres- ence or absence of these key quality indicators. Agreement among annotators was high, and initial machine learning models trained from this corpus were able to identify some indicators of quality with as much as an 18% improvement over the baseline. ", "authors": "Steven Bethard University of Colorado 594 UCB Boulder, CO, USA steven.bethard@ colorado.edu Philipp Wetzler University of Colorado 594 UCB Boulder, CO, USA philipp.wetzler@ colorado.edu Kirsten Butcher University of Utah 1705 Campus Center Dr Salt Lake City, UT, USA kirsten.butcher@ utah.edu James H. Martin University of Colorado 430 UCB Boulder, CO, USA james.martin@ colorado.edu Tamara Sumner University of Colorado 594 UCB Boulder, CO, USA tamara.sumner@ colorado.edu ", "categories": " H.3.6 [Information Systems]: Library Automation; H.3.7 [Information Systems]: Digital Libraries〞Standards, User issues; I.2.7 [Computing Methodologies]: Natu- ral Language Processing〞Text analysis; I.5.4 [Computing Methodologies]: Applications〞Text processing General Terms Human Factors, Algorithms ", "id": "09_p221", "keywords": " Quality, learning resource, machine learning, educational digital library ", "title": "Automatically Characterizing Resource Quality for Educational Digital Libraries\n"}, "09_p231": {"abstract": " Individual optical character recognition (OCR) engines vary in the types of errors they commit in recognizing text, par- ticularly poor quality text. By aligning the output of mul- tiple OCR engines and taking advantage of the differences between them, the error rate based on the aligned lattice of recognized words is significantly lower than the individ- ual OCR word error rates. This lattice error rate consti- tutes a lower bound among aligned alternatives from the OCR output. Results from a collection of poor quality mid- twentieth century typewritten documents demonstrate an average reduction of 55.0% in the error rate of the lattice of alternatives and a realized word error rate (WER) reduc- tion of 35.8% in a dictionary-based selection process. As an important precursor, an innovative admissible heuristic for the A* algorithm is developed, which results in a significant reduction in state space exploration to identify all optimal alignments of the OCR text output, a necessary step toward the construction of the word hypothesis lattice. On average 0.0079% of the state space is explored to identify all optimal alignments of the documents. ", "authors": "William B. Lund Harold B. Lee Library and the Department of Computer Science Brigham Young University 2060 Lee Library Provo, Utah 84602, USA bill_lund@byu.edu Eric K. Ringger Department of Computer Science Brigham Young University 3368 Talmage Building Provo, Utah 84602, USA ringger@cs.byu.edu ", "categories": " G.2.2 [Discrete Mathematics]: Graph Theory〞Path and circuit problems; I.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search〞Graph and tree search strategies; I.4.9 [Image Processing and Computer Vi- sion]: Applications; I.7.5 [Document and Text Process- ing]: Document Capture〞Optical character recognition (OCR) General Terms Algorithms, Experimentation ", "id": "09_p231", "keywords": " A* algorithm, text alignment, OCR error rate reduction ", "title": "Improving Optical Character Recognition through Efficient Multiple System Alignment\n"}, "09_p241": {"abstract": " User-contributed tags have shown promise as a means of indexing multimedia collections by harnessing the combined efforts and enthusiasm of online communities. But tags are only one way of describing multimedia items. In this study, I compare the characteristics of public tags with other forms of descriptive metadata〞titles and narrative captions〞that users have assigned to a collection of very similar images gathered from the photo- sharing service Flickr. The study shows that tags converge on different descriptions than the other forms of metadata do, and that narrative metadata may be more effective than tags for capturing certain aspects of images that may influence their subsequent retrieval and use. The study also examines how photographers use peoples＊ names to personalize the different types of metadata and how they tell stories across short sequences of images. The study results are then brought to bear on design recommendations for user tagging tools and automated tagging algorithms and on using photo sharing sites as de facto art and architecture resources.  ", "authors": " Catherine C. Marshall Microsoft Research, Silicon Valley 1065 La Avenida Mountain View, CA 94043 +1 650 693 1308 cathymar@microsoft.com     ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 system issues, user issues General Terms Documentation, Design, Human Factors. ", "id": "09_p241", "keywords": " Metadata, tags, study, collaborative information management. ", "title": "No Bull, No Spin: A comparison of tags with other forms of user metadata \n"}, "09_p251": {"abstract": " Web users are spending more of their time and creative en- ergies within online social networking systems. While many of these networks allow users to export their personal data or expose themselves to third-party web archiving, some do not. Facebook, one of the most popular social networking websites, is one example of a ※walled garden§ where users＊ activities are trapped. We examine a variety of techniques for extracting users＊ activities from Facebook (and by ex- tension, other social networking systems) for the personal archive and for the third-party archiver. Our framework could be applied to any walled garden where personal user data is being locked. ", "authors": "Frank McCown Harding University Computer Science Dept Searcy, Arkansas, USA 72149 fmccown@harding.edu Michael L. Nelson Old Dominion University Computer Science Dept Norfolk, Virginia, USA 23529 mln@cs.odu.edu ", "categories": " H.3.5 [Information Storage and Retrieval]: Online In- formation Services〞Web-based services; H.3.7 [Information Storage and Retrieval]: Digital Libraries〞Collection General Terms Design, Experimentation, Management, Human Factors ", "id": "09_p251", "keywords": " digital preservation, social networks, personal archiving ", "title": "What Happens When Facebook is Gone?\n"}, "09_p255": {"abstract": " Journals, letters, and other writings are of great value to historians and those who research their own family history; however, it can be difficult to find writings by specific peo- ple, and even harder to find what others wrote about them. We present a prototype web-based system that enables users to discover information about historical people (including their own ancestors) by linking digital library content to unique PersonIDs from a genealogical database. Users can contribute content such as scanned journals or information about where items can be found. They can also transcribe content and tag it with PersonIDs to identify who it is about. Additional features provide tools for users to explore histor- ical contexts and relationships. These include the ability to tag places and to create a historical social network by spec- ifying non-family relationships or by using a mechanism we call rosters to imply participation in some group or event. ", "authors": "Douglas J. Kennard Brigham Young University Provo, Utah, U.S.A. kennard@cs.byu.edu William B. Lund Brigham Young University Provo, Utah, U.S.A. bill_lund@byu.edu Bryan S. Morse Brigham Young University Provo, Utah, U.S.A. morse@cs.byu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries〞Standards, Systems issues, User issues General Terms Design, Experimentation, Human Factors ", "id": "09_p255", "keywords": "", "title": "Improving Historical Research by Linking Digital Library Information to a Global Genealogical Database\n"}, "09_p259": {"abstract": " This paper discusses new work to represent, in a digital li- brary of classical sources, authors whose works themselves are lost and who survive only where surviving authors quote, paraphrase or allude to them. It describes initial works from a digital collection of such fragmentary authors designed not only to capture but to extend the ontologies that traditional scholarship has developed over generations: the aim is rep- resenting every nuance of print conventions while using the capabilities of digital libraries to extend our ability to iden- tify fragments, to represent what we have identified, and to render the results of that work intellectually and physically more accessible than was possible in print culture. ", "authors": "Monica Berti, Matteo Romanello, Alison Babeu, and Gregory Crane The Perseus Project Medford, MA, USA monica.berti@tufts.edu, matteo.romanello@tufts.edu, alison.jones@tufts.edu, gregory.crane@tufts.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries〞collection, dissemination, standards General Terms Documentation, Performance, Standardization, Languages. ", "id": "09_p259", "keywords": " Digital Libraries, Fragmentary Authors, Greek Fragmentary Historians, XML, TEI P5 Guidelines. ", "title": "Collecting Fragmentary Authors in a Digital Library\n"}, "09_p263": {"abstract": " In this paper we present an application of image registration techniques to the specific domain of manuscript images. We show the application of this technique to images of the Vene- tus A, a 10th century manuscript of Homer＊s Iliad. The same algorithm is used to register images of the MS across time (including photographs separated by over a century), as well as across imaging modalities. ", "authors": "Ryan Baumann Center for Visualization & Virtual Environments University of Kentucky Lexington, KY, USA ryan.baumann@uky.edu W. Brent Seales Center for Visualization & Virtual Environments University of Kentucky Lexington, KY, USA seales@uky.edu ", "categories": " I.4.3 [Image Processing and Computer Vision]: En- hancement〞Registration General Terms Algorithms ", "id": "09_p263", "keywords": " Image registration, manuscript restoration, image warping, multispectral imaging ", "title": "Robust Registration of Manuscript Images\n"}, "09_p267": {"abstract": " The utility of an enterprise search system is determined by three key players: the information retrieval (IR) system (the search engine), the enterprise users, and the service provider who delivers the tailored IR service to its designated enterprise users. Currently, evaluations of enterprise search have been focused largely on the IR system effectiveness and efficiency, only a relatively small amount of effort on the user＊s involvement, and hardly any effort on the service provider＊s role. This paper will investigate the role of the service provider. We propose a method that evaluates the cost and benefit for a service provider of using a mediated search engine 每 in particular, where domain experts intervene on the ranking of the search results from a search engine. We test our cost and benefit evaluation method in a case study and conduct user experiments to demonstrate it. Our study shows that: 1) by making use of domain experts＊ relevance assessments in search result ranking, the precision and the discount cumulated gain of ranked lists have been improved significantly (144% and 40% respectively); 2) the service provider gains substantial return on investment and higher search success rate by investing in domain experts＊ relevance assessments; and 3) the cost and benefit evaluation also indicates the type of queries to be selected from a query log for evaluating an enterprise search engine.  ", "authors": " Mingfang Wu   James A. Thom    Andrew Turpin Ross Wilkinson School of Computer Science & Information Technology RMIT University, Melbourne, Australia  {mingfang.wu, james.thom, andrew.turpin}@rmit.edu.au Australia National Data Service Melbourne, Australia  ross.wilkinson@ands.org.au ", "categories": " H 1.1 [Systems and Information Theory]: Value of Information H.3.3 [Information Search and Retrieval]: Relevance Feedback H.3.5 [Online Information Services]: Web-based Services  General Terms Measurement, Performance, Human Factors, Economics ", "id": "09_p267", "keywords": " Information Retrieval, Enterprise Search, Relevance Feedback, Evaluation, Mediated Search, Cost and Benefit Analysis ", "title": "Cost and Benefit Analysis of Mediated Enterprise Search \n"}, "09_p277": {"abstract": " In addition to the frequency of terms in a document collec- tion, the distribution of terms plays an important role in determining the relevance of documents for a given search query. In this paper, term distribution analysis using Fourier series expansion as a novel approach for calculating an ab- stract representation of term positions in a document cor- pus is introduced. Based on this approach, two methods for improving the evaluation of document relevance are pro- posed: (a) a function-based ranking optimization represent- ing a user defined document region, and (b) a query expan- sion technique based on overlapping the term distributions in the top-ranked documents. Experimental results demon- strate the effectiveness of the proposed approach in provid- ing new possibilities for optimizing the retrieval process. ", "authors": "Patricio Galeas Dept. of Math. & Comp. Sci. University of Marburg Hans-Meerwein-Str. 3 D-35032 Marburg, Germany galeas@informatik.uni- marburg.de Ralph Kretschmer Kretschmer Software Zum Bernstein 3 D-57076 Siegen, Germany kretschmer@kretschmer- software.com Bernd Freisleben Dept. of Math. & Comp. Sci. University of Marburg Hans-Meerwein-Str. 3 D-35032 Marburg, Germany freisleb@informatik.uni- marburg.de ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval models General Terms Algorithms, Experimentation ", "id": "09_p277", "keywords": " Fourier series, query expansion, ranked retrieval, term dis- tribution ", "title": "Document Relevance Assessment via Term Distribution Analysis Using Fourier Series Expansion\n"}, "09_p285": {"abstract": " Web 2.0 enables information sharing, collaboration among users and most notably supports active participation and creativity of the users. As a result, a huge amount of manually created metadata de- scribing all kinds of resources is now available. Such semantically rich user generated annotations are especially valuable for digital libraries covering multimedia resources such as music, where these metadata enable retrieval relying not only on content-based (low level) features, but also on the textual descriptions represented by tags. However, if we analyze the annotations users generate for music tracks, we find them heavily biased towards genre. Previous work investigating the types of user provided annotations for music tracks showed that the types of tags which would be really benefi- cial for supporting retrieval 每 usage (theme) and opinion (mood) tags 每 are often neglected by users in the annotation process. In this paper we address exactly this problem: in order to support users in tagging and to fill these gaps in the tag space, we develop algorithms for recommending mood and theme annotations. Our methods exploit the available user annotations, the lyrics of music tracks, as well as combinations of both. We also compare the re- sults for our recommended mood / theme annotations against genre and style recommendations 每 a much easier and already studied task. Besides evaluating against an expert (AllMusic.com) ground truth, we evaluate the quality of our recommended tags through a Facebook-based user study. Our results are very promising both in comparison to experts as well as users and provide interesting in- sights into possible extensions for music tagging systems to support music search. ", "authors": "Deriving Mood & Theme Annotations from User Tags Kerstin Bischoff, Claudiu S. Firan, Wolfgang Nejdl, Raluca Paiu L3S Research Center Appelstr. 4 30167 Hannover, Germany {bischoff,firan,nejdl,paiu}@L3S.de ", "categories": " H.3.2.d [Information Storage and Retrieval]: Metadata; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.5 [Information Storage and Retrieval]: Online In- formation Services〞Web-based services General Terms Algorithms, Experimentation, Human Factors, Measurement, Reli- ability ", "id": "09_p285", "keywords": " Collaborative Tagging, High-Level Music Descriptors, Mood and Theme Tag Recommendations, Metadata Enrichment ", "title": "How Do You Feel about ※Dancing Queen§?\n"}, "09_p295": {"abstract": " The old dream of a universal repository containing all the human knowledge and culture is becoming possible through the Internet and the Web. Moreover, this is happening with the direct collaborative, participation of people. Wikipedia is a great example. It is an enormous repository of infor- mation with free access and edition, created by the commu- nity in a collaborative manner. However, this large amount of information, made available democratically and virtually without any control, raises questions about its relative qual- ity. In this work we explore a significant number of qual- ity indicators, some of them proposed by us and used here for the first time, and study their capability to assess the quality of Wikipedia articles. Furthermore, we explore ma- chine learning techniques to combine these quality indicators into one single assessment judgment. Through experiments, we show that the most important quality indicators are the easiest ones to extract, namely, textual features related to length, structure and style. We were also able to determine which indicators did not contribute significantly to the qual- ity assessment. These were, coincidentally, the most com- plex features, such as those based on link analysis. Finally, we compare our combination method with state-of-the-art solution and show significant improvements in terms of ef- fective quality prediction. ", "authors": "Wikipedia Daniel Hasan Dalip, Marcos Andr谷 Gon?alves Dept of Computer Science - UFMG Belo Horizonte/MG, Brazil {hasan,mgoncalv}@dcc.ufmg.br Marco Cristo NEPCOMP 每 FUCAPI Manaus/AM, Brazil marco.cristo@fucapi.br P芍vel Calado Instituto Superior T谷cnico/ INESC-ID Porto Salvo, Portugal pavel.calado@tagus.ist.utl.pt ", "categories": " H.3.7 [Information Storage and Retrieval]: [Digital Li- braries, User Issues] General Terms Human Factors, Measurement, Experimentation ", "id": "09_p295", "keywords": " Quality Assessment, Wikipedia, Machine Learning, SVM ", "title": "Automatic Quality Assessment of Content Created Collaboratively by Web Communities: A Case Study of\n"}, "09_p305": {"abstract": " This paper reports on an adaption of the existing PopoutText and ClearText display techniques to mobile phones. It explains the design rationale for a freely available iPhone application to read books from the International Children＊s Digital Library. Through a combination of applied image processing, a zoomable user interface, and a process of working with children to develop the detailed design, we present an interface that supports clear reading of scanned picture books in multiple languages on a mobile phone. ", "authors": " Benjamin B. Bederson1,2,3,4 bederson@cs.umd.edu  Alex Quinn1,2 aq@cs.umd.edu Allison Druin1,2,3 allisond@umiacs.umd.edu  University of Maryland Human-Computer Interaction Lab 1 Computer Science Dept. 2 iSchool 3 College Park, MD 20742 Zumobi, Inc. 4 Seattle, WA 98101 www.zumobi.com     ", "categories": " H.1.2 [Models and Principles]: User/Machine Systems 每 Human factors.  General Terms Design, Human Factors. ", "id": "09_p305", "keywords": " Mobile phones, iPhone, children, readability, interface, design, books, digital libraries.  ", "title": "Designing the Reading Experience for Scanned Multi-lingual Picture Books on Mobile Phones \n"}, "09_p309": {"abstract": " Millions of people in developed countries routinely create and share digital content; but what about the billions of others in on the wrong side of what has been called the ＆global digital divide＊? This paper considers three mobile platforms to illustrate their potential in enabling rural Indian villagers to make and share digital stories. We describe our experiences in creating prototypes using mobile phones; high-end media-players; and, paper. Interaction designs are discussed along with findings from various trials within the village and elsewhere. Our approach has been to develop prototypes that can work together in an integrated fashion so that content can flow freely and in interesting ways through the village. While our work has particular relevance to those users in emerging world contexts, we see it also informing needs and practices in the developed world for user-generated content.  ", "authors": "Matt Jones & Emma Thom FIT Lab Swansea University, UK always@acm.org  David Bainbridge Computer Science University of Waikato, NZ davidb@cs.waikato.ac.nz  David Frohlich Digital World Research Centre Surrey University, UK d.frohlich@surrey.ac.uk        ", "categories": " H.5.1 Multimedia Information Systems: Audio input/output, video; H.5.2 User Interfaces: Interaction styles, evaluation/methodology. General Terms Design, Experimentation, Human Factors. ", "id": "09_p309", "keywords": " Digital-Divide, digital libraries, mobility, information ecologies, user-generated content. ", "title": "Mobility, Digital Libraries and a Rural Indian Village \n"}, "09_p313": {"abstract": " This study examined how searchers interacted with a web- based, faceted library catalog when conducting exploratory searches. It applied eye tracking, stimulated recall interviews, and direct observation to investigate important aspects of gaze behavior in a faceted search interface: what components of the interface searchers looked at, for how long, and in what order. It yielded empirical data that will be useful for both practitioners (e.g., for improving search interface designs), and researchers (e.g., to inform models of search behavior). Results of the study show that participants spent about 50 seconds per task looking at (fixating on) the results, about 25 seconds looking at the facets, and only about 6 seconds looking at the query itself. These findings suggest that facets played an important role in the exploratory search process. ", "authors": "Bill Kules1, Robert Capra2, Matthew Banta1, and Tito Sierra3 kules@cua.edu, rcapra3@unc.edu, matt.banta@gmail.com, tito_sierra@ncsu.edu 1The Catholic University of America School of Library and Information Science Washington, DC 2University of North Carolina School of Information and Library Science Chapel Hill, NC 3North Carolina State University NCSU Libraries Raleigh, NC  ", "categories": " H5.2 User Interfaces: Evaluation/methodology; H3.3 Information Search and Retrieval General Terms Experimentation, Human Factors, Measurement ", "id": "09_p313", "keywords": "", "title": "What Do Exploratory Searchers Look at in a Faceted Search Interface? \n"}, "09_p323": {"abstract": " The Open Archives Initiative 每 Object Reuse and Exchange (OAI- ORE) specifications provide a flexible set of mechanisms for transferring complex data objects between different systems. In order to serve as an exchange syntax, OAI-ORE must be able to support the import of information from localized data structures serving various communities of practice. In this paper, we examine the Metadata Encoding & Transmission Standard (METS) and the issues that arise when trying to map from a localized structural metadata schema into the OAI-ORE data model and serialization syntaxes. ", "authors": " Jerome P. McDonough Graduate School of Library & Information Science, University of Illinois at Urbana-Champaign 501 E. Daniel Street, MC-493 Champaign, IL 61820 +1 217-244-5916 jmcdonou@illinois.edu    ", "categories": " E.2 [Data Storage Representations]: Object representations General Terms Design, Standardization  ", "id": "09_p323", "keywords": " METS, OAI-ORE, structural metadata, aggregation, modeling ", "title": "Aligning METS with the OAI-ORE Data Model \n"}, "09_p331": {"abstract": " The World Wide Web has become a key source of knowl- edge pertaining to almost every walk of life. Unfortunately, much of data on the Web is highly ephemeral in nature, with more than 50-80% of content estimated to be changing within a short time. Continuing the pioneering efforts of many national (digital) libraries, organizations such as the International Internet Preservation Consortium (IIPC), the Internet Archive (IA) and the European Archive (EA) have been tirelessly working towards preserving the ever changing Web. However, while these web archiving efforts have paid sig- nificant attention towards long term preservation of Web data, they have paid little attention to developing an global- scale infrastructure for collecting, archiving, and performing historical analyzes on the collected data. Based on insights from our recent work on building text analytics for Web Archives, we propose EverLast , a scalable distributed frame- work for next generation Web archival and temporal text analytics over the archive. Our system is built on a loosely- coupled distributed architecture that can be deployed over large-scale peer-to-peer networks. In this way, we allow the integration of many archival efforts taken mainly at a na- tional level by national digital libraries. Key features of EverLast include support of time-based text search & anal- ysis and the use of human-assisted archive gathering. In this paper, we outline the overall architecture of EverLast, and present some promising preliminary results. ", "authors": "Avishek Anand Max-Planck Institute for Informatics, Saarbr邦cken, Germany aanand@mpi-inf.mpg.de Srikanta Bedathur Max-Planck Institute for Informatics, Saarbr邦cken, Germany bedathur@mpi- inf.mpg.de Klaus Berberich Max-Planck Institute for Informatics, Saarbr邦cken, Germany kberberi@mpi-inf.mpg.de Ralf Schenkel Saarland University, Saarbr邦cken, Germany schenkel@mmci.uni- saarland.de Christos Tryfonopoulos Max-Planck Institute for Informatics, Saarbr邦cken, Germany trifon@mpi-inf.mpg.de ", "categories": " H.3.1 [Content Analysis and Indexing]: Indexing meth- ods; H.3.1 [Information Storage and Retrieval]: Li- brary AutomationLarge text archives General Terms Algorithms, Design, Experimentation ", "id": "09_p331", "keywords": " Web Archives, Crawling, Indexing, Time-travel search ", "title": "EverLast: A Distributed Architecture for Preserving the Web\n"}, "09_p341": {"abstract": " In prior work we have demonstrated that search engine caches and archiving projects like the Internet Archive＊s Wayback Machine can be used to ※lazily preserve§ websites and re- construct them when they are lost. We use the term ※web repositories§ for collections of automatically refreshed and migrated content, and collectively we refer to these reposi- tories as the ※web infrastructure§. In this paper we present a framework for describing web repositories and the status of web resources in them. This includes an abstract API for web repository interaction, the concepts of deep vs. flat and light/dark/grey repositories and terminology for describing the recoverability of a web resource. Our API may serve as a foundation for future web repository interfaces. ", "authors": "Frank McCown Department of Computer Science Harding University Searcy, AR, 72149 fmccown@harding.edu Michael L. Nelson Department of Computer Science Old Dominion University Norfolk, VA, 23529 mln@cs.odu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: [Digital Li- braries] General Terms Standardization, Design ", "id": "09_p341", "keywords": " Preservation, Web Repositories, Web Resources ", "title": "A Framework for Describing Web Repositories\n"}, "09_p345": {"abstract": " Digital preservation aims at maintaining digital objects accessible over a long period of time, regardless of the challenges of organizational or technological changes or failures. In particular, data produced in e-Science domains could be reliably stored in today＊s data grids, taking advantage of the natural properties of this kind of infrastructure to support redundancy. However, to achieve reliability we must take into account failure interdependency. Taking into account the fact that correlated failures can affect multiple components and potentially cause complete loss of data, we propose a solution to evaluate redundancy strategies in the context of heterogeneous environments such as data grids. This solution is based on a simulation engine that can be used not only to support the process of designing the preservation environment and related policies, but also later on to observe and control the deployed system. ", "authors": "Gon?alo Antunes* goncalo.antunes@tagus.ist.utl.pt  Jos谷 Barateiro** jbarateiro@lnec.pt   Manuel Cabral* manuel.cabral@tagus.ist.utl.pt   Jos谷 Borbinha* jlb@ist.utl.pt  Rodrigo Rodrigues*** rodrigo.rodrigues@inesc-id.pt  *INESC-ID, Information Systems Group, Lisbon, Portugal **LNEC 每 Laborat車rio Nacional de Engenharia Civil, Lisbon, Portugal ***Max Planck Institute for Software Systems, Kaiserslautern and Saarbr邦cken, Germany   ", "categories": " H.3.7 [Digital Libraries]: Systems Issues; H.3.4 [Systems and Software]: Distributed Systems General Terms Reliability. ", "id": "09_p345", "keywords": " Digital Libraries, Digital Preservation, Dependability, Data Grids. ", "title": "Preserving Digital Data in Heterogeneous Environments \n"}, "09_p349": {"abstract": " The prevailing model for digital preservation is that archives should be similar to a ※fortress§: a large, protective infras- tructure built to defend a relatively small collection of data from attack by external forces. Such projects are a luxury, suitable only for limited collections of known importance and requiring significant institutional commitment for sus- tainability. In previous research, we have shown the web infrastructure (i.e., search engine caches, web archives) re- freshes and migrates web content in bulk as side-effects of their user-services, and these results can be mined as a use- ful, but passive preservation service. Our current research involves a number of questions resulting from removing the implicit assumption that web-based data objects must pas- sively await curatorial services: What if data objects were not tethered to repositories? What are the implications if the content were actively seeking out and injecting itself into the web infrastructure (i.e., search engine caches, web archives)? All of this leads to our primary research ques- tion: Can we create objects that preserve themselves more effectively than repositories or web infrastructure can? ", "authors": "Charles L. Cartledge Old Dominion University Department of Computer Science Norfolk, VA 23529 USA ccartled@cs.odu.edu Michael L. Nelson Old Dominion University Department of Computer Science Norfolk, VA 23529 USA mln@cs.odu.edu ", "categories": " H.3.7 [Digital Libraries]: General Terms Algorithms, Design, Experimentation ", "id": "09_p349", "keywords": "", "title": "Unsupervised Creation of Small World Networks for the Preservation of Digital Objects\n"}, "09_p353": {"abstract": "  We report on the exploratory stages of multi-university, multi- research-site, multi-year effort to investigate and compare data practices in multiple cyberinfrastructure projects and their emerging virtual organizations. Our long-term goal is to understand the data practices and data management requirements of virtual organizations and their implications for the design and development of data digital libraries. We have constructed our own virtual organization as a participant-observer approach to the research. Results to date suggest that collaborative technologies are emergent and that defining and scoping the data products of collaborations continues to be problematic.  ", "authors": "Christine L. Borgman University of California, Los Angeles  +1(310)825-6164 borgman@gseis.ucla.edu Geoffrey C. Bowker Santa Clara University Santa Clara, CA +1(408)551-6058 gbowker@scu.edu Thomas A. Finholt University of Michigan Ann Arbor, MI +1(734)647-6131 finholt@umich.edu Jillian C. Wallis University of California, Los Angeles  +1(301)206-0029 jwallisi@ucla.edu   ", "categories": " H.5.3 [Group and Organization Interfaces]: Computer- supported cooperative work. General Terms Management, Documentation, Design, Standardization. ", "id": "09_p353", "keywords": " Scientific data, sensor networks, cyberinfrastructure, collaborative work. ", "title": "Towards a Virtual Organization for Data Cyberinfrastructure\n"}, "10_p001": {"abstract": " As Digital Libraries (DL) become more aligned with the web architecture, their functional components need to be fundamentally rethought in terms of URIs and HTTP.  Annotation, a core scholarly activity enabled by many DL solutions, exhibits a clearly unacceptable characteristic when existing models are applied to the web: due to the representations of web resources changing over time, an annotation made about a web resource today may no longer be relevant to the representation that is served from that same resource tomorrow. We assume the existence of archived versions of resources, and combine the temporal features of the emerging Open Annotation data model with the capability offered by the Memento framework that allows seamless navigation from the URI of a resource to archived versions of that resource, and arrive at a solution that provides guarantees regarding the persistence of web annotations over time. More specifically, we provide theoretical solutions and proof-of-concept experimental evaluations for two problems: reconstructing an existing annotation so that the correct archived version is displayed for all resources involved in the annotation, and retrieving all annotations that involve a given archived version of a web resource.  ", "authors": "Robert Sanderson Los Alamos National Laboratory Los Alamos NM 87544, USA +1 (505) 665-5804 rsanderson@lanl.gov Herbert Van de Sompel Los Alamos National Laboratory Los Alamos NM 87544, USA +1 (505) 667-1267 herbertv@lanl.gov  ", "categories": " H.5.4 [Information Interfaces and Presentation]: Hypertext/ Hypermedia 每 Architectures, Navigation.  General Terms Design, Reliability ", "id": "10_p001", "keywords": " Annotation, Persistence, Digital Preservation, Web Architecture  ", "title": "Making Web Annotations Persistent over Time \n"}, "10_p011": {"abstract": " We present here a method for automatically projecting struc- tural information across translations, including canonical ci- tation structure (such as chapters and sections), speaker in- formation, quotations, markup for people and places, and any other element in TEI-compliant XML that delimits spans of text that are linguistically symmetrical in two languages. We evaluate this technique on two datasets, one contain- ing perfectly transcribed texts and one containing error- ful OCR, and achieve an accuracy rate of 88.2% projecting 13,023 XML tags from source documents to their transcribed translations, with an 83.6% accuracy rate when projecting to texts containing uncorrected OCR. This approach has the potential to allow a highly granular multilingual digital library to be bootstrapped by applying the knowledge con- tained in a small, heavily curated collection to a much larger but unstructured one. ", "authors": "David Bamman The Perseus Project Tufts University Medford, MA david.bamman@tufts.edu Alison Babeu The Perseus Project Tufts University Medford, MA alison.jones@tufts.edu Gregory Crane The Perseus Project Tufts University Medford, MA gregory.crane@tufts.edu ", "categories": " H.3.7 [Information Systems: Information Storage and Retrieval]: digital libraries General Terms Design, Documentation, Performance ", "id": "10_p011", "keywords": " Annotation projection, multilingual alignment, knowledge transfer ", "title": "Transferring Structural Markup Across Translations Using Multilingual Alignment and Projection\n"}, "10_p021": {"abstract": " Digitizing legacy documents and marking them up with XML is important for many scientific domains. However, creating com- prehensive semantic markup of high quality is challenging. Re- spective processes consist of many steps, with automated markup generation and intermediate manual correction. These corrections are extremely laborious. To reduce this effort, this paper makes two contributions: First, it proposes ProcessTron, a lightweight markup-process-control mechanism. ProcessTron assists users in two ways: It ensures that the steps are executed in the appropriate order, and it points the user to possible errors during manual cor- rection. Second, ProcessTron has been deployed in real-world projects, and this paper reports on our experiences. A core obser- vation is that ProcessTron more than halves the time users need to mark up a document. Results from laboratory experiments, which we have conducted as well, confirm this finding. ", "authors": "Guido Sautter KIT Am Fasanengarten 5 76128 Karlsruhe guido.sautter@kit.edu Klemens B?hm KIT Am Fasanengarten 5 76128 Karlsruhe klemens.boehm@kit.edu Conny K邦hne KIT Am Fasanengarten 5 76128 Karlsruhe conny.kuehne@kit.edu Tobias Math?? KIT Am Fasanengarten 5 76128 Karlsruhe   ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing 每 Linguistic processing. General Terms Algorithms, Experimentation, Human Factors, Languages. ", "id": "10_p021", "keywords": " Semantic XML Markup, Data-driven Markup Process Control. ", "title": "ProcessTron: Efficient Semi-Automated Markup Generation for Scientific Documents \n"}, "10_p029": {"abstract": " We examine the effect of modeling a researcher＊s past works in recommending scholarly papers to the researcher. Our hypothesis is that an author＊s published works constitute a clean signal of the latent interests of a researcher. A key part of our model is to en- hance the profile derived directly from past works with information coming from the past works＊ referenced papers as well as papers that cite the work. In our experiments, we differentiate between junior researchers that have only published one paper and senior researchers that have multiple publications. We show that filter- ing these sources of information is advantageous 每 when we ad- ditionally prune noisy citations, referenced papers and publication history, we achieve statistically significant higher levels of recom- mendation accuracy. ", "authors": "Kazunari Sugiyama National University of Singapore Computing 1, 13 Computing Drive, Singapore 117417 sugiyama@comp.nus.edu.sg Min-Yen Kan National University of Singapore Computing 1, 13 Computing Drive, Singapore 117417 kanmy@comp.nus.edu.sg ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering, Search process; H.3.7 [Digital Libraries]: Systems issues, User issues General Terms Algorithms, Experimentation, Human factors, Performance ", "id": "10_p029", "keywords": " Digital library, Information retrieval, Recommendation, User mod- eling ", "title": "Scholarly Paper Recommendation via User＊s Recent Research Interests \n"}, "10_p039": {"abstract": " Name ambiguity in the context of bibliographic citation reco- rds is a hard problem that affects the quality of services and content in digital libraries and similar systems. Supervised methods that exploit training examples in order to distin- guish ambiguous author names are among the most effective solutions for the problem, but they require skilled human annotators in a laborious and continuous process of manu- ally labeling citations in order to provide enough training examples. Thus, addressing the issues of (i) automatic ac- quisition of examples and (ii) highly effective disambiguation even when only few examples are available, are the need of the hour for such systems. In this paper, we propose a novel two-step disambiguation method, SAND (Self-training As- sociative Name Disambiguator), that deals with these two issues. The first step eliminates the need of any manual labeling effort by automatically acquiring examples using a clustering method that groups citation records based on the similarity among coauthor names. The second step uses a supervised disambiguation method that is able to detect un- seen authors not included in any of the given training exam- ples. Experiments conducted with standard public collec- tions, using the minimum set of attributes present in a cita- tion (i.e., author names, work title and publication venue), demonstrated that our proposed method outperforms rep- resentative unsupervised disambiguation methods that ex- ploit similarities between citation records and is as effective as, and in some cases superior to, supervised ones, without manually labeling any training example. ", "authors": "Anderson A. Ferreira Adriano Veloso Marcos Andr谷 Gon?alves Alberto H. F. Laender Departamento de Ci那ncia da Computa??o Universidade Federal de Minas Gerais 31270-901 Belo Horizonte, Brazil {ferreira, adrianov, mgoncalv, laender}@dcc.ufmg.br ", "categories": " H.3.3 [Information Search and Retrieval]: Information Retrieval; I.5.2 [Pattern Recognition]: Classifier design and evaluation General Terms Algorithms, Experimentation ", "id": "10_p039", "keywords": " Name Disambiguation, Bibliographic Citations ", "title": "Effective Self-Training Author Name Disambiguation in Scholarly Digital Libraries\n"}, "10_p049": {"abstract": " The question of citation behavior has always intrigued scientists from various disciplines. While general citation patterns have been widely studied in the literature we develop the notion of citation projection graphs by investigating the citations among the publi- cations that a given paper cites. We investigate how patterns of citations vary between various scientific disciplines and how such patterns reflect the scientific impact of the paper. We find that id- iosyncratic citation patterns are characteristic for low impact pa- pers; while narrow, discipline-focused citation patterns are com- mon for medium impact papers. Our results show that crossing- community, or bridging citation patters are high risk and high re- ward since such patterns are characteristic for both low and high impact papers. Last, we observe that recently citation networks are trending toward more bridging and interdisciplinary forms. ", "authors": "Xiaolin Shi Stanford University Stanford, CA 94305 shixl@stanford.edu Jure Leskovec Stanford University Stanford, CA 94305 jure@cs.stanford.edu Daniel A. McFarland Stanford University Stanford, CA 94305 dmcfarla@stanford.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries; H.4.0 [Information Systems Applications]: General General Terms Experimentation, Measurement. ", "id": "10_p049", "keywords": " Citation projection, citation networks, publication impact ", "title": "Citing for High Impact\n"}, "10_p059": {"abstract": " Missing web pages (pages that return the 404 ※Page Not Found§error) are part of the browsing experience. The man- ual use of search engines to rediscover missing pages can be frustrating and unsuccessful. We compare four automated methods for rediscovering web pages. We extract the page＊s title, generate the page＊s lexical signature (LS), obtain the page＊s tags from the bookmarking website delicious.com and generate a LS from the page＊s link neighborhood. We use the output of all methods to query Internet search en- gines and analyze their retrieval performance. Our results show that both LSs and titles perform fairly well with over 60% URIs returned top ranked from Yahoo!. However, the combination of methods improves the retrieval performance. Considering the complexity of the LS generation, querying the title first and in case of insufficient results querying the LSs second is the preferable setup. This combination ac- counts for more than 75% top ranked URIs. ", "authors": "Martin Klein Department of Computer Science Old Dominion University Norfolk, VA, 23529 mklein@cs.odu.edu Michael L. Nelson Department of Computer Science Old Dominion University Norfolk, VA, 23529 mln@cs.odu.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Measurement, Performance, Design, Algorithms ", "id": "10_p059", "keywords": " Web Page Discovery, Digital Preservation, Search Engines ", "title": "Evaluating Methods to Rediscover Missing Web Pages from the Web Infrastructure\n"}, "10_p069": {"abstract": " Personalization of information retrieval tailors search towards individual users to meet their particular information needs by taking into account information about users and their contexts, often through implicit sources of evidence such as user behaviors. Task types have been shown to influence search behaviors including usefulness judgments. This paper reports on an investigation of user behaviors associated with different task types. Twenty-two undergraduate journalism students participated in a controlled lab experiment, each searching on four tasks which varied on four dimensions: complexity, task product, task goal and task level. Results indicate regular differences associated with different task characteristics in several search behaviors, including task completion time, decision time (the time taken to decide whether a document is useful or not), and eye fixations, etc. We suggest these behaviors can be used as implicit indicators of the user＊s task type.  ", "authors": "Jingjing Liu, Michael J. Cole, Chang Liu, Ralf Bierig, Jacek Gwizdka, Nicholas J. Belkin,  Jun Zhang, Xiangmin Zhang School of Communication and Information, Rutgers University 4 Huntington Street, New Brunswick, NJ 08901, USA {belkin, m.cole, bierig, jacekg}@rutgers.edu, {jingjing, changl, zhangj}@eden.rutgers.edu, xiangminz@gmail.com  ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval 每 relevance feedback, search process General Terms Design, Experimentation, Human Factors, Measurement, Performance. ", "id": "10_p069", "keywords": " Personalization, Information retrieval, Task type, User behavior, Eye tracking. ", "title": "Search Behaviors in Different Task Types\n"}, "10_p079": {"abstract": " Query expansion of named entities can be employed in order to increase the retrieval effectiveness. A peculiarity of named enti- ties compared to other vocabulary terms is that they are very dy- namic in appearance, and synonym relationships between terms change with time. In this paper, we present an approach to ex- tracting synonyms of named entities over time from the whole his- tory of Wikipedia. In addition, we will use their temporal patterns as a feature in ranking and classifying them into two types, i.e., time-independent or time-dependent. Time-independent synonyms are invariant to time, while time-dependent synonyms are relevant to a particular time period, i.e., the synonym relationships change over time. Further, we describe how to make use of both types of synonyms to increase the retrieval effectiveness, i.e., query expan- sion with time-independent synonyms for an ordinary search, and query expansion with time-dependent synonyms for a search wrt. temporal criteria. Finally, through an evaluation based on TREC collections, we demonstrate how retrieval performance of queries consisting of named entities can be improved using our approach. ", "authors": "Nattiya Kanhabua Dept. of Computer Science Norwegian University of Science and Technology Trondheim, Norway nattiya@idi.ntnu.no Kjetil N?rv?g Dept. of Computer Science Norwegian University of Science and Technology Trondheim, Norway noervaag@idi.ntnu.no ", "categories": " H.3.3 [[Information Storage and Retrieval]]: :Information Search and Retrieval General Terms Algorithms, Experimentation, Measurement ", "id": "10_p079", "keywords": " Temporal Search, Synonym Detection, Query Expansion ", "title": "Exploiting Time-based Synonyms in Searching Document Archives\n"}, "10_p089": {"abstract": " Word sense discrimination is the first, important step to- wards automatic detection of language evolution within large, historic document collections. By comparing the found word senses over time, we can reveal and use important infor- mation that will improve understanding and accessibility of a digital archive. Algorithms for word sense discrimi- nation have been developed while keeping today＊s language in mind and have thus been evaluated on well selected, mod- ern datasets. The quality of the word senses found in the discrimination step has a large impact on the detection of language evolution. Therefore, as a first step, we verify that word sense discrimination can successfully be applied to dig- itized historic documents and that the results correctly cor- respond to word senses. Because accessibility of digitized historic collections is influenced also by the quality of the optical character recognition (OCR), as a second step we investigate the effects of OCR errors on word sense discrim- ination results. All evaluations in this paper are performed on The Times Archive, a collection of newspaper articles from 1785? 1985. ", "authors": "Nina Tahmasebi L3S Research Center Appelstr. 9a Hannover, Germany tahmasebi@L3S.de Kai Niklas L3S Research Center Appelstr. 9a Hannover, Germany niklas@L3S.de Thomas Theuerkauf L3S Research Center Appelstr. 9a Hannover, Germany theuerkauf@L3S.de Thomas Risse L3S Research Center Appelstr. 9a Hannover, Germany risse@L3S.de ", "categories": " H.3.1 [Content Analysis and Indexing]: Linguistic pro- cessing; H.3.3 [Information Search and Retrieval]: Clus- tering; H.3.7 [Digital Libraries]: Collection General Terms Algorithms, Experimentation ?This work is partly funded by the European Commission under LiWA (IST 216267) ", "id": "10_p089", "keywords": " Word Sense Discrimination, Information Extraction, OCR Error Impact, Historic Document Collections ", "title": "Using Word Sense Discrimination on Historic Document Collections\n"}, "10_p099": {"abstract": " Manifesting the handwriting characters with the specific style of a famous artwork is fascinating. In this paper, a system is built to render the user＊s handwriting characters with a specific style. A stroke database is established firstly. When rendering a character, the strokes are extracted and recog- nized, then proper radicals and strokes are filtered, finally these strokes are deformed and the result is generated. The Special Nine Grid (SNG) is presented to help recognize rad- icals and strokes. The Rule-base Stroke Deformation Al- gorithm (RSDA) is proposed to deform the original strokes according to the handwriting strokes. The rendering result manifests the specific style with high quality. It is feasible for people to generate the tablet or other artworks with the proposed system. ", "authors": "Zhenting Zhang College of Computer Science Zhejiang University Hangzhou, China lmzzt@126.com Jiangqin Wu* College of Computer Science Zhejiang University Hangzhou, China wujq@zju.edu.cn Kai Yu College of Computer Science Zhejiang University Hangzhou, China stephan@zju.edu.cn ", "categories": " I.3.m [Computer Graphics]: Miscellaneous; J.5 [Computer Application]: Arts and Humanities〞Arts and Humanities General Terms Design, Experimentation. ", "id": "10_p099", "keywords": " Specific style rendering, Special Nine Grid, Rule-base stroke deformation ", "title": "Chinese Calligraphy Specific Style Rendering System\n"}, "10_p109": {"abstract": " The Bleek and Lloyd Collection is a collection of artefacts documenting the life and language of the Bushman people of southern Africa in the 19th century. Included in this collec- tion is a handwritten dictionary that contains English words and their corresponding |xam Bushman language transla- tions. This dictionary allows for the manual translation of |xam words that appear in the notebooks of the Bleek and Lloyd collection. This, however, is not practical due to the size of the dictionary, which contains over 14000 entries. To solve this problem a content-based image retrieval system was built that allows for the selection of a |xam word from a notebook and returns matching words from the dictionary. The system shows promise with some search keys returning relevant results. ", "authors": "Kyle Williams Department of Computer Science University of Cape Town Private Bag X3, Rondebosch, 7701 South Africa kwilliams@cs.uct.ac.za Hussein Suleman Department of Computer Science University of Cape Town Private Bag X3, Rondebosch, 7701 South Africa hussein@cs.uct.ac.za ", "categories": " H.3.3 [Information Storage and Retrieval]: Informa- tion Search and Retrieval; H.3.3 [Information Storage and Retrieval]: Digital Libraries; I.4.6 [Image Process- ing and Computer Vision]: Segmentation〞edge and fea- ture detection General Terms Algorithms, Experimentation, Design, Performance ", "id": "10_p109", "keywords": " Information retrieval, cbir, cultural heritage preservation, digital libraries, handwritten manuscripts, image processing ", "title": "Translating Handwritten Bushman Texts\n"}, "10_p119": {"abstract": " Wikipedia is one of the most successful online knowledge bases, attracting millions of visits daily. Not surprisingly, its huge success has in turn led to immense research interest for a better understanding of the collaborative knowledge building process. In this paper, we performed a (terror- ism) domain-specific case study, comparing and contrast- ing the knowledge evolution in Wikipedia with a knowledge base created by domain experts. Specifically, we used the Terrorism Knowledge Base (TKB) developed by experts at MIPT. We identified 409 Wikipedia articles matching TKB records, and went ahead to study them from three aspects: creation, revision, and link evolution. We found that the knowledge building in Wikipedia had largely been indepen- dent, and did not follow TKB - despite the open and online availability of the latter, as well as awareness of at least some of the Wikipedia contributors about the TKB source. In an attempt to identify possible reasons, we conducted a detailed analysis of contribution behavior demonstrated by Wikipedians. It was found that most Wikipedians con- tribute to a relatively small set of articles each. Their con- tribution was biased towards one or very few article(s). At the same time, each article＊s contributions are often champi- oned by very few active contributors including the article＊s creator. We finally arrive at a conjecture that the contri- butions in Wikipedia are more to cover knowledge at the article level rather than at the domain level. ", "authors": "Yi Zhang, Aixin Sun, Anwitaman Datta, Kuiyu Chang School of Computer Engineering Nanyang Technological University, Singapore {yizhang, axsun}@ntu.edu.sg Ee-Peng Lim School of Information Systems Singapore Management University Singapore eplim@smu.edu.sg ", "categories": " H.1.2 [Models and Principles]: User/Machine Systems〞 Human information processing ; H.3.7 [Information Stor- age and Retrieval]: Digital Libraries〞User issues General Terms Experimentation ", "id": "10_p119", "keywords": " Wikipedia, knowledge building, contributing behavior ", "title": "Do Wikipedians Follow Domain Experts? A Domain-specific Study on Wikipedia Knowledge Building\n"}, "10_p129": {"abstract": " Space and time are important dimensions in the representation of a large number of concepts. However there exists no available resource that provides spatiotemporal mappings of generic concepts. Here we present a link-analysis based method for extracting the main locations and periods associated to all Wikipedia concepts. Relevant locations are selected from a set of geotagged articles, while relevant periods are discovered using a list of people with associated life periods. We analyze article versions over multiple languages and consider the strength of a spatial/temporal reference to be proportional to the number of languages in which it appears. To illustrate the utility of the spatiotemporal mapping of Wikipedia concepts, we present an analysis of cultural interactions and a temporal analysis of two domains. The Wikipedia mapping can also be used to perform rich spatiotemporal document indexing by extracting implicit spatial and temporal references from texts.  ", "authors": "Adrian Popescu Institut T谷l谷com/TELECOM Bretagne Technop?le Brest-Iroise  29238 Plouzan谷 +330229001435 adrian.popescu@telecom-bretagne.eu Gregory Grefenstette Exalead 10 Place de la Madeleine 75008 Paris +330155352766 gregory.grefenstette@exalead.com ", "categories": " H.m [MISCELLANEOUS] General Terms Algorithms, Experimentation, Human Factors. ", "id": "10_p129", "keywords": " Wikipedia, spatial-temporal, concept, multilinguism, cultural, interaction. ", "title": "Spatiotemporal Mapping of Wikipedia Concepts\n"}, "10_p139": {"abstract": " The※wisdom of crowds§is accomplishing tasks that are cum- bersome for individuals yet cannot be fully automated by means of specialized computer algorithms. One such task is the construction of thesauri and other types of concept hierarchies. Human expert feedback on the relatedness and relative generality of terms, however, can be aggregated to dynamically construct evolving concept hierarchies. The InPhO (Indiana Philosophy Ontology) project bootstraps feedback from volunteer users unskilled in ontology design into a precise representation of a specific domain. The ap- proach combines statistical text processing methods with expert feedback and logic programming to create a dynamic semantic representation of the discipline of philosophy. In this paper, we show that results of comparable quality can be achieved by leveraging the workforce of crowdsourcing services such as the Amazon Mechanical Turk (AMT). In an extensive empirical study, we compare the feedback ob- tained from AMT＊s workers with that from the InPhO vol- unteer users providing an insight into qualitative differences of the two groups. Furthermore, we present a set of strate- gies for assessing the quality of different users when gold standards are missing. We finally use these methods to con- struct a concept hierarchy based on the feedback acquired from AMT workers. ", "authors": "Kai Eckert KR & KM Research Group University of Mannheim, Germany kai@informatik.uni- mannheim.de Mathias Niepert KR & KM Research Group University of Mannheim, Germany mathias@informatik.uni- mannheim.de Christof Niemann University Library University of Mannheim, Germany christof.niemann@bib.uni- mannheim.de Cameron Buckner Department of Philosophy Indiana University, USA cbuckner@indiana.edu Colin Allen Department of History and Philosophy of Science & Program in Cognitive Science Indiana University, USA colallen@indiana.edu Heiner Stuckenschmidt KR & KM Research Group University of Mannheim, Germany heiner@informatik.uni- mannheim.de ", "categories": " H.1.2 [User/Machine Systems]: Human information pro- cessing; H3.1 [Content Analysis and Indexing]: The- sauruses General Terms Human Factors, Experimentation ", "id": "10_p139", "keywords": " Crowdsourcing, Thesaurus learning, Similarity ", "title": "Crowdsourcing the Assembly of Concept Hierarchies\n"}, "10_p149": {"abstract": " We describe the evaluation of a personal digital library en- vironment designed to help musicians capture, enrich and store their ideas using a spatial hypermedia paradigm. The target user group is musicians who primarily use audio and text for composition and arrangement, rather than with for- mal music notation. Using the principle of user-centered design, the software implementation was guided by a diary study involving nine musicians which suggested five require- ments for the software to support: capturing, overdubbing, developing, storing, and organizing. Moreover, the under- lying spatial data-model was exploited to give raw audio compositions a hierarchical structure, and〞to aid musicians in retrieving previous ideas〞a search facility is available to support both query by humming and text-based queries. A user evaluation of the completed design with eleven sub- jects indicated that musicians, in general, would find the hypermedia environment useful for capturing and managing their moments of musical creativity and exploration. More specifically they would make use of the query by humming facility and the hierarchical track organization, but not the overdubbing facility as implemented. ", "authors": "David Bainbridge University of Waikato Hamilton, New Zealand davidb@cs.waikato.ac.nz Brook J. Novak University of Waikato Hamilton, New Zealand bjn8@cs.waikato.ac.nz Sally Jo Cunningham University of Waikato Hamilton, New Zealand sallyjo@cs.waikato.ac.nz ", "categories": " H.5.1 [Multimedia Information Systems]: Audio in- put/output; H.3.7 [Information storage and retrieval]: Digital Libraries General Terms Design and Experimentation ", "id": "10_p149", "keywords": " Personal digital music library, Spatial hypermedia, Music composition ", "title": "A User-Centered Design of a Personal Digital Library for Music Exploration\n"}, "10_p159": {"abstract": " Mood is an emerging metadata type and access point in music digital libraries (MDL) and online music repositories. In this study, we present a comprehensive investigation of the usefulness of lyrics in music mood classification by evaluating and comparing a wide range of lyric text features including linguistic and text stylistic features. We then combine the best lyric features with features extracted from music audio using two fusion methods. The results show that combining lyrics and audio significantly outperformed systems using audio-only features. In addition, the examination of learning curves shows that the hybrid lyric + audio system needed fewer training samples to achieve the same or better classification accuracies than systems using lyrics or audio singularly. These experiments were conducted on a unique large-scale dataset of 5,296 songs (with both audio and lyrics for each) representing 18 mood categories derived from social tags. The findings push forward the state-of-the-art on lyric sentiment analysis and automatic music mood classification and will help make mood a practical access point in music digital libraries. ", "authors": "Xiao Hu Graduate School of Library and Information Science University of Illinois at Urbana-Champaign Champaign, IL 61820, U.S.A. xiaohu@illinois.edu J. Stephen Downie Graduate School of Library and Information Science University of Illinois at Urbana-Champaign Champaign, IL 61820, U.S.A. jdownie@illinois.edu ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing 每 indexing methods, linguistic processing. H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 systems issues. J.5 [Arts and Humanities]: Music. General Terms Measurement, Performance, Experimentation. ", "id": "10_p159", "keywords": "", "title": "Improving Mood Classification in Music Digital Libraries by Combining Lyrics and Audio\n"}, "10_p169": {"abstract": " This paper describes the use of relational database management system (RDBMS) and treemap visualization to represent and analyze a group of personal digital collections created in the context of work and with no external metadata. We evaluated the visualization vis a vis the results of previous personal information management (PIM) studies. We suggest that this visualization supports analysis that allows understanding PIM practices overtime.  ", "authors": "Weijia Xu Texas Advanced Computing Center  University of Texas at Austin xwj@tacc.utexas.edu Maria Esteva Texas Advanced Computing Center  University of Texas at Austin maria@tacc.utexas.edu Suyog Dott Jain Department of Computer Sciences University of Texas at Austin suyog.dott.jain@gmail.com  ", "categories": " H.2.8 [Systems]: Databases Applications H.3.7 [Digital Libraries]: Collection H.5.2 [Information Interfaces and Presentation (e.g. HCI)]: User Interfaces  General Terms Human Factors ", "id": "10_p169", "keywords": " Personal information management (PIM), information visualization, digital collections, treemap, database applications ", "title": "Visualizing Personal Digital Collections\n"}, "10_p173": {"abstract": " Digital libraries must support assistive technologies that allow people with disabilities such as blindness to use, navigate and understand their documents. Increasingly, many documents are Web-based and present their contents using complex layouts. However, approaches that translate two-dimensional layouts to one-dimensional speech produce a very different user experience and loss of information. To address this issue, we conducted a study of how blind people navigate and interpret layouts of news and shopping Web pages using current assistive technology. The study revealed that blind people do not parse Web pages fully during their first visit, and that they can miss important parts. The study also provided insights for improving assistive technologies. ", "authors": "Luis Francisco-Revilla1, Jeff Crow2 School of Information 1 University Station D7000 Austin, TX, 78715-0390 1+512-471-3821 1 revilla@ischool.utexas.edu  2 jcrow@mail.utexas.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 systems issues, user issues.  General Terms Measurement, Experimentation, Human Factors. ", "id": "10_p173", "keywords": " Assistive technology, Web page layouts, blind users. ", "title": "Interpretation of Web Page Layouts by Blind Users \n"}, "10_p177": {"abstract": " For open-ended information tasks, users must sift through many potentially relevant documents, a practice we refer to as document triage. Normally, people perform triage using multiple applications in concert: a search engine interface presents lists of potentially relevant documents; a document reader displays their contents; and a third tool〞a text editor or personal information management application〞is used to record notes and assessments. To support document triage, we have developed an extensible multi-application architecture that initially includes an information workspace and a document reader. An Interest Profile Manager infers users' interests from their interactions with the triage applications, coupled with the characteristics of the documents they are interacting with. The resulting interest profile is used to generate visualizations that direct users' attention to documents or parts of documents that match their inferred interests. The novelty of our approach lies in the aggregation of activity records across applications to generate fine-grained models of user interest. ", "authors": "Soonil Bae4, DoHyoung Kim1, Konstantinos Meintanis1, J. Michael Moore1, Anna Zacchi1, Frank Shipman1, Haowei Hsieh2, Catherine C. Marshall3 1Dept. of Computer Science Texas A&M University College Station, TX 77843 2School of Library & Information Science University of Iowa Iowa City, IA 52242-1420 3Microsoft Research Silicon Valley 1065 La Avenida Mountain View, CA 94043 4Samsung Techwin 13th Fl., KIPS Center Yeoksam-dong Kangnam-gu Seoul 135-980, Korea soonil.bae@samsung.com, shipman@cs.tamu.edu, haowei-hsieh@uiowa.edu, cathymar@microsoft.com  ", "categories": " H.3.3 [Information storage and retrieval]: Information search and retrieval 每 Search process General Terms Design, Experimentation, Human Factors. ", "id": "10_p177", "keywords": " Document triage, multi-application user modeling, visualization. ", "title": "Supporting Document Triage via Annotation-based Multi-Application Visualizations \n"}, "10_p187": {"abstract": " Photo libraries are growing in quantity and size, requiring better support for locating desired photographs. MediaGLOW is an inter- active visual workspace designed to address this concern. It uses attributes such as visual appearance, GPS locations, user-assigned tags, and dates to filter and group photos. An automatic layout al- gorithm positions photos with similar attributes near each other to support users in serendipitously finding multiple relevant photos. In addition, the system can explicitly select photos similar to spec- ified photos. We conducted a user evaluation to determine the ben- efit provided by similarity layout and the relative advantages of- fered by the different layout similarity criteria and attribute filters. Study participants had to locate photos matching probe statements. In some tasks, participants were restricted to a single layout simi- larity criterion and filter option. Participants used multiple attri- butes to filter photos. Layout by similarity without additional fil- ters turned out to be one of the most used strategies and was especially beneficial for geographical similarity. Lastly, the relative appropriateness of the single similarity criterion to the probe sig- nificantly affected retrieval performance. ", "authors": " Andreas Girgensohn, Frank Shipman, Thea Turner, Lynn Wilcox ", "categories": " H5.1. Information interfaces and presentation: Multimedia infor- mation systems; H3.3. Information storage and retrieval: Informa- tion search and retrieval. General Terms Algorithms, Design, Human Factors. ", "id": "10_p187", "keywords": " Photo libraries, photo retrieval, similarity criteria, visual similarity, geographic data, tagged photos. ", "title": "Flexible Access to Photo Libraries via Time, Place, Tags, and Visual Features\n"}, "10_p197": {"abstract": " We describe a novel video player that uses Temporal Se- mantic Compression (TSC) to present a compressed sum- mary of a movie. Compression is based on tempo which is derived from film rhythms. The technique identifies peri- ods of action, drama, foreshadowing and resolution, which can be mixed in different amounts to vary the kind of sum- mary presented. The compression algorithm is embedded in a video player, so that the summary can be interactively recomputed during playback. ", "authors": "Stewart Greenhill, Brett Adams, Svetha Venkatesh Department of Computing, Curtin University of Technology GPO Box U1987, Perth, 6845, W. Australia {s.greenhill,b.adams,s.venkatesh}@curtin.edu.au ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems General Terms Algorithms, Human Factors, Experimentation ", "id": "10_p197", "keywords": " Video browsing, Media aesthetics, Compression ", "title": "Interactively Browsing Movies in terms of Action,Foreshadowing and Resolution\n"}, "10_p201": {"abstract": " Attending a complex scheduled social event, such as a multi-day music festival, requires a significant amount of planning before and during its progression. Advancements in mobile technology and social networks enable attendees to contribute content in real- time that can provide useful information to many. Currently access to and presentation of such information is challenging to use during an event. The Timeline Interactive Multimedia Experience (TIME) system aggregates information posted to multiple social networks and presents the flow of information in a multi-touch timeline interface. TIME was designed to be placed on location to allow real-time access to relevant information that helps attendees to make plans and navigate their crowded surroundings. ", "authors": "Jeff Crow, Eryn Whitworth, Ame Wongsa,  Luis Francisco-Revilla School of Information The University of Texas  Austin, TX jcrow, eryn, ame, revilla@ischool.utexas.edu Swati Pendyala College of Natural Science The University of Texas  Austin, TX swati.pendyala@gmail.com ", "categories": " H.5.2 [Information interfaces and presentation]: User Interfaces〞 Graphical user interfaces General Terms Design ", "id": "10_p201", "keywords": " Timeline, multi-touch, social media, events, complex scheduled events, planning ", "title": "Timeline Interactive Multimedia Experience (TIME): On Location Access to Aggregate Event Information\n"}, "10_p205": {"abstract": " We present a new algorithm to measure domain-specific read- ability. It iteratively computes the readability of domain- specific resources based on the difficulty of domain-specific concepts and vice versa, in a style reminiscent of other bi- partite graph algorithms such as Hyperlink-Induced Topic Search (HITS) and the Stochastic Approach for Link-Structure Analysis (SALSA). While simple, our algorithm outperforms standard heuristic measures and remains competitive among supervised-learning approaches. Moreover, it is less domain- dependent and portable across domains as it does not rely on an annotated corpus or expensive expert knowledge that supervised or domain-specific methods require. ", "authors": "Jin Zhao Department of Computer Science School of Computing National University of Singapore Singapore, 117590 zhaojin@comp.nus.edu.sg Min-Yen Kan Department of Computer Science School of Computing National University of Singapore Singapore, 117590 kanmy@comp.nus.edu.sg ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; J.2 [Computer Applications]: Physical Sciences and Engineering General Terms Algorithm, Measurement ", "id": "10_p205", "keywords": " Readability Measure, Iterative Computation, Domain-Specific Information Retrieval, Graph-based Algorithm ", "title": "Domain-Specific Iterative Readability Computation\n"}, "10_p215": {"abstract": " Topic models could have a huge impact on improving the ways users find and discover content in digital libraries and search interfaces, through their ability to automatically learn and apply subject tags to each and every item in a collection, and their ability to dynamically create virtual collections on the fly. However, much remains to be done to tap this potential, and empirically evaluate the true value of a given topic model to humans. In this work, we sketch out some sub-tasks that we suggest pave the way towards this goal, and present methods for assessing the coherence and inter- pretability of topics learned by topic models. Our large-scale user study includes over 70 human subjects evaluating and scoring almost 500 topics learned from collections from a wide range of genres and domains. We show how a scoring model 每 based on pointwise mutual information of word- pairs using Wikipedia, Google and medline as external data sources 每 performs well at predicting human scores. This automated scoring of topics is an important first step to integrating topic modeling into digital libraries. ", "authors": "David Newman ? Dept. Computer Science University of California Irvine, and NICTA Australia newman@uci.edu Youn Noh Office of Digital Assets and Infrastructure Yale University youn.noh@yale.edu Edmund Talley National Institute of Neuro. Disorders and Stroke National Institutes of Health talleye@ninds.nih.gov Sarvnaz Karimi NICTA Australia Melbourne, Australia sarvnaz.karimi@nicta.com.au Timothy Baldwin Dept. Computer Science and Software Engineering University of Melbourne tb@ldwin.net ", "categories": " H.3.3 [Information Search and Retrieval]: Clustering General Terms Experimentation ", "id": "10_p215", "keywords": " topic models, user evaluation ", "title": "Evaluating Topic Models for Digital Libraries\n"}, "10_p225": {"abstract": " This paper addresses the problem of using the FRBR model to support the presentation of results. It describes a service implementing new algorithms and techniques for transforming existing MARC records into the FRBR model for this specific purpose. This work was developed in the context of the TELPlus project and processed 100,000 bibliographic and authority records from multilingual catalogs of 12 European countries. ", "authors": "Hugo Manguinhas INESC-ID 每 Instituto de Engenharia de Sistemas e Computadores Apartado 13069, 1000-029 Lisboa, Portugal hugo.manguinhas@ist.utl.pt Nuno Freire INESC-ID 每 Instituto de Engenharia de Sistemas e Computadores Apartado 13069, 1000-029 Lisboa, Portugal nuno.freire@ist.utl.pt Jos谷 Borbinha INESC-ID 每 Instituto de Engenharia de Sistemas e Computadores Apartado 13069, 1000-029 Lisboa, Portugal jlb@ist.utl.pt   ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 Collection, Dissemination, Standards, System issues, User issues.  H.3.3 每 [Information Storage and Retrieval]: Information Search and Retrieval 每 Clustering. General Terms Algorithms, Performance, Design, Standardization. ", "id": "10_p225", "keywords": " FRBR, FRBRization, Multilingual catalogs, Bibliographic records. ", "title": "FRBRization of MARC Records in Multiple Catalogs \n"}, "10_p235": {"abstract": " In recent years, the vast amount of digitally available content has lead to the creation of many topic-centered digital libraries. Also in the domain of chemistry more and more digital collections are available, but the complex query formulation still hampers their intuitive adoption. This is because information seeking in chemi- cal documents is focused on chemical entities, for which current standard search relies on complex structures which are hard to extract from documents. Moreover, although simple keyword searches would often be sufficient, current collections simply cannot be indexed by Web search providers due to the ambiguity of chemical substance names. In this paper we present a frame- work for automatically generating metadata-enriched index pages for all documents in a given chemical collection. All information is then linked to the respective documents and thus provides an easy to crawl metadata repository promising to open up digital chemical libraries. Our experiments, indexing an open access journal, show that not only the documents can be found using a simple Google search via the automatically created index pages, but also that the quality of the search is much more efficient than fulltext indexing in terms of both precision/recall and perfor- mance. Finally, we compare our indexing against a classical struc- ture search and figured out that keyword-based search can indeed solve at least some of the daily tasks in chemical workflows. To use our framework thus promises to expose a large part of the currently still hidden chemical Web, making the techniques em- ployed interesting for chemical information providers like digital libraries and open access journals. ", "authors": "Sascha T?nnies1, Benjamin K?hncke1, Oliver Koepler2, Wolf-Tilo Balke3 1 L3S Research Center, Appelstra?e 9a, 30167 Hannover, Germany 2 TIB Hannover, Welfengarten 1B, 30167 Hannover, Germany 3 IFIS TU Braunschweig, M邦hlenpfordtstra?e 23, 38106 Braunschweig, Germany {toennies, koehncke}@L3S.de, oliver.koepler@tib.uni-hannover.de, balke@ifis.cs.tu-bs.de  ", "categories": " H.3.1 [INFORMATION STORAGE AND RETRIEVAL]: Content Analysis and Indexing 每 indexing methods H.3.3 [INFORMATION STORAGE AND RETRIEVAL]: Information Search and Retrieval H.3.7 [INFORMATION STORAGE AND RETRIEVAL]: Digital Libraries General Terms Algorithms, Experimentation, Performance. ", "id": "10_p235", "keywords": " Digital libraries, information extraction, chemical digital collec- tions, information retrieval, Web search, hidden Web. ", "title": "Exposing the Hidden Web for Chemical Digital Libraries \n"}, "10_p245": {"abstract": " Representing the semantics of unstructured scientific publi- cations will certainly facilitate access and search and hope- fully lead to new discoveries. However, current digital li- braries are usually limited to classic flat structured meta- data even for scientific publications that potentially con- tain rich semantic metadata. In addition, how to search the scientific literature of linked semantic metadata is an open problem. We have developed a semantic digital library oreChem ChemxSeer that models chemistry papers with se- mantic metadata. It stores and indexes extracted metadata from a chemistry paper repository ChemxSeer using ※com- pound objects§. We use the Open Archives Initiative Ob- ject Reuse and Exchange (OAI-ORE) )1 standard to define a compound object that aggregates metadata fields related to a digital object. Aggregated metadata can be managed and retrieved easily as one unit resulting in improved ease-of-use and has the potential to improve the semantic interpretation of shared data. We show how metadata can be extracted from documents and aggregated using OAI-ORE. ORE ob- jects are created on demand; thus, we are able to search for a set of linked metadata with one query. We were also able to model new types of metadata easily. For example, chemists are especially interested in finding information related to experiments in documents. We show how paragraphs con- taining experiment information in chemistry papers can be extracted and tagged based on a chemistry ontology with 470 classes, and then represented in ORE along with other document-related metadata. Our algorithm uses a classifier with features that are words that are typically only used to describe experiments, such as ※apparatus§, ※prepare§, etc. Using a dataset comprised of documents from the Royal Society of Chemistry digital library, we show that the our proposed method performs well in extracting experiment- related paragraphs from chemistry documents. 1http://www.openarchives.org/ore/ ", "authors": "Na Li?, Leilei Zhu?, Prasenjit Mitra?, Karl Mueller?, Eric Poweleit?, C. Lee Giles? ?College of Information Sciences and Technology ?Department of Chemistry The Pennsylvania State University University Park, PA 16802, USA {nzl116, luz113, pmitra, ktm2, etp113, clg20}@psu.edu ", "categories": " D.2.12 [Software Engineering]: Interoperability〞Data map- ping,Distributed objects; E.2 [Data Storage Representa- tions]: Linked representations; H.3.7 [Information Stor- age and Retrieval]: Digital Library〞Collection,Dissemination General Terms Design, Experimentation, Management ", "id": "10_p245", "keywords": " Digital library, OAI-ORE, metadata extraction, semantic web, Support Vector Machines, ChemxSeer SeerSuite ", "title": "oreChem ChemXSeer: A Semantic Digital Library for Chemistry\n"}, "10_p255": {"abstract": " Converting a scanned document to a binary format (black and white) is a key step in the digitization process. While many existing binarization algorithms operate robustly for well-kept documents, these algorithms often produce less than satisfactory results when applied to old documents, es- pecially those degraded with stains and other discolorations. For these challenging documents, user assistance can be ad- vantageous in directing the binarization procedure. Many existing algorithms, however, are poorly designed to incor- porate user assistance. In this paper, we discuss a software framework, BinarizationShop, that combines a series of bi- narization approaches that have been tailored to exploit user assistance. This framework provides a practical approach for converting difficult documents to black and white. ", "authors": "Fanbo Deng Zheng Wu Zheng Lu Michael S. Brown School of Computing National University of Singapore {dfanbo, wuz, luzheng, brown}@comp.nus.edu.sg ", "categories": " H.4 [Information Systems Applications]: Miscellaneous; J.m [Computer Applications]: Miscellaneous General Terms Algorithms, Human Factors, Design ", "id": "10_p255", "keywords": " Binarization, document processing, user-assisted software ", "title": "BinarizationShop: A User-Assisted Software Suite for Converting Old Documents to Black-and-White\n"}, "10_p259": {"abstract": " Access to materials in digital collections has been extensively studied within digital libraries. Exploring a collection requires customized indices and novel interfaces to allow users new exploration mechanisms. Materials or objects can then be found by way of full-text, faceted, or thematic indexes. There has been a marked interest not only in finding objects in a collection, but in discovering relationships and properties. For example, multiple representations of the same object enable the use of visual aids to augment collection exploration. Depending on the domain and characteristics of the objects in a collection, relationships among components can be used to enrich the process of understanding their contents. In this context, the Nautical Archaeology Digital Library (NADL) includes multilingual textual- and visual-rich objects (shipbuilding treatises, illustrations, photographs, and drawings). In this paper we describe an approach for enhancing access to a collection of ancient technical documents, illustrations, and photographs documenting archaeological excavations. Because of the nature of our collection, we exploit a multilingual glossary along with an ontology. Preliminary tests of our prototype suggest the feasibility of our method for enhancing access to the collection.  ", "authors": "Carlos Monroy and Richard Furuta  Center for the Study of Digital Libraries and Department of Computer Science and Engineering Texas A&M University College Station, TX 77843-3112, USA {cmonroy, furuta}@csdl.tamu.edu Filipe Castro Center for Maritime Archaeology and Conservation Texas A&M University College Station, TX 77843-4352, USA fvcastro@tamu.edu   ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 system issues.  General Terms: Design. ", "id": "10_p259", "keywords": ": Nautical Archaeology, multilingual technical manuscripts, ship reconstruction, information retrieval, technical documents, interfaces. ", "title": "Using an Ontology and a Multilingual Glossary for Enhancing the Nautical Archaeology Digital Library \n"}, "10_p263": {"abstract": " Digital map is getting increasingly popular as an intuitive and interactive platform for data presentation recently. Thus applications integrated with digital map have attracted much attention. But no offtheshelf systems or services could we use if the time span of maps be extended to historical ones. There are a large number of valuable ancient atlases in CADAL digital library. However, they are seldom made use of be- cause the ones which are in image format are not conve- nient for users to read or search. In this paper, we propose a novel hybrid approach to utilizing these atlases directly and constructing some applications based on ancient maps. We call it CAMAME which means Chinese Ancient Maps Automatic Marking and Extraction. We create a gazetteer to store the geographic information of sites which will be project on the map, then use kernel method to do the re- gression and correct the estimated results with image pro- cessing and local regression methods. The empirical results show that CAMAME is effective and efficient, by which most valuable data in the map images is marked and identified. Some Chinese literary chronicle applications that exhibit an- cient literary and related historical information over those digitized atlas resources in CADAL digital library were de- veloped. ", "authors": "Zhenchao Ye College of Computer Science Zhejiang University Hangzhou, China yzc617@gmail.com Ling Zhuang College of Computer Science Zhejiang University Hangzhou, China zhuangling2000@yahoo.com.cn Jiangqin Wu College of Computer Science Zhejiang University Hangzhou, China wujq@zju.edu.cn Chenyang Du College of Computer Science Zhejiang University Hangzhou, China duchy@zju.edu.cn Baogang Wei College of Computer Science Zhejiang University Hangzhou, China wbg@zju.edu.cn Yin Zhang College of Computer Science Zhejiang University Hangzhou, China zhangyin98@zju.edu.cn ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.7 [Digital Libraries]: System Issues General Terms Algorithms, Experimentation ", "id": "10_p263", "keywords": " Atlases, Digital Library, Image Processing, Kernel Method ", "title": "In-depth Utilization of Chinese Ancient Maps: A Hybrid Approach to Digitizing Map Resources in CADAL\n"}, "10_p273": {"abstract": " This paper reports an investigation into the connection of the workspace of physical libraries with digital library ser- vices. Using simple sensor technology, we provide focused access to digital resources on the basis of the user＊s physical context, including the topic of the stacks they are next to, and the content of books on their reading desks. Our re- search developed the technological infrastructure to support this fused interaction, investigated current patron behavior in physical libraries, and evaluated our system in a user- centred pilot study. The outcome of this research demon- strates the potential utility of the fused library, and provides a starting point for future exploitation. ", "authors": "George Buchanan Centre for HCI Design City University London, UK +44 20 7040 8469 george.buchanan.1@city.ac.uk ", "categories": " H.3.7 [Information storage and retrieval]: Digital Li- braries〞Systems issues,User issues General Terms Design,Experimentation,Human Factors ", "id": "10_p273", "keywords": " Digital Libraries, Physical Interaction, RFID, Bluetooth ", "title": "The Fused Library: Integrating Digital and Physical Libraries with Location-Aware Sensors\n"}, "10_p283": {"abstract": " Despite the growing prominence of digital libraries as tools to support humanities scholars, little is known about the work practices and needs of these scholars as they pertain to working with source documents. In this paper we present our findings from a formative user study consisting of semi-structured interviews with eight scholars. We find that the use of source materials (by which we mean the original physical documents or digital facsimiles with minimal editorial intervention) in scholarship is not a simple, straight- forward examination of a document in isolation. Instead, scholars study source materials as an integral part of a complex ecosystem of inquiry that seeks to understand both the text being studied and the context in which that text was created, transmitted and used. Drawing examples from our interviews, we address critical questions of why scholars use source documents and what information they hope to gain by studying them. We also briefly summarize key note-taking practices as a means for assessing the potential to design user interfaces that support scholarly work- practices.  ", "authors": "Neal Audenaert, Richard Furuta Center for the Study of Digital Libraries Department of Computer Science and Engineering Texas A&M University College Station, Texas 77843-3112 USA {neal, furuta}@csdl.tamu.edu  ", "categories": ": H.1.2 [User/Machine Systems] Human factors, H.5.2 [User Interfaces]: Interaction styles, H.5.4 [Hypertext/Hypermedia]: User Issues General Terms: Design, Human Factors. ", "id": "10_p283", "keywords": ": digital humanities, source documents, user studies ", "title": "What Humanists Want: How Scholars Use Source Materials\n"}, "10_p293": {"abstract": " Identification of contexts associated with sentences is becoming increasingly necessary for developing intelligent information retrieval systems. This article describes a supervised learning mechanism employing a conditional random field (CRF) for context identification and sentence classification. Specifically, we focus on sentences in related work sections in research articles. Based on a generic rhetorical pattern, a framework for modelling the sequential flow in these sections is proposed. Adopting a generalization strategy, each of these sentences is transformed into a set of features, which forms our dataset. We distinguish between two kinds of features for each of these sentences viz., citation features and sentence features. While an overall accuracy of 96.51% is achieved by using a combination of both citation and sentence features, the use of sentence features alone yields an accuracy of 93.22%. The results also show F-Scores ranging from 0.99 to 0.90 for various classes indicating the robustness of our application.  ", "authors": "M.A. Angrosh Stephen Cranefield Nigel Stanger Department of Information Science, University of Otago, Dunedin, New Zealand {angrosh, scranefield, nstanger}@infoscience.otago.ac.nz  ", "categories": " H.3.3 [Information Storage and Retrieval]: Content Analysis and Indexing, Information Search and Retrieval, Digital Libraries  General Terms Algorithms, Experimentation ", "id": "10_p293", "keywords": " Sentence Classification, Citation Classification, Conditional Random Fields ", "title": "Context Identification of Sentences in Related Work Sections using a Conditional Random Field: Towards Intelligent Digital Libraries \n"}, "10_p303": {"abstract": " Developing methods for searching image databases is a challenging and ongoing area of research. A common approach is to use manual annotations, although generating annotations can be expensive in terms of time and money, and therefore may not be justified in many situations. Content-based search techniques which extract visual features from image data can be used, but users are typically forced to express their information need using example images, or through sketching interfaces. This can be difficult if no visual example of the information need is available, or when the information need cannot be easily drawn.   In this paper, we consider an alternative approach which allows a user to search for images through an intermediate database. In this approach, a user can search using text in the intermediate database as a way of finding visual examples of their information need. The visual examples can then be used to search a database that lacks annotations. Three experiments are presented which investigate this process. The first experiment automatically selects the image queries from the intermediary database; the second instead uses images which have been hand-picked by users. A third experiment, an interactive study, is then presented this study compares the intermediary interface to text search, where we consider text as an upper bound of performance. For this last study, an interface which supports the intermediary search process is described. Results show that while performance does not match manual annotations, users are able to find relevant material without requiring collection annotations.  ", "authors": "Robert Villa, Martin Halvey, Hideo Joho1, David Hannah, Joemon M. Jose Department of Computing Science University of Glasgow  Scotland, UK, G12 8QQ  {villar, halvey, davidh, jj}@dcs.gla.ac.uk  Graduate School of Library, Information and Media Studies1 University of Tsukuba, Ibaraki, Japan hideo@slis.tsukuba.ac.jp   ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval 每 search process General Terms: Experimentation, Human Factors ", "id": "10_p303", "keywords": ": Content-based image retrieval, search strategies ", "title": "Can an Intermediary Collection Help Users Search Image Databases Without Annotations? \n"}, "10_p313": {"abstract": " In search engines, ranking algorithms measure the importance and relevance of documents mainly based on the contents and relationships between documents. User attributes are usually not considered in ranking. This user-neutral approach, however, may not meet the diverse interests of users, who may demand different documents even with the same queries. To satisfy this need for more personalized ranking, we propose a ranking framework, Social Network Document Rank (SNDocRank), that considers both document contents and the relationship between a searcher and document owners in a social network. This method combines the traditional tf-idf ranking for document contents with our Multi-level Actor Similarity (MAS) algorithm to measure to what extent document owners and the searcher are structurally similar in a social network. We implemented our ranking method in a simulated video social network based on data extracted from YouTube and tested its effectiveness on video search. The results show that compared with the traditional ranking method like tf-idf, the SNDocRank algorithm returns more relevant documents. More specifically, a searcher can get significantly better results by being in a larger social network, having more friends, and being associated with larger local communities in a social network. ", "authors": " Liang Gou1, Xiaolong (Luke) Zhang1, Hung-Hsuan Chen2, Jung-Hyun Kim2, C. Lee Giles1,2 Information Sciences and Technology1, Computer Science and Engineering2 The Pennsylvania State University, University Park, PA, 16802, USA {lug129, xuz14, hhchen, jzk171}@psu.edu, giles@ist.psu.edu  ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval 每 relevance feedbacks, retrieval models, selection process; H.1.2 [Models and Principles]: User/Machine Systems 每 human factors.  General Terms Algorithms, Experimentation, Human Factors. ", "id": "10_p313", "keywords": " Ranking, Social Networks, Information Retrieval, Multilevel Actor Similarity. ", "title": "Social Network Document Ranking \n"}, "10_p323": {"abstract": " File format obsolescence has so far been considered the major risk in long-term storage of digital objects. There are, however, growing indications that file transfer may be a real threat as the migration time, i.e., the time required to migrate Petabytes of data, may easily spend years. However, hardware support is usually limited to 3-4 years and a situation can emerge when a new migration has to be started although the previous one is still not finished yet. This paper chooses a process modeling approach to obtain estimates of upper and lower bounds for the required migration time. The advantage is that information about potential bottlenecks can be acquired. Our theoretical considerations are validated by migration tests at the National Library of Norway (NB) as well as at our department. ", "authors": " Feng Luan Dept. of Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway +47 735 91457 luan@idi.ntnu.no Mads Nyg?rd Dept. of Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway +47 735 93470 mads@idi.ntnu.no Thomas Mestl Research and Innovation Det Norske Veritas (DNV), H?vik, Norway + 47 67579900 thomas.mestl@dnv.com   ", "categories": " C.4 [Performance of system] H.3.2 [Information Storage]  H.3.7 [Digital Library]  General Terms Management, Measurement, Design, ", "id": "10_p323", "keywords": " Long-term preservation, Migration, Storage, Process modeling, Performance ", "title": "A Mathematical Framework for Modeling and Analyzing Migration Time \n"}, "10_p333": {"abstract": " Science and technology research is becoming not only more distributed and collaborative, but more highly instrumented. Digital libraries provide a means to capture, manage, and access the data deluge that results from these research enterprises. We have conducted research on data practices and participated in developing data management services for the Center for Embedded Networked Sensing since its founding in 2002 as a National Science Foundation Science and Technology Center. Over the course of eight years, our digital library strategy has shifted dramatically in response to changing technologies, practices, and policies. We report on the development of several DL systems and on the lessons learned, which include the difficulty of anticipating data requirements from nascent technologies, building systems for highly diverse work practices and data types, the need to bind together multiple single-purpose systems, the lack of incentives to manage and share data, the complementary nature of research and development in understanding practices, and sustainability.  ", "authors": "Jillian C. Wallis Dept. of Info. Studies University of California, Los Angeles +1(310)206-0029 jwallisi@ucla.edu Matthew S. Mayernik Dept. of Info. Studies University of California, Los Angeles +1(310)206-0029 mattmayernik@ucla.edu Christine L. Borgman Dept. of Info. Studies University of California, Los Angeles +1(310)825-6164 borgman@gseis.ucla.edu Alberto Pepe Dept. of Info. Studies University of California, Los Angeles +1(310) 206-0029 apepe@ucla.edu   ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 collection, standards, user issues. General Terms Management, Design, Human Factors, Standardization. ", "id": "10_p333", "keywords": " Data deluge, cyberinfrastructure, eScience, distributed research, collaborative research ", "title": "Digital Libraries for Scientific Data Discovery and Reuse: From Vision to Practical Reality \n"}, "10_p341": {"abstract": " Ensemble, the National Science Digital Library (NSDL) Pathways project for Computing, builds upon a diverse group of prior NSDL, DL-I, and other projects. Ensemble has shaped its activities according to principles related to design, development, implementation, and operation of distributed portals. Here we articulate 8 key principles for distributed portals (PDPs). While our focus is on education and pedagogy, we expect that our experiences will generalize to other digital library application domains. These principles inform, facilitate, and enhance the Ensemble R&D and production activities. They allow us to provide a broad range of services, from personalization to coordination across communities. The eight PDPs can be briefly summarized as: (1) Articulation across communities using ontologies. (2) Browsing tailored to collections. (3) Integration across interfaces and virtual environments. (4) Metadata interoperability and integration. (5) Social graph construction using logging and metrics. (6) Superimposed information and annotation integrated across distributed systems. (7) Streamlined user access with IDs. (8) Web 2.0 multiple social network system interconnection. ", "authors": " Edward A. Fox, Yinlin Chen, Monika Akbar,  Clifford A. Shaffer,  Stephen H. Edwards Dept. Comp. Sci. Virginia Tech, Blacksburg, VA 24061 USA {fox,ylchen,amonika,shaffer, s.edwards}@vt.edu  Lois Delcambre,  Felicia Decker, David Archer P.O. Box 751, 1900 SW 4th Avenue Portland State University CS Dept. Portland, OR 97207-0751 USA {lmd,deckerfe,darcher}@cs.pdx.edu  Peter Brusilovsky School of Information Sciences University of Pittsburgh 135 North Bellefield Avenue Pittsburgh, PA 15260 USA peterb@pitt.edu    Richard Furuta, Frank Shipman, Stephen Carpenter Texas A&M University CSDL College Station, TX 77843-3112 USA {furuta,shipman,bscarpenter}@ tamu.edu   Dan Garcia Computer Science Dept. 777 Soda Hall UC Berkeley Berkeley, CA 94720-1776 USA ddgarcia@cs.berkeley.edu   Lillian (Boots) Cassel Dept. of Computing Sciences MSC 161-B, 800 Lancaster Avenue Villanova University Villanova, PA 19085-1699 USA lillian.cassel@villanova.edu ", "categories": " H.3.7 [Digital Libraries]: Distributed Portal.  General Terms Design, Human Factors, Standardization. ", "id": "10_p341", "keywords": " Adaptive Education System, Distributed Portal, Ontology, Superimposed Information. ", "title": "Ensemble PDP-8: Eight Principles for Distributed Portals \n"}, "10_p345": {"abstract": " Access to data crucial to research is often slow and difficult. When research problems cross disciplinary boundaries, problems are exacerbated. This paper argues that it is important to make it easier to find and access data that might be found in an institution, in a disciplinary data store, in a government department, or held privately. We explore how to meet ad hoc needs that cannot easily be supported by a disciplinary ontology, and argue that web pages that describe data collections with rich links and rich text are valuable. We describe the approach followed by the Australian National Data Service (ANDS) in making such pages available. Finally, we discuss how we plan to evaluate this approach. ", "authors": "Stefanie Kethers Australian National Data Service c/o Monash University Clayton 3800, Australia (61) 3 9902 0546 Stefanie.Kethers@ ands.org.au Xiaobin Shen Australian National Data Service  c/o Monash University Clayton 3800, Australia (61) 3 9902 0567 Xiaobin.Shen@ ands.org.au Andrew E. Treloar Australian National Data Service c/o Monash University Clayton 3800, Australia (61) 3 9902 0572 Andrew.Treloar@ ands.org.au Ross G. Wilkinson Australian National Data Service c/o Monash University Clayton 3800, Australia (61) 3 9902 0598 Ross.Wilkinson@ ands.org.au  ", "categories": " H.3.5 [Online Information Services]: Data Sharing; H3.7 [Digital Libraries]: Collection, User Issues, Standards General Terms Documentation, Design, Human Factors ", "id": "10_p345", "keywords": " e-research, metadata, Australian Research Data Commons ", "title": "Discovering Australia＊s Research Data \n"}, "10_p349": {"abstract": " Many user-centred studies of digital libraries (DLs) include a think-aloud element and are usually conducted with the purpose of identifying usability issues related to the DLs used or understanding aspects of users＊ information behaviour. However, few of these studies present detailed accounts of how their think- aloud data was collected and analysed or reflect on this process. In this paper, we discuss and reflect on the decisions made when planning and conducting a think-aloud study of lawyers＊ interactive information behaviour. Our discussion is framed by Blandford et al.＊s PRET A Rapporter (＆ready to report＊) framework 每 a framework that can be used to plan, conduct and describe user-centred studies of DL use from an information work perspective. ", "authors": "Stephann Makri Department of Information Studies University College London Gower Street, London WC1E 6BT S.Makri@ucl.ac.uk Ann Blandford and Anna L. Cox UCL Interaction Centre MPEB 8th Floor, University College London Gower Street, London WC1E 6BT {A.Blandford, Anna.Cox}@ucl.ac.uk  ", "categories": " H.5.2 [User Interfaces]: Evaluation/methodology. General Terms Human Factors ", "id": "10_p349", "keywords": " Think-aloud, methodology, user study, reflection ", "title": "This is What I＊m Doing and Why: Reflections on a Think-Aloud Study of DL Users＊ Information Behaviour\n"}, "10_p353": {"abstract": " The Curriculum Customization Service enables science educators to customize their instruction with interactive digital library resources. Preliminary results from a field trial with 124 middle and high school teachers suggest that the Service offers a promising model for embedding educational digital libraries into teaching practices and for supporting teachers to integrate customizing into their curriculum planning.  ", "authors": "Tamara Sumner Institute of Cognitive Science University of Colorado at Boulder Boulder, Colorado, USA +1 303 735 4469 sumner@colorado.edu CCS Team Digital Learning Sciences University of Colorado at Boulder University Corp for Atmospheric Research +1 303 497 2662 ccshelp@dls.ucar.edu ", "categories": " H.5 [Information Interfaces and Presentation]: User Interfaces 每 prototyping, user-centered design.  General Terms Design, Human Factors ", "id": "10_p353", "keywords": " Educational digital libraries, science education, personalization, differentiated instruction, customizing instruction, software infrastructure for teachers ", "title": "Customizing Science Instruction with Educational Digital Libraries \n"}, "10_p357": {"abstract": " This paper presents our ongoing study of the current/future impact of social bookmarks (or social tags) on information retrieval (IR). Our main research question asked in the present work is ※How are social tags compared with conventional, yet reliable manual index- ing from the viewpoint of IR performance?§. To answer the ques- tion, we look at the biomedical literature and begin with examin- ing basic statistics of social tags from CiteULike in comparison with Medical Subject Headings (MeSH) annotated in the Medline bibliographic database. Then, using the data, we conduct various experiments in an IR setting, which reveals that social tags work complementarily with MeSH and that retrieval performance would improve as the coverage of CiteULike grows. ", "authors": "Kazuhiro Seki Organization of Advanced Science & Technology Kobe University 1-1 Rokkodai, Nada, Kobe 657-8501, Japan seki@cs.kobe-u.ac.jp Huawei Qin Graduate School of Engineering Kobe University 1-1 Rokkodai, Nada, Kobe 657-8501, Japan qin@ai.cs.kobe-u.ac.jp Kuniaki Uehara Graduate School of Engineering Kobe University 1-1 Rokkodai, Nada, Kobe 657-8501, Japan uehara@kobe-u.ac.jp ", "categories": " H.3.1 [Information storage and retrieval]: Content Analysis and Indexing〞Indexing methods, Thesauruses; H.3.7 [Information stor- age and retrieval]: Digital Libraries〞Collection, Standards General Terms Experimentation, Languages, Performance ", "id": "10_p357", "keywords": " Subject headings, controlled vocabulary, free keywords, folkson- omy ", "title": "Impact and Prospect of Social Bookmarks for Bibliographic Information Retrieval\n"}, "10_p361": {"abstract": " Digital library interoperability relies on the use of a common metadata format. However, implementing a common metadata format among multiple digital libraries is not always a straightforward exercise. This paper reviews some of the metadata issues that arose during the merger of two digital libraries, the Internet Public Library and the Librarian＊s Internet Index. As part of the merger, each library＊s metadata was crosswalked to Dublin Core. This required considerable work. A sociotechnical analysis suggests that the metadata for each library had been shaped in complex ways over time by local factors, and that this complexity negatively impacted the efficiency of the crosswalk. Some implications of this finding for digital library interoperability are discussed. ", "authors": "Michael Khoo, Catherine Hall The iSchool at Drexel University 3141 Chestnut Street Philadelphia, PA 19104, USA +1 215 895 1230 {khoo, ceh48}@drexel.edu ", "categories": " H.3.7 Digital Libraries 每 collection, standards, user issues. General Terms Management, Standardization ", "id": "10_p361", "keywords": " crosswalk, Dublin Core, interoperability, metadata, operations, organizational knowledge, organizations, sociotechnical ", "title": "Merging Metadata: A Sociotechnical Study of Crosswalking and Interoperability\n"}, "10_p365": {"abstract": " The creation of most digital objects occurs solely in inter- active graphical user interfaces which were available at the particular time period. Archiving and preservation orga- nizations are posed with large amounts of such objects of various types. At some point they will need to process these automatically to make them available to their users or convert them to a commonly used format. A substan- tial problem is to provide a wide range of different users with access to ancient environments and to allow using the original environment for a given object. We propose an ab- stract architecture for emulation services in digital preser- vation to provide remote user interfaces to emulation over computer networks without the need to install additional software components. Furthermore, we describe how these ideas can be integrated in a framework of web services for common preservation tasks like viewing or migrating digital objects. ", "authors": "Klaus Rechert Albert-Ludwigs University Freiburg Hermann-Herder Str. 10 79104 Freiburg i. B., Germany klaus.rechert @rz.uni-freiburg.de Dirk von Suchodoletz Albert-Ludwigs University Freiburg Hermann-Herder Str. 10 79104 Freiburg i. B., Germany dsuchod.von.suchodoletz @rz.uni-freiburg.de Randolph Welte Albert-Ludwigs University Freiburg Hermann-Herder Str. 10 79104 Freiburg i. B., Germany randolph.welte @rz.uni-freiburg.de ", "categories": " H.3 [Information Storage and Retrieval]: Digital Li- braries General Terms Design ", "id": "10_p365", "keywords": "", "title": "Emulation Based Services in Digital Preservation\n"}, "11_p001": {"abstract": " We describe here a method for automatically identifying word sense variation in a dated collection of historical books in a large digital library. By leveraging a small set of known translation book pairs to induce a bilingual sense inventory and labeled training data for a WSD classifier, we are able to automatically classify the Latin word senses in a 389 million word corpus and track the rise and fall of those senses over a span of two thousand years. We evaluate the performance of seven different classifiers both in a tenfold test on 83,892 words from the aligned parallel corpus and on a smaller, manually annotated sample of 525 words, measuring both the overall accuracy of each system and how well that ac- curacy correlates (via mean square error) to the observed historical variation. ", "authors": "David Bamman The Perseus Project Tufts University Medford, MA, USA david.bamman@tufts.edu Gregory Crane The Perseus Project Tufts University Medford, MA, USA gregory.crane@tufts.edu ", "categories": " H.3.7 [Information Systems: Information Storage and Retrieval]: digital libraries General Terms Design, Documentation, Performance ", "id": "11_p001", "keywords": " Word sense disambiguation, linguistic variation, digital li- braries ", "title": "Measuring Historical Word Sense Variation\n"}, "11_p011": {"abstract": " Nowadays PDF documents have become a dominating knowledge repository for both the academia and industry largely because they are very convenient to print and exchange. However, the methods of automated structure information extraction are yet to be fully explored and the lack of effective methods hinders the information reuse of the PDF documents. To enhance the usability for PDF-formatted electronic books, we propose a novel computational framework to analyze the underlying physical structure and logical structure. The analysis is conducted at both page level and document level, including global typographies, reading order, logical elements, chapter/section hierarchy and metadata. Moreover, two characteristics of PDF-based books, i.e., style consistency in the whole book document and natural rendering order of PDF files, are fully exploited in this paper to improve the conventional image-based structure extraction methods. This paper employs the bipartite graph as a common structure for modeling various tasks, including reading order recovery, figure and caption association, and metadata extraction. Based on the graph representation, the optimal matching (OM) method is utilized to find the global optima in those tasks. Extensive benchmarking using real-world data validates the high efficiency and discrimination ability of the proposed method. ", "authors": "Liangcai Gao, Zhi Tang Institute of Computer Science & Technology, Peking University, Beijing, China {gaoliangcai, tangzhi}@icst.pku.edu.cn Xiaofan Lin Vobile Inc. 4699 Old Ironsides Drive, Santa Clara, California, USA xiaofan@vobileinc.com Ying Liu Department of Knowledge Service Engineering, KAIST, Daejeon, Republic of Korea yingliu@kaist.ac.kr Ruiheng Qiu State Key Laboratory of Digital Publishing Technology, Peking University Founder Group Co., Ltd., Beijing, China chourh@founder.com.cn Yongtao Wang Institute of Computer Science & Technology, Peking University, Beijing, China wangyongtao@icst.pku.edu.cn ", "categories": " H.3.3 [Information Systems]: Information Search and Retrieval General Terms Algorithms ", "id": "11_p011", "keywords": " Electronic Book, Structure Extraction, Layout Analysis, Bipartite Graph ", "title": "Structure Extraction from PDF-based Book Documents\n"}, "11_p021": {"abstract": " Topic models are emerging tools for improved browsing and searching within digital libraries. These techniques collapse words within documents into unordered ※bags of words,§ ig- noring word order. In this paper, we present a method that examines syntactic dependency parse trees from Wikipedia article titles to learn expected patterns between relative lex- ical arguments. This process is highly dependent on the global word ordering of a sentence, modeling how each word interacts with other words to gain an aggregate perspec- tive on how words interact over all 3.2 million titles. Using this information, we analyze how coherent a given topic is by comparing the relative usage vectors between the top 5 words in a topic. Results suggest that this technique can identify poor topics based on how well the relative usages align with each other within a topic, potentially aiding dig- ital library indexing. ", "authors": "Steve Spagnola Cornell University sps34@cs.cornell.edu Carl Lagoze Cornell University lagoze@cs.cornell.edu ", "categories": " H.3.1 [Content Analysis and Indexing]: Linguistic pro- cessing General Terms Experimentation ", "id": "11_p021", "keywords": " topic models, lexical arguments, semantic coherence ", "title": "Word Order Matters: Measuring Topic Coherence with Lexical Argument Structure\n"}, "11_p025": {"abstract": " Retrieval of subtopical concepts from scholarly communica- tion systems is now possible through a combination of text and metadata analysis, augmented by user search queries and click logs. Here we investigate how a ※phrase§, defined as a variable length sequence of vocabulary words, can be used to represent a concept. We present a method to ex- tract such phrases from a text corpus, and rank them us- ing a citation network measure, the compensated normalized link count (CNLC), which measures the extent to which they are propagated along the citation structure of articles. We validate the ranking with actively and passively deter- mined metrics: comparison with human-assigned keywords, and comparison with passively harvested terms from search query logs. This method is demonstrated on full texts and abstracts from 7 years of high energy physics articles from the arXiv preprint database. ", "authors": "Asif-ul Haque Department of Computer Science Cornell University Ithaca, NY 14853 asif@cs.cornell.edu Paul Ginsparg Departments of Physics and Information Science Cornell University Ithaca, NY 14853 ginsparg@cornell.edu ", "categories": " I.7.m [Computing Methodologies]: Document and Text Processing; H.4.m [Information Systems]: Information Systems Applications General Terms Algorithms, Experimentation, Measurement ", "id": "11_p025", "keywords": " Scientific Literature, Phrase Extraction, Ranking ", "title": "Phrases as Subtopical Concepts in Scholarly Text\n"}, "11_p029": {"abstract": " Videogames and other new media artifacts constitute an important part of our cultural and economic landscape and collecting institutions have a responsibility to collect and preserve these materials for future access. Unfortunately, these kinds of materials present unique challenges for collecting institutions including problems of collection development, technological preservation, and access. This paper presents findings from a grant-funded project focused on examining documentation of the creative process in game development. Data includes twelve qualitative interviews conducted with individuals involved in the game development process, spanning a number of different roles and institution types. The most pressing findings are related to the nature of documentation in the videogame industry: project interviews indicate that the game development process does produce significant and important documentation as traditionally conceived by collecting institutions, ranging from game design documents to email correspondence and business reports. However, while it does exist, traditional documentation does not adequately, or even, at times, truthfully represent the project or the game creation process as a whole. In order to adequately represent the development process, collecting institutions also need to seek out and procure numerous versions of games and game assets as well as those game assets that are natural byproducts of the design process like gamma and beta versions of the game, for example, vertical slices, or different renderings of graphical elements.  ", "authors": "Megan A. Winget University of Texas at Austin School of Information  1616 Guadalupe, Ste. 5.222 +1 (512) 471-3969 megan@ischool.utexas.edu W. Walker Sampson University of Texas at Austin School of Information  1616 Guadalupe, Ste. 5.222 +1 (769) 232-0544 walker.sampson@gmail.com  ", "categories": " H.3.7 [Digital Libraries]: Collection. General Terms Management, Documentation, Design, Experimentation, Human Factors ", "id": "11_p029", "keywords": " History of computing, videogames, software development, game development, non-functional requirements, documentation, iterative programming, archives, cultural institutions ", "title": "Game Development Documentation and Institutional Collection Development Policy \n"}, "11_p039": {"abstract": " In this paper we present a novel system for user-driven in- tegration of name variants when interacting with web-based information systems. The growth and diversity of online in- formation means that many users experience disambiguation and collocation errors in their information searching. We ap- proach these issues via a client-side JavaScript browser ex- tension that can reorganise web content and also integrate remote data sources. The system is illustrated through three worked examples using existing digital libraries. ", "authors": "David Bainbridge University of Waikato Hamilton, New Zealand davidb@cs.waikato.ac.nz Michael B. Twidale University of Illinois Urbana-Champaign, USA twidale@illinois.edu David M. Nichols University of Waikato Hamilton, New Zealand dmn@cs.waikato.ac.nz ", "categories": " H.3.7 [Information storage and retrieval]: Digital Li- braries General Terms Design and Experimentation ", "id": "11_p039", "keywords": " Selective Web Editability, Name Authority Control, Crowd- sourcing ", "title": "That's ＆谷＊ not ＆t＊ ＆?＊ or ＆?＊: A User-driven Context-aware Approach to Erroneous Metadata in Digital Libraries \n"}, "11_p049": {"abstract": " This paper explores a technique to improve searcher access to library collections by providing a faceted search interface built on a data model based on the Functional Requirements for Bibliographic Records (FRBR). The prototype provides a Work- centric view of a moving image collection that is integrated with bibliographic and holdings data. Two sets of facets address important user needs: ※what do you want?§ and ※how/where do you want it?§ enabling patrons to narrow, broaden and pivot across facet values instead of limiting them to the tree-structured hierarchy common with existing FRBR applications. The data model illustrates how FRBR is being adapted and applied beyond the traditional library catalog. ", "authors": "Kelley McGrath University of Oregon Libraries 1299 University of Oregon Eugene, OR 97403-1299 +1-541-346-8232 kelleym@uoregon.edu Bill Kules School of Library and Information Science The Catholic University of America Washington, DC 20064 +1-202-319-6278 kules@cua.edu Chris Fitzpatrick Stanford University Digital Library Systems and Services Stanford, CA 94305 +1-650-724-5085 cfitz@stanford.edu ", "categories": " H.3.7 [Information Search and Retrieval]: Digital Libraries General Terms Design, Standardization. ", "id": "11_p049", "keywords": " FRBR, faceted search, user interface design, moving images, movies, film, video ", "title": "FRBR and Facets Provide Flexible, Work-Centric Access to Items in Library Collections\n"}, "11_p053": {"abstract": " In this paper, we describe an exploratory study comparing the abstracting and indexing practices of a semi-expert LIS community (metadata creators for the digital library, ipl2) and the social tags generated by Delicious users for the same corpus of materials. We find over 88% of the resources in the ipl2 History collection were tagged at least once in Delicious. Overlap between the tags applied to ipl2 resources and indexing shows terms that the two groups are similar enough to be useful, yet dissimilar enough to provide new access points and description.  ", "authors": "Catherine Hall College of Information Science and Technology  Drexel University 3141 Chestnut Street Philadelphia, PA 19104 catherine.hall@ischool.drexel.edu Michael Zarro College of Information Science and Technology  Drexel University 3141 Chestnut Street Philadelphia, PA 19104 michael.a.zarro@drexel.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries每 collection, dissemination, user issues.  General Terms Measurement, Documentation, Design, Economics, Reliability ", "id": "11_p053", "keywords": " Digital libraries, controlled vocabularies, social tagging, folksonomies. ", "title": "What Do You Call It? A Comparison of Library-Created and User-Created Tags \n"}, "11_p057": {"abstract": " Disk images (bitstreams extracted from physical media) can play an essential role in the acquisition and management of digital collections by serving as containers that support data integrity and chain of custody, while ensuring continued access to the underlying bits without depending on physical carriers. Widely used today by practitioners of digital forensics, disk images can serve as baselines for comparison for digital preservation activities, as they provide fail-safe mechanisms when curatorial actions make unexpected changes to data; enable access to potentially valuable data that resides below the file system level; and provide options for future analysis. We discuss established digital forensics techniques for acquiring, preserving and annotating disk images, provide examples from both research and educational collections, and describe specific forensic tools and techniques, including an object-oriented data packaging framework called the Advanced Forensic Format (AFF) and the Digital Forensics XML (DFXML) metadata representation. ", "authors": "Kam Woods School of Information and Library Science University of North Carolina 216 Lenoir Drive, CB #3360 1-(919)-966-3598 kamwoods@email.unc.edu Christopher A. Lee School of Information and Library Science University of North Carolina 216 Lenoir Drive, CB #3360 1-(919)-962-7204 callee@ils.unc.edu Simson Garfinkel Graduate School of Operational and Information Sciences,  Naval Postgraduate School  Monterey, CA 1-(831)-656-3389 slgarfin@nps.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries〞 collection, dissemination, systems issues. General Terms Archiving, Digital Forensics, Disk Images. ", "id": "11_p057", "keywords": " Forensic Datasets; Digital Forensics XML (DFXML); Advanced Forensic Format (AFF); Long-Term Digital Preservation. ", "title": "Extending Digital Repository Architectures to Support Disk Image Preservation and Access\n"}, "11_p067": {"abstract": " Decisions in digital preservation pose the delicate mission of balancing desired goals of authentic long-term access with the technical means available to date. Organisations with a commitment to the long-term value of information and knowledge have to take decisions on several levels to achieve their business goals with the evolving technology of the day. This article explores the decision space in digital preser- vation, with a focus on what can be called the core decision: how to preserve content information. We undertake a crit- ical analysis of the challenges, constraints and objectives of decision making, and discuss the experience in applying the Planets preservation planning method, supported by the planning tool Plato, to real-world business decisions. Based on this methodology and substantial real-world experience in decision making, we present a set of observation points that address issues frequently raised in decision making. The conclusions shall contribute to a clarified understanding of the state of the art and future challenges in scalable decision making for long-term preservation. ", "authors": "Christoph Becker Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/?becker Andreas Rauber Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/?andi ", "categories": " H.3 [Information Storage and Retrieval]: H.3.7 Digital Libraries ", "id": "11_p067", "keywords": " Repositories, Digital Preservation, Preservation Planning, Decision Making General Terms Design, Documentation, Experimentation, Human Factors, Management, Measurement, Performance ", "title": "Preservation Decisions: Terms and Conditions Apply Challenges, Misperceptions and Lessons Learned in Preservation Planning\n"}, "11_p077": {"abstract": " This paper discusses the creation of Ember, a collection of born- digital artifacts generated in the aftermath of the 1999 Aggie Bonfire collapse. Ember is an example of a previously unexamined class of cultural heritage digital libraries, which we describe as a digital memorial museum. Ember＊s artifacts consist of emails, photos, documents, and web pages that the communities surrounding the tragedy created. Due to the community investment and the personal nature of the artifacts, concerns arise on how the collection should be properly handled, which leads us to propose ※Sensitivity§ as an addition to the 5S model. Initially, we are focusing on the email portion of the collection, which can be viewed as the basis of an emerging oral tradition surrounding the Bonfire tragedy. ", "authors": "Paul Logasa Bogen II and Richard Furuta Center for the Study of Digital Libraries and Department of Computer Science and Engineering Texas A&M University College Station, TX 77843 ember@csdl.tamu.edu ", "categories": " H.3.7 [Digital Libraries]: Collection, User issues. General Terms Experimentation, Design, Human Factors. ", "id": "11_p077", "keywords": " Ember, Digital Memorial Museums, Emotional Design. ", "title": "Ember: A Case Study of a Digital Memorial Museum of Born-Digital Artifacts\n"}, "11_p081": {"abstract": " We propose a digital library design to support epidemic and public health simulation experiments in which model ontolo- gies direct collection organization, user interface construc- tion, and discovery. We have developed a SimDL instanti- ation of the ontological design tailored for a typical experi- mentation workflow. SimDL relies on an XML Schema de- scription of a simulation model to form a domain and model specific ontology. We show this approach useful in building digital libraries to support collaborative simulation efforts. ", "authors": "Jonathan Leidig Network Dynamics and Simulation Science Laboratory, VBI; CS Virginia Tech, USA leidig@vt.edu Edward A. Fox Dept. of Computer Science Virginia Tech, USA fox@vt.edu Kevin Hall Network Dynamics and Simulation Science Laboratory, VBI Virginia Tech, USA khall@vbi.vt.edu Madhav Marathe Network Dynamics and Simulation Science Laboratory, VBI Virginia Tech, USA marathe@vt.edu Henning Mortveit Network Dynamics and Simulation Science Laboratory, VBI Virginia Tech, USA hmortvei@vbi.vt.edu ", "categories": ": H.3.7 [Information Storage and Retrieval]: Digital Libraries General Terms: Experimentation, Management ", "id": "11_p081", "keywords": ": Collections, Domain Ontologies, Simulations ", "title": "SimDL: A Model Ontology Driven Digital Library for Simulation Systems\n"}, "11_p085": {"abstract": " Entity resolution is the task of identifying entities that refer to the same real-world object. It has important applications in the con- text of digital libraries, such as citation matching and author disam- biguation. Blocking is an established methodology for efficiently addressing this problem; it clusters similar entities together, and compares solely entities inside each cluster. In order to effectively deal with the current large, noisy and heterogeneous data collec- tions, novel blocking methods that rely on redundancy have been introduced: they associate each entity with multiple blocks in order to increase recall, thus increasing the computational cost, as well. In this paper, we introduce novel techniques that remove the superfluous comparisons from any redundancy-based blocking method. They improve the time-efficiency of the latter without any impact on the end result. We present the optimal solution to this problem that discards all redundant comparisons at the cost of quadratic space complexity. For applications with space limita- tions, we also present an alternative, lightweight solution that oper- ates at the abstract level of blocks in order to discard a significant part of the redundant comparisons. We evaluate our techniques on two large, real-world data sets and verify the significant improve- ments they convey when integrated into existing blocking methods. ", "authors": "George Papadakis$,], Ekaterini Ioannou^, Claudia Nieder谷e], Themis Palpanas?, and Wolfgang Nejdl] $ National Technical University of Athens, Greece gpapadis@mail.ntua.gr ^ Technical University of Crete, Greece ioannou@softnet.tuc.gr ] L3S Research Center, Germany {surname}@L3S.de ? University of Trento, Italy themis@disi.unitn.eu ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering General Terms Algorithms, Experimentation, Performance ", "id": "11_p085", "keywords": " Data Cleaning, Entity Resolution, Redundancy-based Blocking ", "title": "Eliminating the Redundancy in Blocking-based Entity Resolution Methods\n"}, "11_p095": {"abstract": " Individuals contribute content on the Web at an unprece- dented rate, accumulating immense quantities of (semi-) structured data. Wisdom of the Crowds theory advocates that such information (or parts of it) is constantly overwrit- ten, updated, or even deleted by other users, with the goal of rendering it more accurate, or up-to-date. This is par- ticularly true for the collaboratively edited, semi-structured data of entity repositories, whose entity profiles are consis- tently kept fresh. Therefore, their core information that re- main stable with the passage of time, despite being reviewed by numerous users, are particularly useful for the description of an entity. Based on the above hypothesis, we introduce a classifica- tion scheme that predicts, on the basis of statistical and con- tent patterns, whether an attribute (i.e., name-value pair) is going to be modified in the future. We apply our scheme on a large, real-world, versioned dataset and verify its ef- fectiveness. Our thorough experimental study also suggests that reducing entity profiles to their stable parts conveys sig- nificant benefits to two common tasks in computer science: information retrieval and information integration. ", "authors": "George Papadakis$,], George Giannakopoulos?, Claudia Nieder谷e], Themis Palpanas?, and Wolfgang Nejdl] $ National Technical University of Athens, Greece gpapadis@mail.ntua.gr ? SKEL - NCSR Demokritos, Greece ggianna@iit.demokritos.gr ] L3S Research Center, Germany {surname}@L3S.de ? University of Trento, Italy themis@disi.unitn.eu ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering General Terms Algorithms, Experimentation, Performance ", "id": "11_p095", "keywords": " Entity Evolution, Stability Detection, N-gram graphs ", "title": "Detecting and Exploiting Stability in Evolving Heterogeneous Information Spaces\n"}, "11_p105": {"abstract": " User interest in topics and resources is known to be recurrent and to follow specific patterns, depending on the type of topic or resource. Traditional methods for predicting reoccurring patterns are based on ranking and associative models. In this paper, we identify sev- eral ＆canonical＊ patterns by clustering keywords related to visited resources, making use of a large repository of Web usage data. The keywords are derived from a ＆virtual＊ folksonomy of tags assigned to these resources, using a collaborative bookmarking system. ", "authors": "Ricardo Kawase L3S Research Center Hannover, Germany kawase@L3s.de Eelco Herder L3S Research Center Hannover, Germany herder@L3s.de ", "categories": " H.5.4 [Hypertext/Hypermedia]: User Issues General Terms Human Factors ", "id": "11_p105", "keywords": " Revisitation, Navigation support, Recommendation ", "title": "Classification of User Interest Patterns Using a Virtual Folksonomy\n"}, "11_p109": {"abstract": " If researchers use tags in retrieval applications they might assume, implicitly, that tags represent novel information, e.g., when they attribute performance improvement in their retrieval algorithm(s) to the use of tags. In this work, we investigate whether this assumption is true. We focus on the use of tags in domain-specific websites because such websites are more likely to have a coherent, discernible website structure and because the users that are searching for and tagging pages in such a site may have specific information needs (as opposed to the broad range of information needs that users have when browsing/searching the Internet at large). For this study, we assume that the application of the same tag to multiple pages provides an indication that those pages are related. To determine whether this indication of relatedness is contributing new information, we first measure whether pages with common tag(s) could have been deemed as related based on site structure as measured by shortest navigational distance between pages. Second, we measure whether or not tags could have been determined algorithmically based on standard tf-idf scores of terms on the page. Based on our analysis of two different sites, we found that tags contribute novel information that is not discernible from site structure or site/page content. ", "authors": "Jeremy Steinhauer,  Lois M. L. Delcambre, David Maier Computer Science Department Portland State University Portland, OR 97207-0751 USA +1 503 725 2405 {jsteinha, lmd, maier}@cs.pdx.edu Marianne Lykke Dept. of Commun. & Psychology Aalborg University Aalborg, Denmark +45 2125 1854 mlykke@hum.aau.dk   Vu H. Tran Computer Science Department Portland State University Portland, OR 97207-0751 USA tvu@cs.pdx.edu  ", "categories": " H.3.3[Information Storage and Retrieval]: Information Search and Retrieval General Terms Human Factors, Measurement, Verification  ", "id": "11_p109", "keywords": " Tags ", "title": "Tags in Domain-Specific Sites - New Information? \n"}, "11_p113": {"abstract": " A pattern is a model or a template used to summarize and describe the behavior (or the trend) of a data having gen- erally some recurrent events. Patterns have received a con- siderable attention in recent years and were widely studied in the data mining field. Various pattern mining approaches have been proposed and used for different applications such as network monitoring, moving object tracking, financial or medical data analysis, scientific data processing, etc. In these different contexts, discovered patterns were useful to detect anomalies, to predict data behavior (or trend), or more generally, to simplify data processing or to improve system performance. However, to the best of our knowl- edge, patterns have never been used in the context of web archiving. Web archiving is the process of continuously col- lecting and preserving portions of the World Wide Web for future generations. In this paper, we show how patterns of page changes can be useful tools to efficiently archive web sites. We first define our pattern model that describes the changes of pages. Then, we present the strategy used to (i) extract the temporal evolution of page changes, to (ii) discover patterns and to (iii) exploit them to improve web archives. We choose the archive of French public TV chan- nels France Te∩le∩visions as a case study1 in order to validate our approach. Our experimental evaluation based on real web pages shows the utility of patterns to improve archive quality and to optimize indexing or storing. ", "authors": "Myriam Ben Saad LIP6, University P. and M. Curie 4 place Jussieu 75005 Paris, France Myriam.Ben-Saad@lip6.fr St谷phane Gan?arski LIP6, University P. and M. Curie 4 place Jussieu 75005 Paris, France Stephane.Gancarski@lip6.fr ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing General Terms Algorithms, Design, Measurement 1This research is supported by the French National Research Agency ANR in the CARTEC Project (ANR-07-MDCO- 016). ", "id": "11_p113", "keywords": " Web Archiving, Web Page Changes, Pattern ", "title": "Archiving the Web using Page Changes Patterns: A Case Study\n"}, "11_p123": {"abstract": " Academic homepages are rich sources of information on sci- entific research and researchers. Most researchers provide in- formation about themselves and links to their research pub- lications on their homepages. In this study, we address the following questions related to academic homepages: (1) How many academic homepages are there on the web? (2) Can we accurately discriminate between academic homepages and other webpages? and (3) What information can be extracted about researchers from their homepages? For addressing the first question, we use mark-recapture techniques commonly employed in biometrics to estimate animal population sizes. Our results indicate that academic homepages comprise a small fraction of the Web making automatic methods for discriminating them crucial. We study the performance of content-based features for classifying webpages. We propose the use of topic models for identifying content-based features for classification and show that a small set of LDA-based fea- tures out-perform term features selected using traditional techniques such as aggregate term frequencies or mutual in- formation. Finally, we deal with the extraction of name and research interests information from an academic home- page. Term-topic associations obtained from topic models are used to design a novel, unsupervised technique to iden- tify short segments corresponding to research interests of the researchers specified in academic homepages. We show the efficacy of our proposed methods on all the three tasks by ex- perimentally evaluating them on multiple publicly-available datasets. ", "authors": "Sujatha Das Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 gsdas@cse.psu.edu C. Lee Giles, Prasenjit Mitra, Cornelia Caragea Information Science and Technology The Pennsylvania State University University Park, PA 16802 {giles, pmitra, ccaragea}@ist.psu.edu ", "categories": " H.3 [INFORMATION STORAGEANDRETRIEVAL]: Information Search and Retrieval〞Information filtering, Search process General Terms Algorithms ", "id": "11_p123", "keywords": " Latent Dirichlet Allocation, mark-recapture techniques, topic mixtures, webpage classification ", "title": "On Identifying Academic Homepages for Digital Libraries\n"}, "11_p133": {"abstract": " The Memento Project＊s archive access additions to HTTP have enabled development of new web archive access user interfaces. After experiencing this web time travel, the in- evitable question that comes to mind is ※How much of the Web is archived?§ This question is studied by approximating the Web via sampling URIs from DMOZ, Delicious, Bitly, and search engine indexes and measuring number of archive copies available in various public web archives. The results indicate that 35%每90% of URIs have at least one archived copy, 17%每49% have two to five copies, 1%每8% have six to ten copies, and 8%每63% at least ten copies. The number of URI copies varies as a function of time, but only 14.6每31.3% of URIs are archived more than once per month. ", "authors": "Scott G. Ainsworth, Ahmed AlSum, Hany SalahEldeen, Michele C. Weigle, Michael L. Nelson Old Dominion University Norfolk, VA, USA {sainswor, aalsum, hany, mweigle, mln}@cs.odu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries General Terms Design, Experimentation, Standardization ", "id": "11_p133", "keywords": " Web Architecture, HTTP, Resource Versioning, Web Archiv- ing, Temporal Applications, Digital Preservation ", "title": "How Much of the Web Is Archived?\n"}, "11_p137": {"abstract": " For discovering the new URI of a missing web page, lexical signatures, which consist of a small number of words chosen to represent the ※aboutness§ of a page, have been previously proposed. However, prior methods relied on computing the lexical signature before the page was lost, or using cached or archived versions of the page to calculate a lexical sig- nature. We demonstrate a system of constructing a lexical signature for a page from its link neighborhood, that is the ※backlinks§, or pages that link to the missing page. After testing various methods, we show that one can construct a lexical signature for a missing web page using only ten backlink pages. Further, we show that only the first level of backlinks are useful in this effort. The text that the back- links use to point to the missing page is used as input for the creation of a four-word lexical signature. That lexical sig- nature is shown to successfully find the target URI in more than half of the test cases. ", "authors": "Martin Klein Dept of Computer Science Old Dominion University Norfolk, VA, 23529 mklein@cs.odu.edu Jeb Ware Dept of Computer Science Old Dominion University Norfolk, VA, 23529 jware@cs.odu.edu Michael L. Nelson Dept of Computer Science Old Dominion University Norfolk, VA, 23529 mln@cs.odu.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Measurement, Performance, Design ", "id": "11_p137", "keywords": " Web Page Discovery, Preservation, Link Neighborhood ", "title": "Rediscovering Missing Web Pages Using Link Neighborhood Lexical Signatures\n"}, "11_p141": {"abstract": " Sharing news is a popular activity in social media and influence both individuals and society. However, little empirical research has been conducted to explore the motivations underlying users＊ news sharing behavior. Adopting the uses and gratifications perspective, this study examined the role of gratification factors and user experience in explaining users＊ news sharing intention on social media. Hierarchical regression was employed to analyze the data collected from 144 undergraduate and graduate students. The results show that status seeking was the strongest motivation in predicting news sharing intention, followed by sociality and informativeness. However, entertainment/escapism was not a significant predictor in contrast to prior work. Further, we examined user experience in predicting news sharing intention and identified it as a significant factor.  ", "authors": "Long Ma Wee Kim Wee School of Communication and Information Nanyang Technological University  malo0001@ntu.edu.sg Chei Sian Lee Wee Kim Wee School of Communication and Information Nanyang Technological University  leecs@ntu.edu.sg Dion Hoe-Lian Goh Wee Kim Wee School of Communication and Information Nanyang Technological University  ashlgoh@ntu.edu.sg  ", "categories": " J.4 [Computer Applications]: Social and Behavioral Sciences; H.3.5 [Online Information Services]: Data sharing.  General Terms Human Factors, Theory, Experimentation. ", "id": "11_p141", "keywords": " Social media, news sharing, gratifications, personal experience ", "title": "That＊s News to Me: The Influence of Perceived Gratifications and Personal Experience on News Sharing in Social Media\n"}, "11_p145": {"abstract": " In conjunction with Iowa City＊s designation as a UNESCO ※City of Literature,§ an interdisciplinary research team at The Univer- sity of Iowa collaborated to develop a digital library featuring important Iowa City authors and locations. The ※City of Lit§ digi- tal library consists of a mobile application for the general public and a set of web-based interfaces for researchers and content crea- tors. This paper explains the motivation and describes the design and implementation of the digital library, its framework, the user- side mobile app and our future plans. We also outline a pilot study, in which undergraduate students conducted scholarly re- search and created content for the digital collection. ", "authors": "Haowei Hsieh1, Bridget Draxler2, Nicole Dudley1, Jim Cremer3,  Lauren Haldeman4, Dat Nguyen3, Peter Likarish3, Jon Winet5 School of Library & Information Science1, Department of English2, Computer Science Department3,  Virtual Writing University4, Intermedia Program5 The University of Iowa, Iowa City, Iowa, USA 1-319-335-5713 {haowei-hsieh, bridget-draxler, nicole-dudley, jon-winet}@uiowa.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 Collection. K.3.1 [Computers and Education]: Computer Uses in Education 每 Collaborative learning. General Terms Design, Experimentation, Human Factors. ", "id": "11_p145", "keywords": ": Digital libraries, iPhone application, mobile de- vices, digital humanities, literary research. ", "title": "Facilitating Content Creation and Content Research in Building the ※City of Lit§ Digital Library \n"}, "11_p149": {"abstract": " In CADAL, there preserve a lot of Chinese classical literatures, including graceful prose and verse. These works written in ancient Chinese comparatively are concise in vocabulary and sentence patterns. But they express rich feelings and convey a wealth of information. Although can be explained in modern Chinese, the aesthetic sense in those works disappears. So we aim to illustrate the feeling in these works using Chinese traditional music which is also another part of Chinese culture. This is an interesting and challenging work. In this paper, the correlation between the text and music is studied. A novel approach is proposed to model the latent semantic association underlying the two medium. Based on the correlation model we learned from training data, we can associate a literary work (mainly verse and prose in our digital library) with a few music pieces automatically. When a reader is appreciating a literary work, a piece of background music is playing meanwhile, the information and emotion implied by the work and music blend together. The reader may be immersed into the emotion and obtain aesthetic enjoyment intensively. We implement the proposed method and design experiments to evaluate the performance of it. The experimental result substantiates the feasibility of the proposed approach in this paper. ", "authors": "Ling Zhuang College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China zhuangling2000@yahoo.com.cn Zhenchao Ye College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China yzc617@gmail.com Jiangqin Wu College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China wujq@zju.edu.cn Feng Zhou College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China 657067487@qq.com Jian Shao College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China jshao@zju.edu.cn ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.7 [Digital Libraries]: System Issues General Terms: Algorithms, Experimentation ", "id": "11_p149", "keywords": ": Canonical Correlation Analysis, Latent Semantic Analysis, Bag of Words Model ", "title": "Towards a New Reading Experience via Semantic Fusion of Text and Music \n"}, "11_p153": {"abstract": " With the growing presence of large collections of musical content, methods for facilitating efficient browsing and fast comparisons of audio pieces become more and more useful. Notably, methods that isolate relevant parts in audio pieces give an insight of the musical content and can be used to improve similarity evaluation systems. In this context, we propose an indexing method that allows retrieving in au- dio signals particular parts, namely a major repetition. We use harmonic representations together with string match- ing techniques to strictly define and isolate such segments. Experiments on state-of-the-art structural datasets show a strong correlation between the retrieved parts and the per- ceived structure of pieces. ", "authors": "Benjamin Martin, Pierre Hanna, Matthias Robine, Pascal Ferraro Labri, University of Bordeaux 351, cours de la Lib谷ration Talence, France firstname.name@labri.fr ", "categories": " H.3 [Information Storage and Retrieval]: Content Anal- ysis and Indexing〞Indexing Methods; J.5 [Arts and Hu- manities]: Music General Terms Algorithms ", "id": "11_p153", "keywords": " Audio Indexing, Music Information Retrieval ", "title": "Indexing Musical Pieces Using their Major Repetition\n"}, "11_p157": {"abstract": " This paper presents the results of a study of the ownership and reuse of visual media. A survey was administered to 250 social media-savvy respondents to investigate their attitudes about saving, sharing, publishing, and removing online photos; the survey also explored participants＊ current photo-sharing and reuse practices, and their general expectations of photo reuse. Our probe of respondent attitudes revealed that respondents felt: (1) people should be able to save visual media, regardless of its source; (2) people have slightly less right to reuse photos than they do to save them; (3) a photo＊s subject has a slightly greater right than the photographer to reuse the photo in non-commercial situations; (4) removal is controversial, but trends more positive when it involves only metadata (e.g. tags); and (5) access to institutional archives of personal photos is better deferred for 50 years. Participants explained their own reuse of online photos in pragmatic terms that included the nature of the content, the aim and circumstances of reuse, their sense of the photo＊s original use, and their understanding of existing laws and restrictions. In the abstract, the same general question revealed a ＆reuse paradox＊; while respondents trust themselves to make this judgment, they do not trust the reciprocal judgment of unknown others.  ", "authors": "Catherine C. Marshall  Microsoft Research, Silicon Valley 1065 La Avenida Mountain View, CA 94043 1-650-693-1308 cathymar@microsoft.com Frank M. Shipman Department of Computer Science Texas A&M University College Station, TX 77843-3112 1-979-862-3216 shipman@cs.tamu.edu  ", "categories": " H4.3. Information Systems: Communications Applications General Terms Design, Experimentation, Human Factors, Legal Aspects. ", "id": "11_p157", "keywords": " Digital photos, social media, information rights, survey, reuse. ", "title": "The Ownership and Reuse of Visual Media \n"}, "11_p167": {"abstract": " In the process of digitizing a book, a library needs to clear the rights associated with it. Rights clearance is a time consuming process, and possibly, with higher costs than the actual digitization. To analyze the rights situation, a range of information is required, which is distributed across several national databases hosted in national libraries, publishers and collective rights organizations. National bibliographies are key data sources in these processes, as they are the only source to identify all the publications of a specific intellectual work per country. However, national bibliographies are not built for rights clearance purposes. The information in bibliographic records results from cataloguing practices with users and library management in mind, and links between different publications of a single intellectual work are not available. This paper presents a study on the implications of data quality problems of national bibliographies for the identification of all publications of a work. It also presents an approach for work data extraction and matching based on similarity of the most discriminatory attributes of works. Evaluation has shown that the data quality problems are difficult to overcome, as our best approach achieved an F0,5-measure of 0,91. These results help to speed up the process of discovering all relevant publications per work significantly, with sufficient recall. ", "authors": " Nuno Freire, Andreas Juffinger The European Library, National Library of the Netherlands Willem-Alexanderhof 5 2509 LK The Hague, Netherlands nfreire@gmail.com, Andreas.Juffinger@KB.nl  ", "categories": " H.3.6 [Library automation]: Measurement, Algorithms, Experimentation; E.1 [Data Structures] 每 Records; H.3.7 [Digital Libraries]: Standards, System issues;  General Terms Algorithms, Measurement, Experimentation. ", "id": "11_p167", "keywords": " Information extraction, work entity matching, national bibliographies, library catalogues, copyright. ", "title": "Using National Bibliographies for Rights Clearance \n"}, "11_p175": {"abstract": " In this paper we present a model based on the principles of Linked Data that can be used to describe the interrelationships of images, texts and other resources to facilitate the interoperability of repositories of medieval manuscripts or other culturally important handwritten documents. The model is designed from a set of requirements derived from the real world use cases of some of the largest digitized medieval content holders, and instantiations of the model are intended as the input to collection-independent page turning and scholarly presentation interfaces. A canvas painting paradigm, such as in PDF and SVG, was selected based on the lack of a one to one correlation between image and page, and to fulfill complex requirements such as when the full text of a page is known, but only fragments of the physical object remain. The model is implemented using technologies such as OAI-ORE Aggregations and OAC Annotations, as the fundamental building blocks of emerging Linked Digital Libraries. The model and implementation are evaluated through prototypes of both content providing and consuming applications. Although the system was designed from requirements drawn from the medieval manuscript domain, it is applicable to any layout-oriented presentation of images of text. ", "authors": "Robert Sanderson Los Alamos National Laboratory Los Alamos NM 87544, USA +1 (505) 665-5804 rsanderson@lanl.gov Benjamin Albritton Stanford University Stanford CA 94305, USA +1 (605) 387-8678 blalbrit@stanford.edu Rafael Schwemmer e-codices Rue de l'Hopital 4 CH-1700 Fribourg, Switzerland +41 (26) 300-7919 rafael.schwemmer@unifr.ch Herbert Van de Sompel Los Alamos National Laboratory Los Alamos NM 87544, USA +1 (505) 667-1267 herbertv@lanl.gov  ", "categories": " H.5.4 [Information Interfaces and Presentation]: Hypertext/ Hypermedia 每 Architectures, Navigation.  General Terms Design, Experimentation, Standardization ", "id": "11_p175", "keywords": " Digital Humanities, Annotation, Web Architecture, Document Layout, Interoperability  ", "title": "SharedCanvas: A Collaborative Model for Medieval Manuscript Layout Dissemination \n"}, "11_p185": {"abstract": " Many scholarly tasks involve working with subdocuments, or contextualized fine-grain information, i.e., with information that is part of some larger unit. A digital library (DL) facil- itates management, access, retrieval, and use of collections of data and metadata through services. However, most DLs do not provide infrastructure or services to support working with subdocuments. Superimposed information (SI) refers to new information that is created to reference subdocu- ments in existing information resources. We combine this idea of SI with traditional DL services, to define and develop a DL with SI (SI-DL). We explored the use of subimages and evaluated the use of SuperIDR, a prototype SI-DL, in fish species identification, a scholarly task that involves work- ing with subimages. The contexts and strategies of working with subimages in SuperIDR suggest new and enhanced sup- port (SI-DL services) for scholarly tasks that involve work- ing with subimages, including new ways of querying and searching for subimages and associated information. The main conceptual contributions of our work are the insights gained from these findings of the use of subimages and of SuperIDR, which lead to recommendations for the design of digital libraries with superimposed information. ", "authors": "Uma Murthy1, Lin Tzy Li1,2,3, Eric Hallerman3, Edward A. Fox1, Manuel A. P谷rez-Qui?ones1, Lois M. Delcambre4, and Ricardo da S. Torres2 1Department of Computer Science, Virginia Tech, Blacksburg, VA 24061 2Institute of Computing, University of Campinas, SP, Brazil, 13083-852 3Telecommunications Res. & Dev. Center, CPqD Foundation, Campinas, SP, Brazil, 13086-902 4Department of Fisheries and Wildlife Sciences, Virginia Tech, Blacksburg, VA 24061 5Department of Computer Science, Portland State University, Portland OR {umurthy, ehallerm, fox, mperezqu}@vt.edu, {lintzyli, rtorres}@ic.unicamp.br, lmd@cs.pdx.edu ", "categories": " H.3.7 [Digital Libraries]: [User issues]; H.5 [Information Interfaces and Presentation]: [Evaluation/ methodol- ogy]; J.3 [Life and medical sciences]: [Biology and ge- netics] General Terms Human factors ", "id": "11_p185", "keywords": "", "title": "Use of Subimages in Fish Species Identification: A Qualitative Study\n"}, "11_p195": {"abstract": " Some digital libraries support annotations, but sharing these annotations with other systems or across the web is diffi- cult because of the need of special applications to read and decode these annotations. Due to the frequent change of web resources, the annotation＊s meaning can change if the underlying resources change. This project concentrates on minting a new URI for every annotation and creating a per- sistent and independent archived version of all resources. Users should be able to select a segment of an image or a video to be part of the annotation. The media fragment URIs described in the Open Annotation Collaboration data model can be used, but in practice they have limits, and they face the lack of support by the browsers. So in this project the segments of images, and videos can be used in the annotations without using media fragment URIs. ", "authors": "Abdulla Alasaadi Old Dominion University Computer Science Department Norfolk, VA 23529, USA aalasaad@cs.odu.edu Michael L. Nelson Old Dominion University Computer Science Department Norfolk, VA 23529, USA mln@cs.odu.edu ", "categories": " H.3.5 [Online Information Services]: Data Sharing, Web- based services General Terms Design, Reliability ", "id": "11_p195", "keywords": " Web Archiving, Persistence, Annotation, URI ", "title": "Persistent Annotations Deserve New URIs\n"}, "11_p199": {"abstract": " Historic maps are valuable scholarly resources that record information often retained by no other written source. With the YUMA Map Annotation Tool we want to facilitate col- laborative annotation for scholars studying historic maps, and allow for semantic augmentation of annotations with structured, contextually relevant information retrieved from Linked Open Data sources. We believe that the integration of Web resource linkage into the scholarly annotation pro- cess is not only relevant for collaborative research, but can also be exploited to improve search and retrieval. In this paper, we introduce the COMPASS Experiment, an ongo- ing crowdsourcing effort in which we are collecting data that can serve as a basis for evaluating our assumption. We dis- cuss the scope and setup of the experiment framework and report on lessons learned from the data collected so far. ", "authors": "Rainer Simon AIT Austrian Institute of Technology Vienna, Austria rainer.simon@ait.ac.at Bernhard Haslhofer University of Vienna Liebiggasse 4/3-4 Vienna, Austria haslhofer@cs.univie.ac.at Werner Robitza University of Vienna Liebiggasse 4/3-4 Vienna, Austria robitza@cs.univie.ac.at Elaheh Momeni University of Vienna Liebiggasse 4/3-4 Vienna, Austria momeni@cs.univie.ac.at ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval〞Retrieval models; H.3.7 [Information Storage and Retrieval]: Digital Libraries〞User issues General Terms Experimentation, Verification ", "id": "11_p199", "keywords": " Maps, Annotation, Linked Data, Tagging, Crowdsourcing ", "title": "Semantically Augmented Annotations in Digitized Map Collections\n"}, "11_p203": {"abstract": " We need to harness the growing wealth of information in digital libraries to support intellectual work involving creative and exploratory processes. Prior research on hypertext authoring shifted the focus from explicit structure to direct presentation of content aided by ※implicit§ spatial representation of structure. We likewise shift the field of information visualization. Using hypertext's rubric, we redefine what most people think of as \"information visualization\" as explicit structure visualization. We alternatively address implicit structure visualization, presenting content directly, representing structure with spatiality and other visual features. We integrate authoring to emphasize the role of human thought in learning and ideation. Prior research has shown that people iteratively collect and organize information by clipping magazines, piling clippings in somewhat messy ways, and organizing them.  MessyOrganizer is an iterative implicit structure visualization algorithm which, like human practice, gradually collects and organizes information clippings. Content is depicted directly. Structural relationships are visualized implicitly through spatial positioning of related elements, with overlap and translucence. The simulated annealing algorithm is applied to a model of semantic relatedness over a spatial grid. We develop an experiment comparing products created with the integrated environment versus separated visualization and authoring spaces. Results reveal that participants have more novel and varied ideas when visualization is integrated with authoring.  ", "authors": "Andrew M. Webb and Andruid Kerne Interface Ecology Lab Dept. of Computer Science & Engineering, Texas A&M University {andrew, andruid}@ecologylab.net   ", "categories": " H.5.m [Information Systems]: Information Interfaces and Presentation 每 miscellaneous. General Terms Algorithms, Design, Experimentation, Human Factors ", "id": "11_p203", "keywords": " creativity support tools, information visualization, authoring ", "title": "Integrating Implicit Structure Visualization with Authoring Promotes Ideation \n"}, "11_p213": {"abstract": " This paper presents the design rationale and initial findings derived from preliminary usage of OntoStarFish, a visualization technique aimed at taking advantage of implicit relationships that can be inferred from large collections of documents in digital libraries. OntoStarFish makes such relationships explicit so users may visualize them and detect potential collaboration networks. Users that may be interested in exploring collaboration networks include researchers looking for partners for specific projects as well as funding agencies concerned with the strength of associations among participants of competing proposals. OntoStarFish is based upon the use of multiple fisheye views that can be placed on top of starfields, dynamic scatter plots for which each axis is determined by a lightweight ontology of attributes associated to potential collaborators. ", "authors": "J. Alfredo S芍nchez, Ofelia Cervantes, Alfredo Ramos Universidad de las Am谷ricas Puebla Santa Catarina M芍rtir S/N  Cholula, Puebla, Mexico +52-222-229-2666 ?alfredo.sanchez, ofelia.cervantes}@udlap.mx, alfred.exe@gmail.com Maria Auxilio Medina Universidad Polit谷cnica de Puebla San Mateo Cuanal芍 S/N,  Puebla, Pue. +52- 222-774-6641 mauxmedina@gmail.com Juan Carlos Lavariega,  Eric Balam ITESM-Monterrey Av. E. Garza Sada 2501, Monterrey, NL, Mexico +52 (81) 8358-1400ext. 5250 lavariega@itesm.mx, eric_bs21@hotmail.com ", "categories": " H.5.2 [User Interfaces] Graphical User Interfaces. General Terms Design, Human Factors. ", "id": "11_p213", "keywords": " Visualization, collaboration networks, implicit knowledge, network detection, fisheye views, starfields, taxonomic axes. ", "title": "Visualizing Collaboration Networks Implicit in Digital Libraries using OntoStarFish \n"}, "11_p223": {"abstract": " This paper introduces H身para, a new search engine that aims to make Wikipedia easier to explore. It works on top of the encyclopedia＊s existing link structure, abstracting away from document content and allowing users to navigate the resource at a higher level. It utilizes semantic relatedness measures to emphasize articles and connections that are most likely to be of interest, visualization to expose the structure of how the available information is organized, and lightweight information extraction to explain itself. ", "authors": "David Milne    Ian H. Witten Department of Computer Science, University of Waikato Private Bag 3105, Hamilton, New Zealand +64 7 838 4246 {dmilne, ihw}@cs.waikato.ac.nz   ", "categories": " H.5.4 [Information Interfaces and Presentation]: Hypertext/Hypermedia 每 navigation, user issues. General Terms Experimentation, Human Factors. ", "id": "11_p223", "keywords": " Exploratory Search, Information Visualization, Information Retrieval, Wikipedia, Semantic Relatedness. ", "title": "A Link-based Visual Search Engine for Wikipedia \n"}, "11_p227": {"abstract": " Web browsers provide only little support for users to revisit pages that they do not visit very often. We developed a browser toolbar that reminds users of already visited pages that are relevant to the page they are currently viewing. The toolbar makes use of a rec- ommendation method that combines ranking methods with propa- gation methods. Our user evaluation shows that, on average, 22.7% of the revisits were triggered by the toolbar, thus accounting for a considerable change in the participants＊ revisitation routines. In this paper, we discuss the value of the recommendations and the implications derived from the evaluation. ", "authors": "Ricardo Kawase L3S Research Center Hannover, Germany kawase@L3s.de George Papadakis ICCS, NTUA Athens, Greece gpapadis@mail.ntua.gr Eelco Herder L3S Research Center Hannover, Germany herder@L3s.de ", "categories": " H.5.4 [Hypertext/Hypermedia]: User Issues General Terms Experimentation, Human Factors ", "id": "11_p227", "keywords": " Revisitation, Navigation support, Recommendation ", "title": "Supporting Revisitation with Contextual Suggestions\n"}, "11_p231": {"abstract": " Collaborative research has been increasingly popular and important in academic circles. However, there is no open platform available for scholars or scientists to effectively dis- cover potential collaborators. This paper discusses Collab- Seer, an open system to recommend potential research col- laborators for scholars and scientists. CollabSeer discovers collaborators based on the structure of the coauthor net- work and a user＊s research interests. Currently, three dif- ferent network structure analysis methods that use vertex similarity are supported in CollabSeer: Jaccard similarity, cosine similarity, and our relation strength similarity mea- sure. Users can also request a recommendation by selecting a topic of interest. The topic of interest list is determined by CollabSeer＊s lexical analysis module, which analyzes the key phrases of previous publications. The CollabSeer sys- tem is highly modularized making it easy to add or replace the network analysis module or users＊ topic of interest anal- ysis module. CollabSeer integrates the results of the two modules to recommend collaborators to users. Initial exper- imental results over the a subset of the CiteSeerX database shows that CollabSeer can efficiently discover prospective collaborators. ", "authors": "Hung-Hsuan Chen?, Liang Gou?, Xiaolong (Luke) Zhang?, C. Lee Giles?? ?Computer Science and Engineering ?Information Sciences and Technology The Pennsylvania State University hhchen@psu.edu, {lug129, lzhang, giles}@ist.psu.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval〞relevance feedbacks, retrieval models, selection process; H.3.7 [Information Storage and Re- trieval]: Digital Library〞Collections, Dissemination; J.4 [Social and Behavior Sciences]: Sociology General Terms Design, Algorithms, Experimentation ", "id": "11_p231", "keywords": " Social Network, Coauthor Network, Graph Theory, Link Analysis, Digital Library, Information Retrieval ", "title": "CollabSeer: A Search Engine for Collaboration Discovery\n"}, "11_p241": {"abstract": " We investigate how author name homonymy distorts clus- tered large-scale co-author networks, and present a simple, effective, scalable and generalizable algorithm to ameliorate such distortions. We evaluate the performance of the al- gorithm to improve the resolution of mesoscopic network structures, that is those meso-level structures of a network resulting from groupings of nodes and their interlinking. To this end, we establish the ground truth for a sample of author names that is statistically representative of different types of nodes in the co-author network, distinguished by their role for the connectivity of the network. We finally observe that this distinction of node roles based on the mesoscopic struc- ture of the network, in combination with a quantification of the commonality of last names, suggests a new approach to assess network distortion by homonymy and to analyze the reduction of distortion in the network after disambiguation, without requiring ground truth sampling. ", "authors": "Theresa Velden Department of Information Science Cornell University 301 College Avenue Ithaca, NY 14853 tav6@cornell.edu Asif-ul Haque Department of Computer Science Cornell University 4143 Upson Hall Ithaca, NY 14853 asif@cs.cornell.edu Carl Lagoze Department of Information Science Cornell University 301 College Avenue Ithaca, NY 14853 cjl2@cornell.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Information Retrieval; I.5.2 [Pattern Recognition]: Classifier Design and Evaluation General Terms Algorithms, Experimentation, Measurement ", "id": "11_p241", "keywords": " Scientific Communication, Name Disambiguation, Co-author Networks ", "title": "Resolving Author Name Homonymy to Improve Resolution of Structures in Co-author Networks\n"}, "11_p251": {"abstract": " Searching for people with expertise on a particular topic also known as expert search is a common task in digital li- braries. Most models for this task use only documents as evidence for expertise while ranking people. In digital li- braries, other sources of evidence are available such as a document＊s association with venues and citation links with other documents. We propose graph-based models that ac- commodate multiple sources of evidence in a PageRank-like algorithm for ranking experts. Our studies on two publicly- available datasets indicate that our model despite being gen- eral enough to be directly useful for ranking other types of objects performs on par with probabilistic models commonly used for expert ranking. ", "authors": "Sujatha Das Computer Science and Engineering The Pennsylvania State University University Park, PA-16802 gsdas@cse.psu.edu Prasenjit Mitra, C. Lee Giles Information Sciences and Technology The Pennsylvania State University University Park, PA-16802 {pmitra, giles}@ist.psu.edu ", "categories": " H.3.3 [INFORMATION STORAGE ANDRETRIEVAL]: Information Search and Retrieval〞Retrieval Models General Terms Algorithms ", "id": "11_p251", "keywords": " PageRank, Expertise Search ", "title": "Ranking Authors in Digital Libraries\n"}, "11_p255": {"abstract": " Various approaches for plagiarism detection exist. All are based on more or less sophisticated text analysis methods such as string matching, fingerprinting or style comparison. In this paper a new approach called Citation-based Plagiarism Detection is evaluated using a doctoral thesis [8], in which a volunteer crowd-sourcing project called GuttenPlag [1] identified substantial amounts of plagiarism through careful manual inspection. This new approach is able to identify similar and plagiarized documents based on the citations used in the text. It is shown that citation-based plagiarism detection performs significantly better than text-based procedures in identifying strong paraphrasing, translation and some idea plagiarism. Detection rates can be improved by combining citation-based with text-based plagiarism detection.  ", "authors": " Bela Gipp OvGU, Germany & UC Berkeley  gipp@berkeley.edu Norman Meuschke OvGU, Germany & UC Berkeley nmeuschk@st.ovgu.de  Joeran Beel OvGU, Germany & UC Berkeley jbeel@berkeley.org  ", "categories": " H.3.3 [Clustering]: INFORMATION STORAGE AND RETRIEVAL 每 Information Search and Retrieval.  General Terms Algorithms, Experimentation, Measurement, Languages ", "id": "11_p255", "keywords": " Plagiarism Detection Systems, Citation-based Plagiarism Detection ", "title": "Comparative Evaluation of Text- and Citation-based Plagiarism Detection Approaches using GuttenPlag \n"}, "11_p259": {"abstract": " With the growth in operational digital libraries, the need for automatic methods capable of characterizing adoption and use has grown. We describe a computational methodology for producing two, inter-related, user typologies based on use diffusion. Use diffusion theory views technology adop- tion as a process that can lead to widely different patterns of use across a given population of potential users; these mod- els use measures of frequency and variety to characterize and describe these usage patterns. The methodology uses computational techniques such as clickstream entropy and clustering to produce both coarse-grained and fine-grained user typologies. A case study demonstrates the utility and applicability of the method: it is used to understand how middle and high school science teachers participating in an academic year-long field trial adopted and integrated dig- ital library resources into their instructional planning and teaching. The resulting fine-grained user typology identified five different types of teacher-users, including※interactive re- source specialists§ and ※community seeker specialists.§ This typology was validated through comparison with qualitative and quantitative data collected using traditional educational field research methods. ", "authors": "Keith E. Maull Institute of Cognitive Science Dept. of Computer Science University of Colorado Boulder, Colorado 80309 maull@colorado.edu Manuel Gerardo Saldivar Institute of Cognitive Science School of Education University of Colorado Boulder, Colorado 80309 saldivar@colorado.edu Tamara Sumner Institute of Cognitive Science Dept. of Computer Science University of Colorado Boulder, Colorado 80309 sumner@colorado.edu ", "categories": " H.1.2 [Information Systems]: Models and Principles〞 User/Machine Systems; H.3.7 [Information Systems]: In- formation Storage and Retrieval〞User Issues; J.1 [Computer Applications]: Adminstrative Data Processing〞Education General Terms Experimentation,Human Factors ", "id": "11_p259", "keywords": " Technology adoption, diffusion of innovation, use diffusion models, educational digital libraries ", "title": "Understanding Digital Library Adoption: A Use Diffusion Approach\n"}, "11_p269": {"abstract": " Users＊ search tactics often appear na?ve. Much research has endeavored to understand the rudimentary query typically seen in log analyses and user studies. Researchers have tested a number of approaches to supporting query development, including information literacy training and interaction design these have tried and often failed to induce users to use more complex search strategies. To further investigate this phenomenon, we combined established HCI methods with models from cultural studies, and observed customers＊ mediated searches for books in bookstores. Our results suggest that sophisticated search techniques demand mental models that many users lack. ", "authors": "George Buchanan Centre for HCI Design City University, Northampton Square London, EC1V 0HB, UK +44 20 7040 8469 george.buchanan.1@city.ac.uk Dana McKay  Library, Institute for Social Research  Swinburne University of Technology Hawthorn, VIC 312, Australia  +61392145023, dmckay@swin.edu.au  ", "categories": " H.3.7 [Digital Libraries]: User Issues.  General Terms Design, Human Factors ", "id": "11_p269", "keywords": " Query formulation, bookstores, observation, material culture ", "title": "In the Bookshop: Examining Popular Search Strategies \n"}, "11_p279": {"abstract": " Although initiatives are underway in the educational community to consolidate disparate collections of educational standards, little has been done to explore the impact of educational standard formulation on information retrieval. Recent research contrasts two categories of educational standards: ＆World＊ (topical domain- related concepts) and ＆Method＊ (investigative and epistemological principles). This paper explores the information retrieval implications of the World vs. Method distinction. We find that experts are more likely to agree about which educational resources align with a Method standard but that a typical automatic standard assignment tool is more likely to assign a World standard to an educational resource. Further, a text-based information retrieval system is more likely to be accurate in retrieving documents relevant to a World standard as compared to a Method standard. These findings have implications both for educational standard formulation (combining World and Method components in a standard may improve retrieval) and for digital library builders who want to help teachers identify useful, standards-aligned learning objects. ", "authors": "Byron Marshall Oregon State University, College of Business byron.marshall@bus.oregonstate.edu Ren谷 Reitsma Oregon State University, College of Business reitsmar@bus.oregonstate.edu  ", "categories": " K.3.1 [Computer Uses in Education]  General Terms: Design, Experimentation, Human Factors ", "id": "11_p279", "keywords": ": Educational standards; standard assignment; standard types; epistemological; methodological ", "title": "World vs. Method: Educational Standard Formulation Impacts Document Retrieval \n"}, "11_p283": {"abstract": " Assessing the quality of online educational resources in a cost effective manner is a critical issue for educational digital libraries. This study reports on the approach for extending the Open Educational Resource Assessments (OPERA) algorithm from assessing vetted to peer-produced content. This article reports details of changes to the algorithm, comparisons between human raters and the algorithm, and the extent the algorithm can automate the review process.  ", "authors": "Heather Leary, Mimi Recker, Andrew Walker Utah State University 2830 Old Main Hill Logan, Utah 84322 1.435.797.2692 heatherleary@gmail.com Philipp Wetzler, Tamara Sumner, James Martin University of Colorado 594 UCB Boulder, CO, USA 1.303.735.4469 philipp.wetzler@colorado.edu ", "categories": " K.3 [Computers and Education]: Computer Uses in Education - Collaborative Learning General Terms Design, Reliability, Human Factors, Standardization. ", "id": "11_p283", "keywords": " Education Digital Library, Resource Quality, Machine Learning. ", "title": "Automating Open Educational Resources Assessments: A Machine Learning Generalization Study \n"}, "11_p287": {"abstract": " A book recommender system is very useful for a digital library. Good book recommender systems can effectively help users find interesting and relevant books from the massive resources, by providing individual recommendation book list for each end-user. By now, a variety of collaborative filtering algorithms have been invented, which are the cores of most recommender systems. However, because of the explosion of information, especially in the Internet, the improvement of the efficiency of the collabora- tive filting (CF) algorithm becomes more and more important. In this paper, we first propose a parallel Top-N recommendation algorithm in CUDA (Compute Unified Device Architecture) which combines the collaborative filtering and trust-based ap- proach to deal with the cold-start user problem. Then based on this algorithm, we present a parallel book recommender system on a GPU (Graphics Processor unit) for CADAL digital library plat- form. Our experimental results show our algorithm is very effi- cient to process the large-scale datasets with good accuracy, and we report the impact of different values of parameters on the rec- ommendation performance. ", "authors": "Ruifeng Li College of Computer Science, Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 liruifeng426@gmail.com Xiaojun Wang College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 xjwang1987@gmail.com Yin Zhang College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 zhangyin98@zju.edu.cn Jiangqin Wu College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 wujq@zju.edu.cn Haihan Yu College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 yuhaihan@zju.edu.cn         Baogang Wei College of Computer Science Zhejiang University 38 Zhe-Da Road, Hangzhou, China +86-571-87952300 wbg@zju.edu.cn  ", "categories": " H.3.3 [Information Search and Retrieval]: Information filter- ing; H.3.7 [Digital Libraries]: System Issues General Terms Algorithms, Experimentation ", "id": "11_p287", "keywords": " Digital Library, Collaborative Filtering, Recommendation, GPU, CUDA  ", "title": "A Social Network-Aware Top-N Recommender System using GPU \n"}, "11_p297": {"abstract": " As the number of research papers available on the Web has increased enormously over the years, paper recommender systems have been proposed to help researchers on auto- matically finding works of interest. The main problem with the current approaches is that they assume that recommend- ing algorithms are provided with a rich set of evidence (e.g., document collections, citations, profiles) which is normally not widely available. In this paper we propose a novel source independent framework for research paper recommendation. The framework requires as input only a single research pa- per and generates several potential queries by using terms in that paper, which are then submitted to existing Web information sources that hold research papers. Once a set of candidate papers for recommendation is generated, the framework applies content-based recommending algorithms to rank the candidates in order to recommend the ones most related to the input paper. This is done by using only pub- licly available metadata (i.e., title and abstract). We eval- uate our proposed framework by performing an extensive experimentation in which we analyzed several strategies for query generation and several ranking strategies for paper recommendation. Our results show that good recommenda- tions can be obtained with simple and low cost strategies. ", "authors": "Cristiano Nascimento1 Alberto H. F. Laender1 Altigran S. da Silva2 Marcos Andr谷 Gon?alves1 1Universidade Federal de Minas Gerais Departamento de Ci那ncia da Computa??o Belo Horizonte, MG, Brazil {crist, laender, mgoncalv}@dcc.ufmg.br 2Universidade Federal do Amazonas Departamento de Ci那ncia da Computa??o Manaus, AM, Brazil alti@dcc.ufam.edu.br ", "categories": " H.3.3 [Information Storage and Retrieval]: Informa- tion Search and Retrieval〞information filtering, retrieval models, search process; H.3.7 [Information Storage and Retrieval]: Digital Libraries General Terms Algorithms, Experimentation ", "id": "11_p297", "keywords": " Content-Based Filtering, Recommender Systems, Informa- tion Seeking, Digital Libraries ", "title": "A Source Independent Framework for Research Paper Recommendation\n"}, "11_p307": {"abstract": " Serendipity occurs when one finds an interesting discovery while searching for something else. In digital libraries, recommenda- tion engines are particularly well-suited for serendipitous recom- mendations as such processes work without needing queries. Ju- nior researchers can use such scholarly recommendation systems to broaden their horizon and learn new areas, while senior researchers can discover interdisciplinary frontiers to apply integrative research. We adapt a state-of-the-art scholarly paper recommendation sys- tem＊s user profile construction to make use of information drawn from 1) dissimilar users and 2) co-authors to specifically target serendipitous recommendation. ", "authors": "Kazunari Sugiyama? National University of Singapore Computing 1, 13 Computing Drive, Singapore 117417 sugiyama@comp.nus.edu.sg Min-Yen Kan National University of Singapore Computing 1, 13 Computing Drive, Singapore 117417 kanmy@comp.nus.edu.sg ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering, Search process; H.3.7 [Digital Libraries]: Systems issues General Terms Algorithms, Experimentation, Human factors, Performance ", "id": "11_p307", "keywords": " Recommendation, Serendipity, User modeling ", "title": "Serendipitous Recommendation for Scholarly Papers Considering Relations Among Researchers\n"}, "11_p311": {"abstract": " With product reviews growing in depth and becoming more nu- merous, it is growing challenge to acquire a comprehensive under- standing of their contents, for both customers and product manu- facturers. We built a system that automatically summarizes a large collection of product reviews to generate a concise summary. Im- portantly, our system not only extracts the review sentiments but also the underlying justification for their opinion. We solve this problem through a novel application of clustering and validate our approach through an empirical study, obtaining good performance as judged by  -measure (the harmonic mean of purity and inverse purity). ", "authors": "Duy Khang Ly National University of Singapore Computing 1, 13 Computing Drive Singapore 117417 ldkhang@gmail.com Kazunari Sugiyama National University of Singapore Computing 1, 13 Computing Drive Singapore 117417 sugiyama@comp.nus. edu.sg Ziheng Lin National University of Singapore Computing 1, 13 Computing Drive Singapore 117417 linzihen@comp.nus. edu.sg Min-Yen Kan National University of Singapore Computing 1, 13 Computing Drive Singapore 117417 kanmy@comp.nus. edu.sg ", "categories": " H.3.1 [Content Analysis and Indexing]: Abstracting methods; I.2.7 [Natural Language Processing]: Text analysis General Terms Algorithms, Experimentation, Languages, Performance ", "id": "11_p311", "keywords": " Sentiment Analysis, Summarization, Clustering ", "title": "Product Review Summarization from a Deeper Perspective\n"}, "11_p315": {"abstract": " This paper explores the cognitive processes and online behaviors in which preservice teachers engage when seeking educational resources for classroom instruction. Participants used graphical and keyword search interfaces provided by a large-scale digital library (NSDL.org) and a keyword search interface from a large, commercial search engine (Google.com) to complete searches for online materials that would support classroom instruction. Overall, findings from the current work indicate that a graphical search interface can support comprehension by providing a conceptual organization of domain content during digital search and evaluation. Findings also show that digital libraries allow users to offload processing related to resource trustworthiness, thereby increasing cognitive capacity for other purposes.  ", "authors": "Kirsten R. Butcher, Sarah Davies, Ashley Crockett, Aaron Dewald, Robert Zheng Department of Educational Psychology University of Utah, 1705 Campus Center Drive, MBH 327 Salt Lake City, UT 84112  {kirsten.butcher; sarah.davies; ashley.crockett; aaron.dewald; robert.zheng} @utah.edu  ", "categories": " J.4 [Social and Behavioral Sciences]: Psychology 每 information search, evaluation, education, user testing, digital libraries  General Terms: Performance, Experimentation. ", "id": "11_p315", "keywords": " Preservice teachers, digital resources, resource evaluation ", "title": "Do Graphical Search Interfaces Support Effective Search for and Evaluation of Digital Library Resources? \n"}, "11_p325": {"abstract": " Nowadays, the information access is conducted almost exclusively using the Web. Simple keyword based Web search engines, e.g. Google or Yahoo!, offer suitable retrieval and ranking features. In contrast, for highly specialized domains, represented by digital libraries, these features are insufficient. Considering the domain of chemistry, where searching for relevant literature is essentially centered on chemical entities. Beside commercial information providers such as Chemical Abstract Service (CAS) numerous groups are working on building free chemical search engines to overcome the expensive access to chemical literature. However, due to the nature of chemical queries these are often overspecialized. Often we need meaningful similarity measures for chemical entities for query relaxation. In chemistry, the similarity measures are vast; more than 40 similarity measures are available and focus on different aspects of chemical entities. This vast number of similarity measures is obvious, because the desired search results highly depend on the working field of the chemist. In this paper we present a personalized retrieval system for chemical documents taking into account the background knowledge of the individual chemist. This is done by a query relaxation for chemical entities using similar substances. We evaluate our approach extensively by analyzing the correlation of commonly used chemical similarity measures and fingerprint representations. All uncorrelated measures are finally used by our feedback engine to learn preferred similarity measures for each user. We also conducted a user study with domain experts showing that our system can assign a unique similarity measure for 75% of the users after only 10 feedback cycles. ", "authors": "Sascha T?nnies L3S Research Center Appelstrasse 9a 30167 Hannover Germany toennies@l3s.de Benjamin K?hncke L3S Research Center Appelstrasse 9a 30167 Hannover Germany koehncke@l3s.de Wolf-Tilo Balke IFIS TU Braunschweig M邦hlenpfordtstrasse 23 38106 Braunschweig Germany balke@ifis.cs.tu-bs.de  ", "categories": " H.3.3 [Information Systems]: Information Storage and Retrieval 每 Information Search and Retrieval. General Terms Measurement, Experimentation, Human Factors.  ", "id": "11_p325", "keywords": " Chemical Digital Libraries, Personalization, Query Relaxation ", "title": "Taking Chemistry to the Task 每 Personalized Queries for Chemical Digital Libraries \n"}, "11_p335": {"abstract": " Physics Pathway is a digital library available through an Adobe Flash portal whose contents are a series of interviews with four experts who answer questions about the pedagogy of teaching physics. The answers were collected over a broad time span, but are presented to the user as if he or she is conducting the personal interview, similar to naturally conversing with the expert. This ※synthetic interview§ style is discussed in this paper, with a mixed methods evaluation by 19 high school teachers who used Physics Pathway for a 14-week period at the end of 2010. The evaluation with teachers showed that the synthetic interviews validated or reinforced their ideas on their course materials and delivery. As these are teachers who are relatively new to physics instruction, confirmation that they are teaching well is important. Physics Pathway is linked with comPADRE, a member of the National Science Digital Library.  ", "authors": "Michael G. Christel Entertainment Technology Center Carnegie Mellon University Pittsburgh, PA 15213 1-412-268-7799 christel@cmu.edu Scott M. Stevens Entertainment Technology Center Carnegie Mellon University Pittsburgh, PA 15213 1-412-268-7796 sms@cs.cmu.edu Dean Zollman Department of Physics Kansas State University Manhattan, KS 66506 1-785-532-1619 dzollman@phys.ksu.edu  ", "categories": " H5.1 [Information Interfaces and Presentation]: Multimedia Information Systems.  General Terms Design, Human Factors. ", "id": "11_p335", "keywords": " Synthetic interviews, physics pedagogy, digital video libraries. ", "title": "Physics Pathway: A Digital Library Filled with Synthetic Interviews \n"}, "11_p339": {"abstract": " This paper describes an approach for performing recognition and resolution of place names mentioned over the descriptive metadata records of typical digital libraries. Our approach exploits evidence provided by the existing structured attributes within the metadata records to support the place name recognition and resolution, in order to achieve better results than by just using lexical evidence from the textual values of these attributes. In metadata records, lexical evidence is very often insufficient for this task, since short sentences and simple expressions are predominant. Our implementation uses a dictionary based technique for recognition of place names (with names provided by Geonames), and machine learning for reasoning on the evidences and choosing a possible resolution candidate. The evaluation of our approach was performed in data sets with a metadata schema rich in Dublin Core elements. Two evaluation methods were used. First, we used cross-validation, which showed that our solution is able to achieve a very high precision of 0,99 at 0,55 recall, or a recall of 0,79 at 0,86 precision. Second, we used a comparative evaluation with an existing commercial service, where our solution performed better on any confidence level (p<0,001). ", "authors": " Nuno Freire, Jos谷 Borbinha, P芍vel Calado, Bruno Martins IST / INESC-ID Apartado 13069,  1000-029 Lisboa, Portugal  {nuno.freire, jlb, pavel.calado, bruno.g.martins}@ist.utl.pt  ", "categories": " E.1 [Data] Data Structures 每 Records; H.3.7. [Digital Libraries]; I.2.7 [Artificial Intelligence]: Natural Language Processing - Text analysis; I.7.m [Document and Text Processing]:[Miscellaneous]  General Terms Algorithms. Documentation Experimentation. ", "id": "11_p339", "keywords": " Information extraction, entity recognition, entity resolution, metadata, geographic information. ", "title": "A Metadata Geoparsing System for Place Name Recognition and Resolution in Metadata Records \n"}, "11_p349": {"abstract": " A large number of news articles are generated every day on the Web. Automatically identifying events from a large document col- lection is a challenging problem. In this paper, we propose two event detection approaches using generative models. We combine the popular LDA model with temporal segmentation and spatial clustering. In addition, we adapt an image segmentation model, SLDA, for spatial-temporal event detection on text. The results of our experiments show that both approaches outperform the tradi- tional content-based clustering approaches on our datasets. ", "authors": "Chi-Chun Pan Dep. of Industrial & Manufacturing Engineering The Pennsylvania State University University Park, PA 16802. czp117@psu.edu Dr. Prasenjit Mitra College of Information Sciences & Technology The Pennsylvania State University University Park, PA 16802. pmitra@ist.psu.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms ", "id": "11_p349", "keywords": " Event detection, spatial segmentation, temporal clustering ", "title": "Event Detection with Spatial Latent Dirichlet Allocation\n"}, "11_p359": {"abstract": " Nowadays, digital libraries contain more and more videos in them, and how to organize and retrieve those videos effectively has become very urgent. Text in videos is a very meaningful clue for video semantic understanding, and it can be used for video organization and retrieval. However, existing text recognizing methods can not deal with multilingual texts or texts embedded in a complex background very well. In this paper, we propose a novel video text detection method. Edge detection and candidate region extraction are firstly used to obtain all rough candidate text regions, and then region refinement is used to obtain the accurate location of each region. Based on our observation that a real text region has a uniform distribution with its non-zero pixels in its binary image, an entropy filter is used to remove non-text regions. Experiments on various videos show that our method is effective and robust against different languages, background complexities and font styles.  ", "authors": "Jie Yuan College of Computer Science and Technology Zhejiang University Hangzhou, China java_mc@163.com  Weiming Lu College of Computer Science and Technology Zhejiang University Hangzhou, China luwm@zju.edu.cn Baogang Wei College of Computer Science and Technology Zhejiang University Hangzhou, China wbg@zju.edu.cn  Lidong Wang Qianjiang College, Hangzhou Normal University College of Computer Science and Technology, Zhejiang University  Hangzhou, China violet_wld@163.com  ", "categories": " [I.2.10] Vision and Scene Understanding General Terms Algorithms, Performance, Design, Experimentation ", "id": "11_p359", "keywords": " Video retrieval, video text detection, distribution entropy.  ", "title": "A New Video Text Detection Method \n"}, "11_p363": {"abstract": " Increasing amounts of data are collected in many areas of research and application. The degree to which this data can be accessed, retrieved, and analyzed is decisive to ob- tain progress in fields such as scientific research or indus- trial production. We present a novel method supporting content-based retrieval and exploratory search in reposito- ries of multivariate research data. In particular, functional dependencies are a key characteristic of data that researchers are often interested in. Our methods are able to describe the functional form of such dependencies, e.g., the relationship between inflation and unemployment in economics. Our ba- sic idea is to use feature vectors based on the goodness-of-fit of a set of regression models, to describe the data mathe- matically. We denote this approach Regressional Features and use it for content-based search and, since our approach motivates an intuitive definition of interestingness, for ex- ploring the most interesting data. We apply our method on considerable real-world research datasets, showing the use- fulness of our approach for user-centered access to research data in a Digital Library system. ", "authors": "Maximilian Scherer J邦rgen Bernard Tobias Schreck Interactive Graphics Systems Group Technische Universit?t Darmstadt Fraunhoferstr. 5, 64283 Darmstadt, Germany {maximilian.scherer, juergen.bernard, tobias.schreck}@gris.tu-darmstadt.de ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries; H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing〞Indexing methods General Terms Algorithms ", "id": "11_p363", "keywords": " Research Data Repositories, Content-Based Access, Para- metric Fitting, Interestingness Analysis, Clustering ", "title": "Retrieval and Exploratory Search in Multivariate Research Data Repositories using Regressional Features\n"}, "11_p373": {"abstract": " In 2008, the National Science Foundation released the DataNet solicitation, which presents an ambitious vision for a comprehensive data curation cyberinfrastructure in support of fourth paradigm science. The program subsequently funded two projects, DataONE and the Data Conservancy. The authors put forth an uncertainty framework for understanding the larger socio- cultural issues that influence the progress of DataNet projects and cyberinfrastructure projects in general. This framework highlights the key technical, organizational, scientific, and institutional contexts that the projects must consider as they mature. ", "authors": "Carl Lagoze Cornell Information Science 301 College Ave. Ithaca, NY 14850 +1-607-255-6046 clagoze@gmail.com Karin Patzke Cornell Information Science 301 College Ave. Ithaca, NY 14850 +1-607-255-5483 klp76@cornell.edu  ", "categories": " H.1.1 [Value of Information]: Models and Principles 每 systems and information theory General Terms Management, Theory. ", "id": "11_p373", "keywords": " Cyberinfrastructure, Data Curation. ", "title": "A Research Agenda for Data Curation Cyberinfrastructure \n"}, "11_p383": {"abstract": " As science becomes more dependent upon digital data, the need for data curation and for data digital libraries becomes more urgent. Questions remain about what researchers consider to be their data, their criteria for selecting and trusting data, and their orientation to data challenges. This paper reports findings from the first 18 months of research on astronomy data practices from the Data Conservancy. Initial findings suggest that issues for data production, use, preservation, and sharing revolve around factors that rarely are accommodated in use cases for digital library system design including trust in data, funding structures, communication channels, and perceptions of scientific value. ", "authors": "Laura Wynholds Information Studies University of California Los Angeles wynholds@ucla.edu David S. Fearon Jr Information Studies University of California Los Angeles dfearon@ucla.edu Christine L. Borgman Information Studies University of California Los Angeles  borgman@gseis.ucla.edu  Sharon Traweek Women＊s Studies University of California Los Angeles traweek@history.ucla.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 collection, standards, user issues. General Terms Management, Design, Human Factors, Standardization. ", "id": "11_p383", "keywords": " Scientific data practices, digital data curation, astronomy, information behavior, user-centered design, ethnography, science & technology studies, data repositories, collaboration. ", "title": "When Use Cases Are Not Useful: Data Practices, Astronomy, and Digital Libraries \n"}, "12_p001": {"abstract": " Social media records the thoughts and activities of countless cultures and subcultures around the globe. Yet institutional efforts to archive social media content remain controversial. We report on 988 responses across six surveys of social media users that included questions to explore this controversy. The quantitative and qualitative results show that the way people think about the issue depends on how personal and ephemeral they view the content to be. They use concepts such as creator privacy, content characteristics, technological capabilities, perceived legal rights, and intrinsic social good to reason about the boundaries of institutional social media archiving efforts. ", "authors": "Catherine C. Marshall Microsoft Research, Silicon Valley 1065 La Avenida Mountain View, CA 94043 1-650-693-1308 cathymar@microsoft.com Frank M. Shipman Department of Computer Science Texas A&M University College Station, TX 77843-3112 1-979-862-3216 shipman@cs.tamu.edu  ", "categories": " H4.3 Information Systems: Communications Applications. General Terms Design, Experimentation, Human Factors. ", "id": "12_p001", "keywords": " Library of Congress, archiving, information rights, survey. ", "title": "On the Institutional Archiving of Social Media\n"}, "12_p011": {"abstract": " Diverse digital resources are commonly used by different types of users. It is common practice to develop those appli- cation having in mind a set of requirements for a specific tar- get category of users. We envisaged and designed the IPSA archive and system using a similar approach: the identifica- tion of a set of requirements for researchers in illuminated manuscripts as a target group of domain professional users. The IPSA system has been in use as a research tool by do- main professionals. The consideration that the content of the archive managed by the IPSA system could be of interest for other types of users suggested reconsidering its approach to envisage a new system designed around the same archive of illuminated manuscripts for their access by diverse cat- egories of users. The paper reports on the work that was conducted to re-design and re-engineer the system to match requirements and expectations of non-domain users. ", "authors": "Maristella Agosti Department of Information Engineering University of Padua Via Gradenigo, 6/a Padua, Italy maristella.agosti@unipd.it Nicola Orio Department of Cultural Heritage University of Padua Piazza Capitaniato, 7 Padua, Italy nicola.orio@unipd.it ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries - User issues General Terms Human Factors, Design, Experimentation ", "id": "12_p011", "keywords": " Digital Archives, Illuminated Manuscripts, Digital Archive Systems, Evaluation, Categories of Users ", "title": "To Envisage and Design the Transition from a Digital Archive System Developed for Domain Experts to one for Non-domain Users\n"}, "12_p015": {"abstract": " Archive-It, a subscription service from the Internet Archive, allows users to create, maintain and view digital collections of web resources. The current interface of Archive-It is largely text-based, supporting drill-down navigation using lists of URIs. To provide an overview of each collection and highlight the collection＊s underlying characteristics, we present four alternate visualizations (image plot with his- togram, wordle, bubble chart and timeline). The sites in an Archive-It collection may be organized by the collection cu- rator into groups for easier navigation. However, many col- lections do not have such groupings, making them difficult to explore. We introduce a heuristics-based categorization for such collections. ", "authors": "Kalpesh Padia kpadia@cs.odu.edu Yasmin AlNoamany yasmin@cs.odu.edu Michele C. Weigle mweigle@cs.odu.edu Department of Computer Science Old Dominion University Norfolk, VA 23529 ", "categories": " H.3.5 [On-line Information Services]: Commercial ser- vices; H.3.7 [Digital Libraries]: Collection; H.5.2 [User Interfaces]: Graphical user interfaces General Terms Human Factors ", "id": "12_p015", "keywords": " Digital collections, information visualization, bubble chart, timeline, image plot, wordle ", "title": "Visualizing Digital Collections at Archive-It\n"}, "12_p019": {"abstract": " Data are proliferating far faster than they can be captured, managed, or stored. What types of data are most likely to be used and reused, by whom, and for what purposes? Answers to these questions will inform information policy and the design of digital libraries. We report findings from semi-structured interviews and field observations to investigate characteristics of data use and reuse and how those characteristics vary within and between scientific communities. The two communities studied are researchers at the Center for Embedded Network Sensing (CENS) and users of the Sloan Digital Sky Survey (SDSS) data. The data practices of CENS and SDSS researchers have implications for data curation, system evaluation, and policy. Some data that are important to the conduct of research are not viewed as sufficiently valuable to keep. Other data of great value may not be mentioned or cited, because those data serve only as background to a given investigation. Metrics to assess the value of documents do not map well to data.  ", "authors": "Laura A. Wynholds, Jillian C. Wallis, Christine L. Borgman, Ashley Sands, Sharon Traweek* Department of Information Studies, University of California, Los Angeles *History and Gender Studies Departments, University of California, Los Angeles wynholds@ucla.edu, jwallisi@ucla.edu, borgman@gseis.ucla.edu, ashleysa@ucla.edu, traweek@history.ucla.edu  ", "categories": " H.3.7 [Digital Libraries]: User Issues. General Terms Documentation, Design, Human Factors, Standardization. ", "id": "12_p019", "keywords": " Scientific data, data practices, data sharing, data citation. ", "title": "Data, Data Use, and Scientific Inquiry: Two Case Studies of Data Practices \n"}, "12_p023": {"abstract": " Important biomedical information is often recorded, published or archived in unstructured and semi-structured textual form. Artificial intelligence and knowledge discovery techniques may be applied to large volumes of such data to identify and extract useful metadata, not only for providing access to these documents, but also for conducting analyses and uncovering patterns and trends in a field. The System for Preservation of Electronic Resources (SPER), an information management tool developed at the U.S. National Library of Medicine, provides these capabilities by integrating machine learning, data mining and digital preservation techniques. In this paper, we present an overview of SPER and its ability to retrieve information from one such dataset. We show how SPER was applied to the semi-structured records of an international health science program, the 46-year continuous archive of conference publications and related documents from the Joint Cholera Panel of the U.S.-Japan Cooperative Medical Science Program (CMSP). We explain the techniques by which metadata was extracted automatically from the semi-structured document contents to preserve these publications, and show how such data was used to quantitatively describe the activity of a research community toward a preliminary study of a subset of its specific health science program goals.  ", "authors": "Dharitri Misra National Library of Medicine Bethesda, MD, USA 20894 dmisra@mail.nih.gov Robert H. Hall National Institute of Allergy and Infectious Diseases Bethesda, MD, USA 20892 robert.hall@nih.gov Susan M. Payne National Institute of Allergy and Infectious Diseases Bethesda, MD, USA 20892 susan.payne@nih.gov George R. Thoma National Library of Medicine Bethesda, MD, USA 20894 gthoma@mail.nih.gov ", "categories": " H.3 [Information Storage and Retrieval]: H3.3 Information Search and Retrieval. H3.4 Systems and Software. H3.7 Digital Libraries I.5 [Pattern Recognition] I.5.2 Design Methodology - Feature evaluation and selection.  General Terms Algorithms, Management, Design, Experimentation ", "id": "12_p023", "keywords": " Metadata, Automated Metadata Extraction, Machine Learning, Digital Preservation, Data Analysis, Knowledge Discovery ", "title": "Digital Preservation and Knowledge Discovery Based on Documents from an International Health Science Program \n"}, "12_p027": {"abstract": " Understanding the social aspects of digital resource utiliza- tion is an area of active research. In this study, we exam- ine the digital library resource utilization and social behav- iors of middle and high school Earth Science teachers of a large United States urban school district. We present the results of three analysis based on teachers using an online curriculum planning tool called the Curriculum Customiza- tion Service (CCS), and examine the social networks that emerge among the participating teachers. We explore these networks in the context of the digital library resources that were part of the CCS and the use of socio-centric features around those resources. Our initial findings show promise toward developing a broader understanding of the social net- works of teachers, their behaviors around and usage of digi- tal library resources, as well as the diffusion of information through those networks. ", "authors": "Ogheneovo Dibie University of Colorado Institute of Cognitive Science Dept. of Computer Science Boulder, Colorado USA ogheneovo.dibie@colorado.edu Keith E. Maull University of Colorado Institute of Cognitive Science Dept. of Computer Science Boulder, Colorado USA maull@colorado.edu Tamara Sumner University of Colorado Institute of Cognitive Science Dept. of Computer Science Boulder, Colorado USA sumner@colorado.edu ", "categories": " H.3.7 [Digital Libraries]: Collection〞digital resources; H.3.7 [Digital Libraries]: User Issues〞social networks; H.4.m [Information Systems]: Information Systems Applications〞 educational resources applications ", "id": "12_p027", "keywords": " Social network analysis, information diffusion, teacher col- laboration ", "title": "Teacher Sociality and Information Diffusion in Educational Digital Libraries\n"}, "12_p031": {"abstract": " The growing number of digital libraries providing open educational resources (OER) requires effective resource discovery mechanisms to optimally exploit the benefits of their openness.  This paper discusses the OER repositories role and presents a study aimed at understanding how educators find OER by seeking answers to questions such as: what proportion of users seeking OER go directly to OER repositories and what proportion uses search engines or some other means and why. Understanding how and with what tools users discover and access resources can have an impact on the OER repositories strategic development.  ", "authors": "Christo Dichev  Computer Science Department Winston Salem State University Winston Salem, NC dichevc@wssu.edu Darina Dicheva Computer Science Department Winston Salem State University Winston Salem, NC dichevad@wssu.edu  ", "categories": " K.3.2 [Computers and Education]: Computer and Information Science Education; H.3.5 [Information Storage and Retrieval] On-line Information Services  General Terms Design, Human Factors  ", "id": "12_p031", "keywords": " Open Education, Open Educational Repositories, Discoverability ", "title": "Is It Time to Change the OER Repositories Role? \n"}, "12_p035": {"abstract": " This paper describes the results of a study designed to assess human expert ratings of educational concept features for use in automatic core concept extraction systems. Digital library resources provided the content base for human experts to annotate automatically extracted concepts on seven dimensions: coreness, local importance, topic, content, phrasing, structure, and function.  The annotated concepts were used as training data to build a machine learning classifier as part of a tool used to predict the core concepts in the document. These predictions were compared with the experts＊ judgment of concept coreness.  ", "authors": "James M. Foster, Md. Arafat Sultan, Holly Devaul2, Ifeyinwa Okoye, Tamara Sumner Institute of Cognitive Science  Digital Learning Sciences2 University of Colorado, Boulder, CO 80309 University Corporation for Atmospheric Research, 80307 {james.m.foster, arafat.sultan, ifeyinwa.okoye, sumner}@colorado.edu devaul@ucar.edu2  ", "categories": " H.3.7 [Digital Libraries]: Collection 每 digital resources; I.2.7 [Natural Language Processing]: Text Analysis 每 multi-document summarization; K.3.1. [Computers and Education]: Computer Uses in Education 每 Computer-aided instruction. General Terms Algorithms, Design, Experimentation, Human Factors, Measurement, Performance ", "id": "12_p035", "keywords": " Core Concepts, Multi-document Summarization ", "title": "Identifying Core Concepts in Educational Resources \n"}, "12_p043": {"abstract": " By analyzing the behavior of previous users, digital libraries can be made to provide new users with more support to find the best information. The AlgoViz Portal collects metadata on algorithm visualizations and associated research litera- ture. We show how logs can be used to discover latent rela- tionships between users, deducing an implicit social network. By clustering the log data, we find different page-viewing patterns, which provide practical information about the dif- ferent groups of users. ", "authors": "Monika Akbar Dept. of Computer Science Virginia Tech, Blacksburg, VA amonika@vt.edu Clifford A. Shaffer Dept. of Computer Science Virginia Tech, Blacksburg, VA shaffer@vt.edu Edward A. Fox Dept. of Computer Science Virginia Tech, Blacksburg, VA fox@vt.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries General Terms Design, Measurement ", "id": "12_p043", "keywords": " Deduced social network, digital library, log data ", "title": "Deduced Social Networks for an Educational Digital Library\n"}, "12_p047": {"abstract": " In this paper we describe preliminary results from two ongoing research projects that investigate the dissemination practices surrounding digital STEM learning materials for undergraduates. This research consists of two related studies, : 1) survey research about the dissemination practices of NSF-funded PIs; and, 2) a case study on the dissemination practices of courseware developers who won the Premier Award for Excellence in Engineering Education. The vast majority of PIs reported in the survey that they do not take advantage of digital dissemination methods such as education digital libraries. Premier Award- winning innovators reported using multiple dissemination methods 每 traditional and digital. Recommendations are provided regarding how digital library developers might work with PIs to improve dissemination. ", "authors": "Flora McMartin Sarah Giersch Broad-based Knowledge, LLC 5935 Orchard Ave Richmond, CA +011 515-237-4795 flora.mcmartin; sgiersch@gmail.com  Joe Tront  Virginia Polytechnic University 359 Durham Hall Blacksburg, VA 24061-0111 +011 540-231-5067 jgtront@exchange.vt.edu  Wesley Shumar  Drexel University 3141 Chestnut Street Philadelphia, PA 19104 +011 215-895-2060 shumarw@drexel.edu   ", "categories": " K.3.0 [Computing Milieux]: Computers and Education 每 General General Terms Measurement, Documentation ", "id": "12_p047", "keywords": " Digital Libraries; Dissemination; Survey; Case Study; Promotion; Tenure ", "title": "A Tale of Two Studies: Is Dissemination Working? \n"}, "12_p051": {"abstract": " Usually scientists breed research ideas inspired by previous publi- cations, but they are unlikely to follow all publications in the un- bounded literature collection. The volume of literature keeps on expanding extremely fast, whilst not all papers contribute equal impact to the academic society. Being aware of potentially influ- ential literature would put one in an advanced position in choos- ing important research references. Hence, estimation of potential influence is of great significance. We study a challenging prob- lem of identifying potentially influential literature. We examine a set of hypotheses on what are the fundamental characteristics for highly cited papers and find some interesting patterns. Based on these observations, we learn to identify potentially influential liter- ature via Future Influence Prediction (FIP), which aims to estimate the future influence of literature. The system takes a series of fea- tures of a particular publication as input and produces as output the estimated citation counts of that article after a given time period. We consider several regression models to formulate the learning process and evaluate their performance based on the coefficient of determination (R2). Experimental results on a real-large data set show a mean average predictive performance of 83.6%measured in R2. We apply the learned model to the application of bibliography recommendation and obtain prominent performance improvement in terms of Mean Average Precision (MAP). ", "authors": "Rui Yan?, \\, Congrui Huang?, Jie Tang∫, Yan Zhang?, ? and Xiaoming Li?, ? ? School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China ? State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100083, China ∫ Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China \\ Department of Computer Science and Information Engineering, National Taiwan University, Taipei 10617, Taiwan {r.yan,hcr,lxm}@pku.edu.cn, jietang@tsinghua.edu.cn, zhy@cis.pku.edu.cn ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.4 [Information Systems Applications]: General General Terms Algorithms, Experimentation, Performance ", "id": "12_p051", "keywords": " Citation pattern analysis, influence prediction, digital libraries ?Corresponding Author. ", "title": "To Better Stand on the Shoulder of Giants\n"}, "12_p061": {"abstract": " Bibliographic documents are basically associated with many entities including authors, venues, affiliations, etc. While bibliographic search engines addressed mainly relevant doc- ument ranking according to a query topic, ranking other re- lated relevant bibliographic entities is still challenging. In- deed, document relevance is the primary level that allows inferring the relevance of the other entities regardless of the query topic. In this paper, we propose a novel inte- grated ranking model, called BibRank, that aims at rank- ing both document and author entities in bibliographic net- works. The underlying algorithm propagates entity scores through the network by means of citation and authorship links. Moreover, we propose to weight these relationships using content-based indicators that estimate the topical re- latedness between entities. In particular, we estimate the common similarity between homogeneous entities by ana- lyzing marginal citations. We also compare document and author language models in order to evaluate the level of author＊s knowledge on the document topic and the docu- ment representativeness of author＊s knowledge. Experiment results on the representative CiteSeerX dataset show that BibRank model outperforms baseline ranking models with a significant improvement. ", "authors": "Laure Soulier IRIT - Paul Sabatier University 118 route de Narbonne 31062 Toulouse, France soulier@irit.fr Lamjed Ben Jabeur IRIT - Paul Sabatier University 118 route de Narbonne 31062 Toulouse, France jabeur@irit.fr Lynda Tamine IRIT - Paul Sabatier University 118 route de Narbonne 31062 Toulouse, France tamine@irit.fr Wahiba Bahsoun IRIT - Paul Sabatier University 118 route de Narbonne 31062 Toulouse, France wbahsoun@irit.fr ", "categories": " H.3.3 [Information Systems]: Information Search and Re- trieval General Terms Algorithms, Experimentation, Performance ", "id": "12_p061", "keywords": " Multi-entity Ranking, Bibliographic Network, Heteroge- neous Information Network, Homogeneous Information Net- work ", "title": "BibRank: a Language-Based Model for Co-Ranking Entities in Bibliographic Networks\n"}, "12_p071": {"abstract": " Recently expertise retrieval has received increasing inter- ests in both academia and industry. Finding experts with demonstrated expertise for a given query is a nontrivial task especially from a large-scale Web 2.0 systems, such as ques- tion answering and bibliography data, where users are ac- tively publishing useful content online, interacting with each other, and forming social networks in various ways, leading to heterogeneous networks in addition to the large amounts of textual content information. Many approaches have been proposed and shown to be useful for expertise ranking. How- ever, most of these methods only consider the textual doc- uments while ignoring heterogeneous network structures or can merely integrate with one additional kind of information. None of them can fully exploit the characteristics of hetero- geneous networks. In this paper, we propose a joint regular- ization framework to enhance expertise retrieval by model- ing heterogeneous networks as regularization constraints on top of document-centric model. We argue that multi-typed linking edges reveal valuable information which should be treated differently. Motivated by this intuition, we formu- late three hypotheses to capture unique characteristics for different graphs, and mathematically model those hypothe- ses jointly with the document and other information. To illustrate our methodology, we apply the framework to ex- pert finding applications using a bibliography dataset with 1.1 million papers and 0.7 million authors. The experimental results show that our proposed approach can achieve signif- icantly better results than the baseline and other enhanced models. ", "authors": "Hongbo Deng1, Jiawei Han1, Michael R. Lyu2, and Irwin King2 1 Dept. of Computer Science, University of Illinois at Urbana-Champaign 2 Dept. of Computer Science and Engineering, The Chinese University of Hong Kong hbdeng@uiuc.edu, hanj@cs.uiuc.edu, lyu@cse.cuhk.edu.hk, king@cse.cuhk.edu.hk ", "categories": ": H.3.3 [Informa- tion Storage and Retrieval]: Information Search and Retrieval〞retrieval models; H.2.8 [Database Management]: Database Applications〞data mining General Terms: Algorithm, Experimentation ", "id": "12_p071", "keywords": ": Expertise ranking, probabilistic model, hetero- geneous bibliographic network, graph regularization ", "title": "Modeling and Exploiting Heterogeneous Bibliographic Networks for Expertise Ranking\n"}, "12_p081": {"abstract": " The number of channels of digital television is increasing, particularly the number that are free-to-air. However due to the nature of broadcasting, this morass of information is not, for the main part, organized〞it is principally a succession of images and sound transmitted as multiplexed streams of data. Compare this deluge that terrestrially bombards our homes with the information available in the digital libraries we access over the Internet〞stored using software purpose built to help organize carefully curated sets of documents. This project brings together these two seemingly incompati- ble concepts to develop a software environment that concur- rently captures all the available live television channels〞so a user does not need to proactively choose what to record〞 and segments them into files which are then imported into a digital video library with a user interface designed to work from a multimedia remote control. A shifting time-based ※window§of all recordings is maintained〞we settled on from the last two weeks so as to be practicably operable on a regular desktop PC. The system leverages off the informa- tion contained in the electronic program guide and the video recordings to generate metadata suitable for the digital li- brary. A user evaluation of the developed prototype showed a high level of participant satisfaction across a range of at- tributes, notably date-based searching. ", "authors": "Maxime Ro邦ast University of Waikato Hamilton, New Zealand max@cs.waikato.ac.nz David Bainbridge University of Waikato Hamilton, New Zealand davidb@cs.waikato.ac.nz ", "categories": " H.3.7 [Information storage & retrieval]: Digital Libraries General Terms Design and Experimentation ", "id": "12_p081", "keywords": " Video Data Streams; Digital Libraries; User Evaluation ", "title": "Live Television in a Digital Library\n"}, "12_p091": {"abstract": " Digitized physical books offer access to tremendous amounts of knowledge, even for people with print-related disabilities. Various projects and standard activities are underway to make all of our past and present books accessible. However digitizing books requires extensive human efforts such as correcting the results of OCR (optical character recognition) and adding structural information such as headings. Some Asian languages need extra efforts for the OCR errors because of their many and varied character sets. Japanese has used more than 10,000 characters compared with a few hundred in English. This heavy workload is inhibiting the creation of accessible digital books. To facilitate digitization, we are developing a new system for processing physical books. We reduce and disperse the human efforts and accelerate conversions by combining automatic inference and human capabilities. Our system preserves the original page images for the entire digitization process to support gradual refinement and distributes the work as micro-tasks. We conducted trials with the Japanese National Diet Library (NDL) to evaluate the required effort for digitizing books with a variety of layouts and years of publication. The results showed old Japanese books had specific problems when correcting the OCR errors and adding structures. Drawing on our results, we discuss further workload reductions and future directions for international digitization systems. ", "authors": "Tatsuya Ishihara? Toshinari Itoko? Daisuke Sato? Asaf Tzadok? Hironobu Takagi? ?IBM Research 每 Tokyo ?IBM Research 每 Haifa 1623-14 Shimo-tsuruma, Yamato, Kanagawa,  242-8502, Japan. Haifa University, Mount Camel, Haifa HA 31905, Israel +81-46-215-4978 +81-46-215-4372 +81-46-215-4793 +972-4-829-6533 +81-46-215-4557 tisihara@jp.ibm.com itoko@jp.ibm.com dsato@jp.ibm.com asaf@il.ibm.com takagih@jp.ibm.com  ", "categories": " H.3.7 [Digital Libraries]: Digital Libraries; H.5.3 [Group and Organization Interfaces]: Collaborative computing; I.7.5 [Document Capture]: Document analysis General Terms Design, Experimentation, Languages. ", "id": "12_p091", "keywords": " Digital books, crowd-sourcing, accessibility, Japanese digitization. ", "title": "Transforming Japanese Archives into Accessible Digital Books\n"}, "12_p101": {"abstract": " In this paper, we present the Invertebrate Paleontology Knowl- edgebase (IPKB), an effort to digitize and share the Trea- tise on Invertebrate Paleontology. The Treatise is the most authoritative compilation of invertebrate fossil records. Un- fortunately, the PDF version is simply a clone of paper pub- lications and the content is in no way organized to facilitate search and knowledge discovery. We extracted texts and im- ages from the Treatise, stored them in a database, and built a system for efficient browsing and searching. For image processing in particular, we segmented fossil photos from figures, recognized the embedded labels, and linked the im- ages to the corresponding data entries. The detailed infor- mation of each genus, including fossil images, is delivered to users through a web access module. Some external applica- tions (e.g. Google Earth) are acquired through web services APIs to improve user experience. Given the rich informa- tion in the Treatise, analyzing, modeling and understand- ing paleontological data are significant in many areas, such as: understanding evolution; understanding climate change; finding fossil fuels, etc. IPKB builds a general framework that aims to facilitate knowledge discovery activities in in- vertebrate paleontology, and provides a solid foundation for future explorations. In this article, we report our initial ac- complishments. The specific techniques we employed in the project, such as those involved in text parsing, image-label association and meta data extraction, can be insightful and serve as examples for other researchers. ", "authors": "Yuanliang Meng?, Junyan Li?, Patrick Denton?, Yuxin Chen∫, Bo Luo?, Paul Selden?, and Xue-wen Chen? ? Department of EECS, The University of Kansas, Lawrence, KS, 66045, USA ? Department of Geology, The University of Kansas, Lawrence, KS, 66045, USA ∫ Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland {ymeng, j357l401, pdenton, bluo, selden, xwchen}@ku.edu, yuxin.chen@inf.ethz.ch ", "categories": " H.3.3 [Information Storage and Retrieval]: Informa- tion search and retrieval; E.2 [Data Storage Representa- tions]: Linked representations General Terms Design, Documentation ", "id": "12_p101", "keywords": " Digital library, Digitization, Paleontology ", "title": "IPKB: A Digital Library for Invertebrate Paleontology\n"}, "12_p111": {"abstract": " Early Modern emblems combined text and image. Though there were many variants, the archetypical emblem literary form (mid- sixteenth through mid-eighteenth centuries) consisted of an image (the pictura), a text inscription (the inscriptio), and a text epigram (the subscriptio), the last usually in verse. Digitized emblem literature poses interesting challenges as regards content and metadata granularity, the use of interdisciplinary controlled vocabularies, and the need to present digitized primary sources in a complex network of associated sources, derivatives, and contemporaneous context. In this paper, we describe a digital library Web application designed to better support the ways emblem scholars search for and use digitized emblem books, focusing on metadata design, issues of resource granularity and identification, and the use of Linked Data Web services for Iconclass, a multilingual classification system for cultural heritage art and images. Outcomes to date, achieved by emblem scholars and librarians working in collaboration, provide a case study for multi-faceted, interactive approaches to curating mixed text-image digital resources and the use of Linked Data vocabulary services.  Lessons learned highlight the value of librarian-scholar collaboration and help to illustrate why digital libraries need to move beyond merely disseminating digitized book surrogates.   ", "authors": "Timothy W. Cole, Myung-Ja Han, Jordan Vannoy Grainger Engineering Library Information Center University of Illinois at Urbana-Champaign 1301 W. Springfield Avenue Urbana, IL 61801 +1 (217) 244-7809 {t-cole3, mhan3, jvannoy}@illinois.edu  ", "categories": " H.3.7 [Digital Libraries]: Systems Issues  General Terms Design, Management, Experimentation, Human Factors. ", "id": "12_p111", "keywords": " emblem books, digital humanities, metadata, Iconclass ", "title": "Descriptive Metadata, Iconclass, and Digitized Emblem Literature \n"}, "12_p121": {"abstract": " The Ensemble Portal harvests resources from multiple heterogeneous federated collections. Managing these dynamically increasing collections requires an automatic mechanism to categorize records in to corresponding topics. We propose an approach to use existing ACM DL metadata to build classifiers for harvested resources in the Ensemble project. We also present our experience with utilizing the Amazon Mechanical Turk platform to build ground truth training data sets from Ensemble collections. ", "authors": " Yinlin Chen Department of Computer Science Virginia Tech Blacksburg, VA +1 540 808 9053 ylchen@vt.edu  Edward A. Fox Department of Computer Science Virginia Tech Blacksburg, VA +1 540 231 5113 fox@vt.edu     Paul Logasa Bogen II Intelligent Computing Research Team Computational Data Analytics Group Oak Ridge National Laboratory Oak Ridge, TN 37931 +1 865 241 0337 bogenpl@ornl.gov    Haowei Hsieh School of Library and Information Science University of Iowa Iowa City, IA 52242 +1 319 335 5713 haowei-hsieh@uiowa.edu   Lillian N. Cassel Department of Computing Sciences Villanova University Villanova PA 19085 +1 610 519 7341 lillian.cassel@villanova.edu  ", "categories": " Copyright 2012 ACM 978-1-4503-1154-0/12/06...$10.00.H.3.7 [Digital Libraries]: Collection. I.5.2 [Design Methodology]: Classifier design and evaluation. General Terms Design, Experimentation.  ", "id": "12_p121", "keywords": " Digital libraries, machine learning, classification, Amazon Mechanical Turk. ", "title": "Categorization of Computing Education Resources with Utilization of Crowdsourcing\n"}, "12_p125": {"abstract": " This work will introduce a new approach to ranking bibliographic records in library search, which is currently dominated by an OPAC style search paradigm, where results are typically not ranked by relevance. The approach we propose in the paper provides the user with the ability to access bibliographic records in a way responsive to his or her preferences, which is essentially done by looking at a community or a group of people who share interests with the user and making use of their publication records to re-rank search results. The experiment found that the present approach gives a clear edge over conventional search methods. ", "authors": "Tadashi Nomoto National Institute of Japanese Literature 10-3 Midori Tachikawa, Tokyo 190-0014, Japan nomoto@acm.org ", "categories": ": H.3 [Information Stor- age and Retrieval]: Information Search and Retrieval // General Terms: Algorithms // ", "id": "12_p125", "keywords": ": OPAC, Relevance Ranking ", "title": "Re-ranking Bibliographic Records for Personalized Library Search\n"}, "12_p129": {"abstract": " Mood is an important access point in music digital libraries and online music repositories, but generating ground truth for evaluating various music mood classification algorithms is a challenging problem. This is because collecting enough human judgments is time-consuming and costly due to the subjectivity of music mood. In this study, we explore the viability of crowdsourcing music mood classification judgments using Amazon Mechanical Turk (MTurk). Specifically, we compare the mood classification judgments collected for the annual Music Information Retrieval Evaluation eXchange (MIREX) with judgments collected using MTurk. Our data show that the overall distribution of mood clusters and agreement rates from MIREX and MTurk were comparable. However, Turkers tended to agree less with the pre-labeled mood clusters than MIREX evaluators. The system evaluation results generated using both sets of data were mostly the same except for detecting one statistically significant pair using Friedman＊s test. We conclude that MTurk can potentially serve as a viable alternative for ground truth collection, with some reservation with regards to particular mood clusters.  ", "authors": "Jin Ha Lee University of Washington Mary Gates Hall, Suite 370 Seattle, WA 98195 +1 206.685.0153 jinhalee@uw.edu Xiao Hu University of Denver 1999 E. Evans Ave. Room 249 Denver, CO 80208 +1 303.871.3352 xiao.hu@du.edu     ", "categories": " H.3.4. [Information Systems]: Information Storage and Retrieval 每 Systems and Software 每 Performance evaluation. J.5 [Arts and Humanities]: Music General Terms Measurement, Human Factors, Performance ", "id": "12_p129", "keywords": " Music Information Retrieval, Evaluation, Ground Truth, Gold Standard, Mood, Mechanical Turk, Crowdsourcing ", "title": "Generating Ground Truth for Music Mood Classification Using Mechanical Turk \n"}, "12_p139": {"abstract": " Today＊s digital libraries (DLs) archive vast amounts of in- formation in the form of text, videos, images, data measure- ments, etc. User access to DL content can rely on similarity between metadata elements, or similarity between the data itself (content-based similarity). We consider the problem of exploratory search in large DLs of time-oriented data. We propose a novel approach for overview-first exploration of data collections based on user-selected metadata properties. In a 2D layout representing entities of the selected property are laid out based on their similarity with respect to the un- derlying data content. The display is enhanced by compact summarizations of underlying data elements, and forms the basis for exploratory navigation of users in the data space. The approach is proposed as an interface for visual explo- ration, leading the user to discover interesting relationships between data items relying on content-based similarity be- tween data items and their respective metadata labels. We apply the method on real data sets from the earth observa- tion community, showing its applicability and usefulness. ", "authors": "J邦rgen Bernard Fraunhofer Institute for Computer Graphics Research Fraunhoferstr. 5 D-64283 Darmstadt, Germany juergen.bernard @igd.fraunhofer.de Tobias Ruppert Fraunhofer Institute for Computer Graphics Research Fraunhoferstr. 5 D-64283 Darmstadt, Germany tobias.ruppert @igd.fraunhofer.de Maximilian Scherer TU Darmstadt Fraunhoferstr. 5 D-64283 Darmstadt, Germany maximilian.scherer @gris.tu-darmstadt.de J?rn Kohlhammer Fraunhofer Institute for Computer Graphics Research Fraunhoferstr. 5 D-64283 Darmstadt, Germany joern.kohlhammer @igd.fraunhofer.de Tobias Schreck University of Konstanz Universit?tsstr. 10 D-78457 Konstanz, Germany tobias.schreck @uni-konstanz.de ", "categories": " H.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3 [Information Storage and Re- trieval]: Digital Libraries; J.2 [Physical Sciences and Engineering]: Earth and atmospheric sciences ", "id": "12_p139", "keywords": " Information Visualization, Exploratory Search, Similarity Measures, Scientific Research Data, Visual Layouts ", "title": "Content-Based Layouts for Exploratory Metadata Search in Scientific Research Data\n"}, "12_p149": {"abstract": " The HUBzero cyberinfrastructure provides a virtual research environment that includes a set of tools for web-based, sci- entific collaboration and a platform for publishing and us- ing resources such as executable software, source code, im- ages, learning modules, videos, documents, and datasets. Released as open source software in 2010, HUBzero has been implemented on a typical LAMP stack (Linux, Apache, MySQL, and PHP) and utilizes the Joomla! content man- agement system. This paper describes the subsequent refac- toring of HUBzero to produce and expose Linked Data from its backend, relational database, altering the external ex- pression of the data without changing its internal structure. The Open Archives Initiative Object Reuse and Exchange (OAI-ORE) specification is applied to model the basic struc- tural semantics of HUBzero resources as Nested Aggrega- tions, and data and metadata are mapped to vocabularies such as Dublin Core and published within the web represen- tations of the resources using RDFa. Resource Maps can be harvested using an RDF crawler or an Open Archives Ini- tiative Protocol for Metadata Harvesting (OAI-PMH) data provider that were bundled for demonstration purposes. A visualization was produced to browse and navigate the rela- tions among data and metadata from an example hub. ", "authors": "Michael Witt Purdue University Libraries 504 W. State Street West Lafayette, IN 47907 USA 765-494-8703 mwitt@purdue.edu Yongyang Yu Dept. of Computer Science, Purdue University 305 N. University Street West Lafayette, IN 47907 USA 765-494-6010 yu163@cs.purdue.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries General Terms Experimentation, Standardization ", "id": "12_p149", "keywords": " Linked Data, Object Reuse and Exchange (OAI-ORE), Open Archives Initiative, Resource Description Framework (RDF), Virtual Research Environments, HUBzero ", "title": "Refactoring HUBzero for Linked Data\n"}, "12_p153": {"abstract": " In this short paper, we describe the production data approach to data curation. We argue that by treating data in a similar fashion to how we build production software, that data will be more readily accessible and available for broad re-use. We should be treating data as an ongoing process. This includes considering third-party contributions; planning for cyclical releases; bug fixes, tracking, and versioning; and issuing licensing and citation information with each release. ", "authors": "Jennifer M. Schopf Woods Hole Oceanographic Institution Woods Hole, MA 02543 (Currently at the National Science Foundation, GEO/OAD) jschopf@whoi.edu   ", "categories": " E.5.3 [Data]: Files - Organization, Structure; E.4.3 [Data]: Coding and information theory - Formal models of communication; H.1 [Information Systems] - Models and principles General Terms Management, Documentation, Design, Verification ", "id": "12_p153", "keywords": " Best practices, Cyclical development and release, Production data ", "title": "Treating Data Like Software: A Case for Production Quality Data \n"}, "12_p157": {"abstract": " While most digital collections have limited forms of change〞 primarily creation and deletion of additional resources〞 there exists a class of digital collections that undergoes addi- tional kinds of change. These collections are made up of re- sources that are distributed across the Internet and brought together into a collection via hyperlinking. Resources in these collections can be expected to change as time goes on. Part of the difficulty in maintaining these collections is determining if a changed page is still a valid member of the collection. Others have tried to address this problem by measuring change and defining a maximum allowed thresh- old of change, however, these methods treat all change as a potential problem and treat web content as a static docu- ment despite its intrinsically dynamic nature. Instead, we approach the significance of change on the web as a normal part of a web document＊s life-cycle and determine the differ- ence between what a maintainer expects a page to do and what it actually does. In this work we evaluate the different options for extractors and analyzers in order to determine the best options from a suite of techniques. The evaluation used a human-generated ground-truth set of blog changes. The results of this work showed a statistically significant im- provement over a range of traditional threshold techniques when applied to our collection of tagged blog changes. ", "authors": "Paul Logasa Bogen II Intelligent Computing Research Team Computational Data Analytics Group Oak Ridge National Laboratory Oak Ridge, Tennessee bogenpl@ornl.gov Frank Shipman, Richard Furuta Center for the Study of Digital Libraries and Dept. of Computer Science and Engineering Texas A&M University College Station, Texas 77843 dcm@csdl.tamu.edu ", "categories": " H.3.7 [Digital Libraries]: Collection, Systems issues, User issues; H.5.4 [Hypertext/Hypermedia]: User issues; I.5.2 [Design Methodology]: Feature evaluation and selection; I.5.4 [Applications]: Text Processing General Terms Management, Design, Experimentation, Human Factors ", "id": "12_p157", "keywords": " Distributed Collection Manager, Pattern Recognition, Kalman Filters, Ensemble ", "title": "A Quantitative Evaluation of Techniques for Detection of Abnormal Change Events in Blogs\n"}, "12_p167": {"abstract": " Entity search is an emerging IR and NLP task that involves the retrieval of entities of a specific type in response to a query. We address the ※similar researcher search§ or the ※researcher recommendation§ problem, an instance of ※sim- ilar entity search§ for the academic domain. In response to a ＆researcher name＊ query, the goal of a researcher recom- mender system is to output the list of researchers that have similar expertise as that of the queried researcher. We pro- pose models for computing similarity between researchers based on expertise profiles extracted from their publications and academic homepages. We provide results of our mod- els for the recommendation task on two publicly-available datasets. To the best of our knowledge, we are the first to address content-based researcher recommendation in an academic setting and demonstrate it for Computer Science via our system, ScholarSearch. ", "authors": "Sujatha Das G. Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 USA gsdas@cse.psu.edu Prasenjit Mitra, C. Lee Giles Information Sciences and Technology Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 USA {pmitra,giles}@ist.psu.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval Models General Terms Algorithms ", "id": "12_p167", "keywords": " Similar-entity Search, Recommendation ", "title": "＆Similar Researcher Search＊ in Academic Environments\n"}, "12_p171": {"abstract": " Information resources in digital libraries are usually described, along with their context, by structured data records, commonly referred as metadata. Those records often contain unstructured information in natural language text, since they typically follow a data model which defines generic semantics for its data elements, or includes data elements modeled to contain free text. The information contained in these data elements, although machine readable, resides in unstructured natural language texts that are difficult to process by computers. This paper addresses a particular task of information extraction, typically called named entity recognition, which deals with the references to entities made by names occurring in the texts. This paper presents the results of a study of how the named entity recognition problem manifests itself in digital library metadata. In particular, we present the main differences between performing named entity recognition in natural language and in the text within metadata. The paper finalizes with a novel approach for named entity recognition in metadata. ", "authors": " Nuno Freire1,2, Jos谷 Borbinha1 and P芍vel Calado1 1IST/INESC-ID, Portugal 2The European Library, National Library of the Netherlands, Netherlands {nuno.freire,jlb,pavel.calado}@ist.utl.pt ", "categories": " E.1 [Data] Data Structures 每 Records; H.3.7. [Digital Libraries]; I.2.7 [Artificial Intelligence]: Natural Language Processing - Text analysis; I.7.m [Document and Text Processing]:[Miscellaneous]  ", "id": "12_p171", "keywords": " Information extraction, entity recognition, metadata, digital libraries. ", "title": "An Analysis of the Named Entity Recognition Problem in Digital Library Metadata \n"}, "12_p175": {"abstract": " One of the hardest problems faced by current scholarly digital li- braries is author name ambiguity. This problem occurs when, in a set of citation records, there are records of a same author under dis- tinct names, or citation records belonging to distinct authors with similar names. Among the several proposed methods, the most effective ones seem to be based on the direct assignment of the records to their respective authors by means of the application of supervised machine learning techniques. The effectiveness of such methods is usually directly correlated with the amount of super- vised training data available. However, the acquisition of training examples requires skilled human annotators to manually label ref- erences. Aiming to reduce the set of examples needed to produce the training data, in this paper we propose a new active sampling strategy based on association rules for the author name disambigua- tion task. We compare our strategy with state-of-the-art supervised baselines that use the complete labeled training dataset and other active methods and show that very competitive results in terms of disambiguation effectiveness can be obtained with reductions in the training set of up to 71%. ", "authors": "Anderson A. Ferreira1,2 Rodrigo Silva1 Marcos Andr谷 Gon?alves1 Adriano Veloso1 Alberto H. F. Laender1 1Departamento de Ci那ncia da Computa??o 2Departamento de Computa??o Universidade Federal de Minas Gerais Universidade Federal de Ouro Preto 31270-901 Belo Horizonte, Brazil 35400-000 Ouro Preto, Brazil {ferreira, rmsilva, mgoncalv, adrianov, laender}@dcc.ufmg.br ", "categories": " H.3.3 [Information Search and Retrieval]: Information Retrieval; I.5.2 [Pattern Recognition]: Classifier design and evaluation General Terms Algorithms, Experimentation ", "id": "12_p175", "keywords": " Name Disambiguation, Bibliographic Citations, Active Sampling ", "title": "Active Associative Sampling for Author Name Disambiguation\n"}, "12_p185": {"abstract": " Acknowledgments are widely used in scientific articles to ex- press gratitude and credit collaborators. Despite suggestions that indexing acknowledgments automatically will give in- teresting insights [9], there is currently, to the best of our knowledge, no such system to track acknowledgments and index them 1. In this paper we introduce AckSeer2, a search engine and a repository for automatically extracted acknowl- edgments in digital libraries. AckSeer is a fully automated system that scans items in digital libraries including con- ference papers, journals, and books extracting acknowledg- ment sections and identifying acknowledged entities men- tioned within. We describe the architecture of AckSeer and discuss the extraction algorithms that achieve a F1 measure above 83%. We use multiple Named Entity Recognition (NER) tools and propose a method for merging the outcome from different recognizers. The resulting entities are stored in a database then made searchable by adding them to the AckSeer in- dex along with the metadata of the containing paper/book. We buildAckSeer on top of the documents in CiteSeerx digi- tal library yielding more than 500,000 acknowledgments and more than 4 million mentioned entities. ", "authors": "Madian Khabsa Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 madian@psu.edu Pucktada Treeratpituk Information Sciences and Technology The Pennsylvania State University University Park, PA 16802 pxt162@ist.psu.edu C. Lee Giles Information Sciences and Technology Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 giles@ist.psu.edu ", "categories": " I.2.7 [Artificial Intelligence]: Natural Language Process- ing〞Text analysis; H.3.1 [Information Storage and Re- trieval]: Content Analysis and Indexing〞Linguistic pro- 1An early acknowledgement indexing system was built in CiteSeer but was not refactored into the new CiteSeerX 2http://ackseer.ist.psu.edu cessing ; H.3.1 [Information Storage and Retrieval]: Dig- ital Libraries〞Collection General Terms Algorithms, Search engines ", "id": "12_p185", "keywords": " Acknowledgments, Information Extraction, Disambiguation ", "title": "AckSeer: A Repository and Search Engine for Automatically Extracted Acknowledgments from Digital Libraries\n"}, "12_p195": {"abstract": " The number of books available online is increasing, but user interfaces may not be taking full advantage of advances in machine learning techniques that could help users navigate, explore, discover and understand interesting and useful content in books. Using a group of ten students and over one thousand crowdsourced judgments, we conducted multiple user studies to evaluate topics and related passages in books, all learned by topic modeling. Using ten books, selected from humanities (e.g. Plato's Republic), social sciences (e.g. Marx's Capital) and sciences (e.g. Einstein's Relativity), and four different evaluation experiments, we show that users agree that the learned topics are coherent and important to the book, and related to the automatically generated passages. We show how crowdsourced evaluations are useful, and can complement more focused evaluations using students who have studied the texts. This work provides a framework for (1) learning topics and related passages in books, and (2) evaluating those learned topics and passages, and moves one step toward automatic annotation to support topic navigation of books. ", "authors": " David Newman  Computer Science Univ. California, Irvine  newman@uci.edu   Youn Noh Office of Digital Assets and Infrastructure Yale University youn.noh@yale.edu Kat Hagedorn University Libraries University of Michigan khage@umich.edu  Arun Balagopalan  Computer Science  Univ. California, Irvine  abalagop@ics.uci.edu   ", "categories": " H.4.0 [Information Systems]: General ", "id": "12_p195", "keywords": ":  topic modeling, book navigation, text mining ", "title": "Learning Topics and Related Passages in Books \n"}, "12_p199": {"abstract": " We studied how an enriched public library catalogue is used to access novels. 58 users searched for interesting novels to read in a simulated situation where they had only a vague idea of what they would like to read. Data consist of search logs, pre and post search questionnaires and observations. Results show, that investing effort on examining results improves search success, i.e. finding interesting novels, whereas effort in querying has no bearing on it. In designing systems for fiction retrieval, enriching result presentation with detailed book information would benefit users. ", "authors": "Suvi Oksanen School of Information Sciences University of Tampere 33014 University of Tampere, Finland  Suvi.Oksanen@uta.fi  Pertti Vakkari School of Information Sciences University of Tampere 33014 University of Tampere, Finland Pertti.Vakkari@uta.fi  ", "categories": " H.3.7. [Digital Libraries]: User Issues General Terms Human Factors ", "id": "12_p199", "keywords": " Fiction Retrieval, Novels, Readers, Public Libraries, Search Tactics, Search Effort, Search Success ", "title": "Emphasis on Examining Results in Fiction Searches Contributes to Finding Good Novels \n"}, "12_p203": {"abstract": "  In 2008, Iowa City was designated as one of only five ※Cities of Literature§ worldwide by UNESCO. To take advantage of our rich local literary history, an interdisciplinary research team from the University of Iowa collaborated to develop a digital library featuring Iowa City authors and locations. The UNESCO City of Literature digital library (referred to internally as ※City of Lit§) consists of a mobile application for the general public to access the database and a set of web-based interfaces for researcher and content creators to contribute to the database. Members of the research team have developed undergraduate literature courses to study the feasibility of using young scholars for digital content creation, and the pedagogical effect of including digital research in traditional literary courses. Students in the courses were trained to conduct scholarly research and generate a variety of digital resources to be included in the digital collection. This paper re- ports our experience building the City of Lit digital library and the results from evaluations and studies of the students in the courses. We also outline the implementation and development of the digi- tal library, its framework, and the client-side mobile application. ", "authors": "Haowei Hsieh1, Bridget Draxler2, Nicole J. Dudley1, Jon Winet3 School of Library & Information Science1, Intermedia Program3 The University of Iowa  Iowa City, Iowa, USA, 319-335-5713 {haowei-hsieh, jon-winet}@uiowa.edu Department of English2 Monmouth College  Monmouth, Illinois, USA bdraxler@monmouthcollege.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 Collection. K.3.1 [Computers and Education]: Computer Uses in Education 每 Collaborative learning. General Terms Design, Experimentation, Human Factors. ", "id": "12_p203", "keywords": " Digital libraries, mobile application, iPhone app, mobile devices, digital humanities, literary research. ", "title": "The ※City of Lit§ Digital Library 每 A Case Study of Interdisciplinary Research and Collaboration\n"}, "12_p213": {"abstract": " The surviving corpora of Greek and Latin are relatively compact but the shift from books and written objects to digitized texts has already challenged students of these languages to move away from books as organizing metaphors and to ask, instead, what do you do with a billion, or even a trillion, words? We need a new culture of intellectual production in which student researchers and citizen scholars play a central role. And we need as a consequence to reorganize the education that we provide in the humanities, stressing participatory learning, and supporting a virtuous cycle where students contribute data as they learn and learn in order to contribute knowledge. We report on five strategies that we have implemented to further this virtuous cycle: (1) reading environments by which learners can work with languages that they have not studied, (2) feedback for those who choose to internalize knowledge about a particular language, (3) methods whereby those with knowledge of different languages can collaborate to develop interpretations and to produce new annotations, (4) dynamic reading lists that allow learners to assess and to document what they have mastered, and (5) general e-portfolios in which learners can track what they have accomplished and document what they have contributed and learned to the public or to particular groups. ", "authors": "Gregory Crane, Bridget Almas, Alison Babeu, Lisa Cerrato Matthew Harrington Tufts University Perseus Project {gregory.crane,bridget.almas, alison.babeu,lisa.cerrato, matthew.harrington}@tufts.edu David Bamman Carnegie Mellon University School of Computer Science Language Technologies Inst. dbamman@cs.cmu.edu Harry Diakoff Alpheios Project Alpheios.net  Harry.Diakoff@gmail.com   ", "categories": " H.3.7. [Information Systems]: Information Storage and Retrieval: digital libraries.  General Terms Documentation, Design, Human Factors,  ", "id": "12_p213", "keywords": " Automatic linking, collection development, document design, reading, browsing. ", "title": " Student Researchers, Citizen Scholars and the Trillion Word Library \n"}, "12_p223": {"abstract": " Textual data ranging from corpora of digitized historic docu- ments to large collections of news feeds provide a rich source for temporal and geographic information. Such types of in- formation have recently gained a lot of interest in support of different search and exploration tasks, e.g., by organizing news along a timeline or placing the origin of documents on a map. However, for this, temporal and geographic infor- mation embedded in documents is often considered in iso- lation. We claim that through combining such information into (chronologically ordered) event-like features interesting and meaningful search and exploration tasks are possible. In this paper, we present a framework for the extraction, exploration, and visualization of event information in doc- ument collections. For this, one has to identify and com- bine temporal and geographic expressions from documents, thus enriching a document collection by a set of normalized events. Traditional search queries then can be enriched by conditions on the events relevant to the search subject. Most important for our event-centric approach is that a search re- sult consists of a sequence of events relevant to the search terms and not just a document hit-list. Such events can originate from different documents and can be further ex- plored, in particular events relevant to a search query can be ordered chronologically. We demonstrate the utility of our framework by different (multilingual) search and explo- ration scenarios using a Wikipedia corpus. ", "authors": "Jannik Str?tgen Institute of Computer Science Heidelberg University Heidelberg, Germany stroetgen@uni-hd.de Michael Gertz Institute of Computer Science Heidelberg University Heidelberg, Germany gertz@uni-hd.de ", "categories": " H.3.3 [Information Systems]: Information Search and Re- trieval〞Query formulation, Search process; I.2.7 [Artificial Intelligence]: Natural Language Processing〞Text analysis ", "id": "12_p223", "keywords": " event extraction, temporal information, geographic informa- tion, querying, corpora exploration ", "title": "Event-centric Search and Exploration in Document Collections\n"}, "12_p233": {"abstract": " For a collection of digitized monographs in a subject domain, a domain meta-index provides a summary of domain concepts, and a structured vocabulary to support a scholar＊s navigation and search. We present a prototype of a Meta-index User Interface (MUI) that provides views of a domain at three levels: summarizing and comparing domains, exposing the regularities of a domain＊s vocabulary, and displaying book information and page content related both to objectively-representative books, and to specific user searches. ", "authors": "Michael Huggett and Edie Rasmussen University of British Columbia Suite 470, 1961 East Mall Vancouver, BC V6T 1Z1 (1-604) 827-5486 {m.huggett, edie.rasmussen}@ubc.ca ", "categories": " H.3.7 [Information Systems]: Information Storage and Retrieval 每 Digital libraries General Terms Algorithms, Design, Human Factors. ", "id": "12_p233", "keywords": " Digital libraries, digital books, digital collections, index, meta- indexes.  ", "title": "Dynamic Online Views of Meta-Indexes \n"}, "12_p237": {"abstract": " Concept taxonomies such as MeSH, the ACM Computing Classification System, and the NY Times Subject Headings are frequently used to help organize data. They typically consist of a set of concept names organized in a hierarchy. However, these names and structure are often not sufficient to fully capture the intended meaning of a taxonomy node, and particularly non-experts may have difficulty navigating and placing data into the taxonomy. This paper introduces two semi-supervised topic models that automatically aug- ment a given taxonomy with many additional keywords by leveraging a corpus of multi-labeled documents. Our exper- iments show that users find the topics beneficial for taxon- omy interpretation, substantially increasing their cataloging accuracy. Furthermore, the models provide a better infor- mation rate compared to Labeled LDA [7]. ", "authors": "Anton Bakalov, Andrew McCallum, Hanna Wallach Dept. of Computer Science University of Massachusetts Amherst, MA 01003 {abakalov,mccallum,wallach}@cs.umass.edu David Mimno Dept. of Computer Science Princeton University Princeton, NJ 08540 mimno@cs.princeton.edu ", "categories": " I.2.7 [Artificial Intelligence]: Natural Language Process- ing〞Text analysis; H.3.7 [Information Systems]: Digital Libraries; G.3 [Mathematics of Computing]: Probability and Statistics〞Statistical computing ", "id": "12_p237", "keywords": " Topic modeling, Taxonomy annotation, Taxonomy browsing ", "title": "Topic Models for Taxonomies\n"}, "12_p241": {"abstract": " For most, the web is the first source to answer a question formulated by curiosity, need, or research reasons. This phenomenon is due to the internet＊s ubiquitous access, ease of use, and the extensive and ever expanding content. The problem is no longer the need to acquire content to encourage use, but to provide organizational tools to support content categorization that will facilitate improved access methods. This paper presents the results of a new text characterization algorithm that combines semantic and linguistic techniques utilizing domain-based ontology background knowledge. It explores the combination of meronym, synonym, and hypernym linguistic relationships to create a set of concept chains used to represent concepts found in a document. The experiments show improved accuracy over bag-of-words based term weighting methods and reveal characteristics of the meronym contribution to document representation. ", "authors": "Lori Watrous-deVersterre Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA llw2@njit.edu Chong Wang Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA cs87@njit.edu Min Song Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA min.song@njit.edu   ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing 每 dictionaries, indexing methods, linguistic processing; H.3.7 [Digital Libraries]: Miscellaneous General Terms Algorithms, Performance, Reliability, Experimentation  ", "id": "12_p241", "keywords": " Concept extraction, text characterization, clustering, digital libraries, machine learning, natural language processing, ontology ", "title": "Concept Chaining Utilizing Meronyms in Text Characterization \n"}, "12_p249": {"abstract": " Multi-faceted book search engine presents diverse category- style options to allow users to refine search results with- out re-entering a query. In this paper, we propose a novel multi-faceted book search engine that utilizes users＊ query- related latent intents mined from click-through logs as mul- tiple facets for books. The latent query intents can be ef- fectively and efficiently discovered by applying the Sparse Latent Semantic Analysis (LSA) model to users＊ query and clicking behaviors in the click-through logs. This paper presents the details to improve the multi-faceted book search by incorporating the compact representation of query-intent- book relationships generated by Sparse LSA into the off-line and online processing procedures. The specificity of latent query intents can be flexibly changed by adjusting the spar- sity level of projection matrix in the Sparse LSA model. We evaluated our approach on CADAL click-through logs con- taining 45,892 queries and 164,822 books. The experimental results show the Sparse LSA model with more sparse projec- tion matrix tends to discover the more specific latent query intents. The latent query intents suggested by our approach usually gain the high user satisfaction ratio. ", "authors": "Deng Yi College of Computer Science, Zhejiang University, Hangzhou, China yideng@zju.edu.cn Yin Zhang College of Computer Science, Zhejiang University, Hangzhou, China zhangyin98@zju.edu.cn Haihan Yu College of Computer Science, Zhejiang University, Hangzhou, China yuhaihan@zju.edu.cn Yanfei Yin College of Computer Science, Zhejiang University, Hangzhou, China yanfei_yin@live.cn Jing Pan College of Computer Science, Zhejiang University, Hangzhou, China panjing0525@zju.edu.cn Baogang Wei College of Computer Science, Zhejiang University, Hangzhou, China wbg@zju.edu.cn ", "categories": " H.2.8 [Database Management]: Database Application- s〞data mining ; H.3.3 [Information Storage and Re- trieval]: Information Search and Retrieval〞information fil- tering, search process; H.3.7 [Information Storage and Retrieval]: Digital Libraries 〞systems issues General Terms Algorithms, Design, Experimentation ", "id": "12_p249", "keywords": " Multi-Faceted Search, Query Intent, Sparse LSA ", "title": "Improving Multi-Faceted Book Search by Incorporating Sparse Latent Semantic Analysis of Click-Through Logs\n"}, "12_p259": {"abstract": " Query In Context (QIC) is a personalized search system that enhances individual search by incorporating user preferences in query expansion, capturing meanings embedded in documents, and ranking search results with context-enriched features. In this paper, we propose a new technique for QIC＊s Query Expansion module, which reformulates user queries by using novel statistical-based and knowledge-based query expansion techniques to improve the returned results. The promising preliminary results analyzed through precision and recall metrics show better alignment between the user＊s interests and the results retrieved. ", "authors": "Prat Tanapaisankit Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA pt26@njit.edu Lori Watrous-deVersterre Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA llw2@njit.edu Min Song Information Systems New Jersey Institute of Technology Newark, NJ 07003, USA min.song@njit.edu   ", "categories": " H3.3 [Information Search and Retrieval]: Query formulation General Terms Algorithms, Human Factors. ", "id": "12_p259", "keywords": " Query Expansion. Semantic Query Analysis, Personalized Search ", "title": "Personalized Query Expansion in the QIC System \n"}, "12_p263": {"abstract": " In this paper, we report on indexing performance by a state- of-the-art keyphrase indexer, Maui, when paired with a text extraction procedure called text denoising. Text denoising is a method that extracts the denoised text, comprising the content-rich sentences, from full texts. The performance of the keyphrase indexer is demonstrated on three standard corpora collected from three domains, namely food and agri- culture, high energy physics, and biomedical science. Maui is trained using the full texts and denoised texts. The indexer, using its trained models, then extracts keyphrases from test sets comprising full texts, and their denoised and noise parts (i.e., the part of texts that remains after denoising). Ex- perimental findings show that against a gold standard, the denoised-text-trained indexer indexing full texts, performs either better than or as good as its benchmark performance produced by a full-text-trained indexer indexing full texts. ", "authors": "Rushdi Shams rshams@csd.uwo.ca Robert E. Mercer mercer@csd.uwo.ca Department of Computer Science University of Western Ontario London, ON N6A 5B7, Canada ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing〞Indexing method General Terms Experimentation, Performance. ", "id": "12_p263", "keywords": " Keyphrase indexing, text denoising, Maui, fog index. ", "title": "Investigating Keyphrase Indexing with Text Denoising\n"}, "12_p267": {"abstract": " Information seeking behavior in microblogging environments such as Twitter differs from traditional web search. The best performing microblog retrieval techniques attempt to uti- lize both semantic and temporal aspects of documents. In this paper, we present an effective approach, including the query modeling, the document modeling and the temporal re-ranking, to discover the most recent but relevant infor- mation to the query. For the query modeling, we introduce a two-stage pseudo-relevance feedback query expansion to overcome the severe vocabulary-mismatch problem of short message retrieval in microblog. For the document model- ing, we propose two ways to expand document with the help of the shortened URL. For the temporal re-ranking, we suggest several methods to evaluate the temporal aspects of documents. Experimental results demonstrate that our approach obtains significant improvements compared with baseline systems. Specifically, the proposed system gives 26.37% and 9.94% further increases in P@30 and MAP over the best performing result on highrel in the TREC＊11 Real- Time Search Task. ", "authors": "Feng Liang liangfeng@pku.edu.cn Runwei Qiang qiangrw@gmail.com Jianwu Yang ? yangjw@pku.edu.cn Institute of Computer Science and Technology Peking University,Beijing 100871,China ", "categories": " H.3.3 [Information Search and Retrieval]: Information Search and Retrieval〞Retrieval models General Terms Algorithms, Experimentation, Performance ", "id": "12_p267", "keywords": " Real-Time Search, Query Expansion, Language Model, Tem- poral Search ?Corresponding author. ", "title": "Exploiting Real-Time Information Retrieval in the Microblogosphere\n"}, "12_p277": {"abstract": " Algorithms are an essential part of computational science. An algorithm search engine, which extracts pseudo-codes and their metadata from documents, and makes it search- able, has recently been developed as part of the CiteseerX suite [3, 4]. However, this algorithm search engine only re- trieves and ranks relevant algorithms solely on textual simi- larity. Here, we propose a method for using the algorithm co- citation network to infer the similarity between algorithms. We apply a graph clustering algorithm on the network for algorithm recommendation and make suggestions on how to improve the current CiteseerX algorithm search engine. ", "authors": "Suppawong Tuarob?, Prasenjit Mitra?? and C. Lee Giles?? ? Computer Science and Engineering, ? Information Sciences and Technology The Pennsylvania State University University Park, PA 16802 suppawong@psu.edu, {pmitra, giles}@ist.psu.edu ", "categories": " H.3.3 [Information Search and Retrieval] ", "id": "12_p277", "keywords": " Algorithms, Clustering, Algorithm Co-Citation Network ", "title": "Improving Algorithm Search Using the Algorithm Co-Citation Network\n"}, "12_p281": {"abstract": " Citation counts have been widely used in a digital library for purposes such as ranking scientific publications and evaluating patents. This paper demonstrates that distinguishing different types of citations could rank better for these purposes. We differentiate patent citations along two dimensions (assignees and technologies) into four types, and propose a weighted citation approach for assessing and ranking patents. We investigate five weight learning methods and compare their performance. Our weighted citation method performs consistently better than simple citation counts, in terms of rank correlations with patent renewal status. The estimated weights on different citations are consistent with economic insights on patent citations. Our study points to an interesting and promising research line on patent citation and network analysis that has not been explored. ", "authors": "Sooyoung Oh Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 sooh@cse.psu.edu Zhen Lei Energy and Mineral Engineering The Pennsylvania State University University Park, PA 16802 zlei@psu.edu Prasenjit Mitra    John Yen Information Sciences and Technology The Pennsylvania State University University Park, PA 16802 {pmitra, jyen}@ist.psu.edu  ", "categories": " H.3.3 [Information Systems]: Information Search and Retrieval General Terms Algorithms ", "id": "12_p281", "keywords": " patent ranking, patent citation, weighted citation, patent renewal. ", "title": "Evaluating and Ranking Patents Using Weighted Citations \n"}, "12_p285": {"abstract": " In education and research, references play a key role. How- ever, extracting and parsing references are difficult prob- lems. One concern is that there are many styles of references; hence, given a surface form, identifying what style was em- ployed is problematic, especially in heterogeneous collections of theses and dissertations, which cover many fields and dis- ciplines, and where different styles may be used even in the same publication. We address these problems by drawing upon suitable knowledge found in the WWW. In particular, we research a two-stage classifier approach, involving multi- class classification with respect to reference styles, and par- tially solve the problem of parsing surface representations of references. We describe empirical evidence for the effec- tiveness of our approach and plans for improvement of our methods. ", "authors": "Sung Hee Park Digital Library Research Laboratory Department of Computer Science Virginia Tech Blacksburg, Virginia, 24061 shpark@vt.edu Roger W. Ehrich Center for Human Computer Interaction Department of Computer Science Virginia Tech Blacksburg, Virginia, 24061 rehrich@vt.edu Edward A. Fox Digital Library Research Laboratory Department of Computer Science Virginia Tech Blacksburg, VA, 24061 fox@vt.edu ", "categories": " H.3.7 [Information storage and retrieval]: Digital Li- braries〞systems issues; I.5 [Pattern Recognition]: De- sign Methodology〞classifier design and evaluation General Terms Algorithm, Performance, Design, Experimentation ", "id": "12_p285", "keywords": " Canonical Representation Extraction, Knowledge Acquisi- tion, Reverse-Engineering, Style-Free Reference Metadata Extraction ", "title": "A Hybrid Two-Stage Approach for Discipline-Independent Canonical Representation Extraction from References\n"}, "12_p295": {"abstract": " Considering the tremendous value of citation metadata, many methods have been proposed to automate Citation Metadata Extraction (CME). The existing methods primarily rely on the content analysis of citation text. However, the results from such content-based methods are often unreliable. Moreover, the extracted citation metadata is only a small part of the relevant metadata that spreads across the Internet. As opposed to the content-based CME methods, this paper proposes a Web-based CME approach and a citation enriching system, called as BibAll, which is capable of correcting the parsing results of content-based CME methods and augmenting citation metadata by leveraging relevant bibliographic data from digital repositories and cited-by publications on the Web. BibAll consists of four main components: citation parsing, Web-based bibliographic data retrieval, irrelevant bibliographic data filtering, and relevant bibliographic data integration. The system has been tested on the publicly available FLUX-CIM dataset. Experimental results show that BibAll significantly improves the citation parsing accuracy and augments the metadata of the original citation.  ", "authors": "Liangcai Gao ICST, Peking University, Beijing  China glc@pku.edu.cn  Xixi Qi ICST, Peking University, Beijing  China qixixi@pku.edu.cn Zhi Tang State Key Laboratory of Digital Publishing Technology, Beijing, China tangzhi@founder.com Xiaofan Lin A9.com  130 Lytton Ave, Palo Alto, CA  USA  xiaofanl@a9.com Ying Liu Department of Knowledge Service Engineering, Korea Advanced Institute of Science and Technology Daejeon, Republic of Korea yingliu@kaist.ac.kr  ", "categories": " H.3.3 [Information Systems]: Information Search and Retrieval ", "id": "12_p295", "keywords": " Citation Extraction and Augmentation, Automatic Metadata Generation, Web-based Extraction, Digital Libraries ", "title": "Web-based Citation Parsing, Correction and Augmentation \n"}, "12_p305": {"abstract": " Little is known about how readers select books, whether they be print books or ebooks. In this paper we present a study of how people select physical books from academic library shelves. We use the insights gained into book selection behavior to make suggestions for the design of ebook-based digital libraries in order to better facilitate book selection behavior. ", "authors": "Annika Hinze  Computer Science Department  University of Waikato  Hamilton, New Zealand  hinze@cs.waikato.ac.nz Dana McKay Library, The Swinburne Institute for Social Research Swinburne University of Technology  Melbourne, Australia dmckay@swin.edu.au Nicholas Vanderschantz,  Claire Timpany,  Sally Jo Cunningham University of Waikato vtwoz, ctimpany, sallyjo@cs.waikato.ac.nz   ", "categories": " H3.7. Digital Libraries: User issues;  H5.4. Hypermedia: User Issues  ", "id": "12_p305", "keywords": " Digital libraries, ebooks, human-computer interaction, information seeking behavior. ", "title": "Book Selection Behavior in the Physical Library: Implications for eBook Collections \n"}, "12_p315": {"abstract": " This paper explores photo organization within an event photo stream, i.e. the chronological sequence of photos from a sin- gle event. The problem is important: with the advent of inexpensive, easy-to-use photo capture devices, people can take a large number of photos per event. A family trip, for example, may include hundreds of photos. In this work, we have developed a photo browser that uses automatically seg- mented groups of photos〞referred to as chapters〞to orga- nize such photos. The photo browser also affords users with a drag-and-drop interface to refine the chapter groupings. We conducted an exploratory study of 23 college students with their 8096 personal photos from 92 events, to under- stand the role of different spatial organization strategies in our chapter-based photo browser, in performing storytelling, photo search and photo set interpretation tasks. We also report novel insights on how the subjects organized their photos into chapters. We tested three layout strategies: bi- level, grid-stacking and space-filling, against a baseline plain grid layout. We found that subjects value the chronological order of the chapters more than maximizing screen space us- age and that they value chapter consistency more than the chronological order of the photos. For automatic chapter groupings, having low chapter boundary misses is more im- portant than having low chapter boundary false alarms; the choice of chapter criteria and granularity for chapter group- ings are very subjective; and subjects found that chapter- based photo organization helps in all three tasks of the user study. Users preferred the chapter-based layout strategies to the baseline at a statistically significant level, with the grid-stacking strategy preferred the most. ", "authors": "Jesse Prabawa Gozali1 Min-Yen Kan1 Hari Sundaram2 1Department of Computer Science, National University of Singapore, Singapore 2Arts Media & Engineering, Arizona State University, USA {jprabawa, kanmy}@comp.nus.edu.sg hari.sundaram@asu.edu ", "categories": " H.5.2 [Information Interfaces and Presentation]: User Interfaces General Terms Design, Human Factors. ", "id": "12_p315", "keywords": " Photo browser, photo digital library, photo layouts, event photo stream segmentation ", "title": "How Do People Organize Their Photos in Each Event and How Does It Affect Storytelling, Searching and Interpretation Tasks?\n"}, "12_p325": {"abstract": " Collaborative reading, or co-reading as we call it, is ubiquitous〞it occurs, for instance, in classrooms, book-clubs, and in less coordi- nated ways through mass media. While individual digital reading has been the subject of much investigation, research into co-reading is scarce. We report a two-phase field study of group reading to identify an initial set of user requirements. A co-reading interface is then designed that facilitates the coordination of group reading by providing temporary ＆Point-out＊ markers to indicate specific lo- cations within documents. A user study compared this new system with collaborative reading on paper, with a positive outcome; the differences in user behavior between paper and the new interface reveal intriguing insights into user needs and the potential benefits of digital media for co-reading. Keywords Co-reading, Documents, Collaboration, Slate PCs ", "authors": "Jennifer Pearson1, Tom Owen1, Harold Thimbleby1, George Buchanan2 1 FIT Lab, Swansea University 2 Centre for HCI Design, City University, London csjen, cstomo, csharold@swan.ac.uk george.buchanan.1@city.ac.uk ", "categories": " H.3.7 [Digital Libraries]: User Issues General Terms Design, Experimentation, Human Factors ", "id": "12_p325", "keywords": "", "title": "Co-Reading: Investigating Collaborative Group Reading\n"}, "13_p001": {"abstract": " Cultural institutions are increasingly opening up their repos- itories and contribute digital objects to social media plat- forms such as Flickr. In return they often receive user com- ments containing information that could be incorporated in their catalog records. Since judging the usefulness of a large number of user comments is a labor-intensive task, our aim is to provide automated support for filtering potentially useful social media comments on digital objects. In this paper, we discuss the notion of usefulness in the context of social media comments and compare it from end-users as well as expert- users perspectives. Then we present a machine-learning ap- proach to automatically classify comments according to their usefulness. Our approach makes use of syntactic and seman- tic comment features and also considers user context. We present the results of an experiment we did on user com- ments received in six different Flickr Commons collections. They show that a few relatively straightforward features can be used to infer useful comments with up to 89% accuracy. ", "authors": "Elaheh Momeni University of Vienna W?hringer Strasse 29, A-1090 Vienna momeni@cs.univie.ac.at Ke Tao Delft University of Technology Mekelweg 4, 2628 CD, Delft k.tao@tudelft.nl Bernhard Haslhofer Cornell University Ithaca, NY 14850 bh392@cornell.edu Geert-Jan Houben Delft University of Technology Mekelweg 4, 2628 CD, Delft g.j.p.m.houben@tudelft.nl ", "categories": " H.3.m [Information Storage and Retrieval]: Miscella- neous ", "id": "13_p001", "keywords": " User-generated Comment, Social Media, Usefulness Predic- tion, Flickr Commons ", "title": "Identification of Useful User Comments in Social Media: A Case Study on Flickr Commons\n"}, "13_p011": {"abstract": " Mathematical formulae in structural formats such as MathML and LATEX are becoming increasingly available. Moreover, repositories and websites, including ArXiv and Wikipedia, and growing numbers of digital libraries use these structural formats to present mathematical formulae. This presents an important new and challenging area of research, namely Mathematical Information Retrieval (MIR). In this paper, we propose WikiMirs, a tool to facilitate mathematical formula retrieval in Wikipedia. WikiMirs is aimed at searching for similar mathematical formulae based upon both textual and spatial similarities, using a new indexing and matching model developed for layout structures. A hierarchical generalization technique is proposed to generate sub-trees from presentation trees of mathematical formulae, and similarity is calculated based upon matching at different levels of these trees. Experimental results show that WikiMirs can efficiently support sub-structure matching and similarity matching of mathematical formulae. Moreover, WikiMirs obtains both higher accuracy and better ranked results over Wikipedia in comparison to Wikipedia Search and Egomath. We conclude that WikiMirs provides a new, alternative, and hopefully better service for users to search mathematical expressions within Wikipedia. ", "authors": "Xuan Hu, Liangcai Gao ? , Xiaoyan Lin, Zhi Tang Institute of Computer Science & Technology, Peking University, Beijing, China {xuan.hu, glc, linxiaoyan, tangzhi}@pku.edu.cn Xiaofan Lin A9.com Palo Alto, CA, USA xiaofanl@a9.com Josef B. Baker School of Computer Science, University of Birmingham Birmingham, UK J.Baker@cs.bham.ac.uk ", "categories": " H.3.3 [Information Systems]: Information Search and Retrieval ", "id": "13_p011", "keywords": " Mathematical Information Retrieval, Mathematical Re- source Management, Structure Matching ?Liangcai Gao is the corresponding author. ", "title": "WikiMirs: A Mathematical Information Retrieval System for Wikipedia\n"}, "13_p021": {"abstract": " There is growing interest by digital collection providers to engage collection users in interacting with the collection (e.g. by tagging or annotating collection contents) and with the collection organizers and other users (e.g. to form loose ＆communities＊ associated with the collection). At present, little has been documented as to the uptake of these mechanisms in specific collections, or the range of behaviors that emerge as users bend existing facilities to their own needs. This paper is one step in that direction: it describes the social information behaviors exhibited in a cultural heritage photography collection in The Commons on Flickr, and suggests implications for digital library design in response to these behaviors. ", "authors": "Sally Jo Cunningham University of Waikato New Zealand  sallyjo@cs.waikato.ac.nz Malika Mahoui Polis Center, IUPUI 1200 Waterway Blvd, Indianapolis, IN 46202  ", "categories": " H.3.7 [Digital Libraries]: User issues General Terms Design, Human Factors ", "id": "13_p021", "keywords": " Social Commenting, Public Photography Collection ", "title": "Interacting with and through a Digital Library Collection: Commenting behavior in Flickr＊s The Commons \n"}, "13_p025": {"abstract": " In addition to its broad popularity Wikipedia is also widely used for scholarly purposes. Many Wikipedia pages pertain to academic papers, scholars and topics providing a rich ecol- ogy for scholarly uses. Scholarly references and mentions on Wikipedia may thus shape the ※societal impact§ of a certain scholarly communication item, but it is not clear whether they shape actual ※academic impact§. In this paper we com- pare the impact of papers, scholars, and topics according to two different measures, namely scholarly citations and Wikipedia mentions. Our results show that academic and Wikipedia impact are positively correlated. Papers, authors, and topics that are mentioned on Wikipedia have higher aca- demic impact than those are not mentioned. Our findings validate the hypothesis that Wikipedia can help assess the impact of scholarly publications and underpin relevance in- dicators for scholarly retrieval or recommendation systems. ", "authors": "Xin Shuai School of Informatics and Computing Indiana University Bloomington IN, USA xshuai@indiana.edu Zhuoren Jiang College of Transportation Management Dalian Maritime University Dalian, China jzr1986@hotmail.com Xiaozhong Liu School of Library and Information Science Indiana University Bloomington IN, USA liu237@indiana.edu Johan Bollen School of Informatics and Computing Indiana University Bloomington IN, USA jbollen@indiana.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries ", "id": "13_p025", "keywords": " Wikipedia; Scholar Impact; Citation Analysis ", "title": "A Comparative Study of Academic and Wikipedia Ranking\n"}, "13_p029": {"abstract": " The reliable and consistent long-term preservation of digital content and metadata is becoming increasingly important 每 even though the storage media used are potentially subject to failures, or the data formats may become obsolete over time. A common approach is to replicate data across several sites to increase their availability. Nevertheless, network, software, or hardware failures as well as the evolution of data formats have to be coped with in a timely and, ideally, an autonomous way, without intervention of an administra- tor. In this paper we present DISTARNET, a distributed, autonomous long-term digital preservation system. Essen- tially, DISTARNET exploits dedicated processes to ensure the integrity and consistency of data with a given replication degree. At the data level, DISTARNET supports complex data objects, the management of collections, annotations, and arbitrary links between digital objects. At process level, dynamic replication management, consistency checking, and automated recovery of the archived digital objects is pro- vided utilizing autonomic behavior governed by preservation policies without any centralized component. We present the concepts and implementation of the distributed DISTAR- NET preservation approach. Most importantly, we provide details of the qualitative and quantitative evaluation of the DISTARNET system. The former addresses the effective- ness of the internal preservation processes while the latter evaluates DISTARNET＊s performance regarding the overall archiving storage capacity and scalability. ", "authors": "Ivan Subotic Lukas Rosenthaler Digital Humanities Lab University of Basel Switzerland {ivan.subotic|lukas.rosenthaler}@unibas.ch Heiko Schuldt Databases and Information Systems University of Basel Switzerland heiko.schuldt@unibas.ch ", "categories": ": H.3 [Information Storage and Retrieval]: Digital Libraries ", "id": "13_p029", "keywords": ": Long-Term Preservation; Autonomic System ", "title": "A Distributed Archival Network for Process-Oriented Autonomic Long-Term Digital Preservation\n"}, "13_p039": {"abstract": " When a user views an archived page using the archive＊s user interface (UI), the user selects a datetime to view from a list. The archived web page, if available, is then displayed. From this display, the web archive UI attempts to simulate the web browsing experience by smoothly transitioning be- tween archived pages. During this process, the target date- time changes with each link followed; drifting away from the datetime originally selected. When browsing sparsely- archived pages, this nearly-silent drift can be many years in just a few clicks. We conducted 200,000 acyclic walks of archived pages, following up to 50 links per walk, comparing the results of two target datetime policies. The Sliding Tar- get policy allows the target datetime to change as it does in archive UIs such as the Internet Archive＊s WaybackMachine. The Sticky Target policy, represented by the Memento API, keeps the target datetime the same throughout the walk. We found that the Sliding Target policy drift increases with the number of walk steps, number of domains visited, and choice (number of links available). However, the Sticky Tar- get policy controls temporal drift, holding it to less than 30 days on average regardless of walk length or number of do- mains visited. The Sticky Target policy shows some increase as choice increases, but this may be caused by other factors. We conclude that based on walk length, the Sticky Target policy generally produces at least 30 days less drift than the Sliding Target policy. ", "authors": "Scott G. Ainsworth Old Dominion University Norfolk, VA, USA sainswor@cs.odu.edu Michael L. Nelson Old Dominion University Norfolk, VA, USA mln@cs.odu.edu ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries ", "id": "13_p039", "keywords": " Digital Preservation, HTTP, Resource Versioning, Temporal Applications, Web Architecture, Web Archiving ", "title": "Evaluating Sliding and Sticky Target Policies by Measuring Temporal Drift in Acyclic Walks Through a Web Archive\n"}, "13_p049": {"abstract": " The Medusa digital preservation service at the University of Illinois at Urbana-Champaign provides a storage environment for digital content selected for long-term retention by content managers and producers affiliated with the Library in order to ensure its enduring access and use. This paper reports on Medusa development, with emphasis on the research processes that informed key decisions related to its design, the central role of PREMIS metadata in its architecture, and future directions of integrating PREMIS management into a Fedora repository architecture. In so doing, it describes a strategy of digital preservation content management that draws strength from the creation and management of comprehensive PREMIS preservation metadata records.    ", "authors": "Kyle Rimkus University of Illinois at Urbana-Champaign 44 Library Urbana, IL 61801 (+1) (217) 300-3842 rimkus@illinois.edu Thomas Habing University of Illinois at Urbana-Champaign 155 Grainger Engineering Library Urbana, IL 61801 (+1) (217) 244-4425 thabing@illinois.edu   ", "categories": " H.3.7 [Digital Libraries]: Systems issues ", "id": "13_p049", "keywords": "  Digital Preservation, Medusa, PREMIS    ", "title": "Medusa at the University of Illinois at Urbana-Champaign: A Digital Preservation Service Based on PREMIS \n"}, "13_p053": {"abstract": " Smartphones and tablets are increasingly used to access the Web, and many websites now provide alternative sites tailored specifically for these mobile devices. Web archivists are in need of tools to aid in archiving this equally ephemeral Mobile Web. We present Findmobile, a tool for automating the discovery of mobile websites. We tested our tool in an experiment examining 10K popular websites and found that the most frequently used technique used by popular websites to direct mobile users to mobile sites was by automated client and server-side redirection. We found that nearly half of mobile web pages differ dramatically from their stationary web counterparts and that the most popular websites are those most likely to have mobile-specific pages. ", "authors": "Richard Schneider  Harding University Computer Science Dept Searcy, Arkansas, USA 72149 rschneid@harding.edu  Frank McCown Harding University Computer Science Dept Searcy, Arkansas, USA 72149 fmccown@harding.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 Collection.  General Terms Design, Experimentation, Measurement. ", "id": "13_p053", "keywords": " Mobile web, web crawling, web archiving. ", "title": "First Steps in Archiving the Mobile Web: Automated Discovery of Mobile Websites \n"}, "13_p057": {"abstract": " In this paper we explore the vertical selection methods in aggregated search in the specific domain of topics for chil- dren between 7 and 12 years old. A test collection consisting of 25 verticals, 3.8K queries and relevant assessments for a large sample of these queries mapping relevant verticals to queries was built. We gather relevant assessment by envis- aging two aggregated search systems: one in which the Web vertical is always displayed and in which each vertical is as- sessed independently from the web vertical. We show that both approaches lead to a di?erent set of relevant verticals and that the former is prone to bias of visually oriented ver- ticals. In the second part of this paper we estimate the size of the verticals for the target domain. We show that em- ploying the global size and domain specific size estimation of the verticals lead to significant improvements when us- ing state-of-the art methods of vertical selection. We also introduce a novel vertical and query representation based on tags from social media and we show that its use lead to significant performance gains. ", "authors": "Sergio Duarte Torres, Djoerd Hiemstra and Theo Huibers University of Twente The Netherlands duartes,hiemstra,huibers@cs.utwente.nl ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval ", "id": "13_p057", "keywords": " vertical selection, aggregated search, children, social media, evaluation ", "title": "Vertical Selection in the Information Domain of Children\n"}, "13_p067": {"abstract": " A key challenge facing educational technology researchers is how to provide structure and guidance when learners use unstructured and open tools such as digital libraries for their own learning. This work attempts to use computational methods to identify that struc- ture in a domain independent way and support learners as they navigate and interpret the information they find. This article high- lights a computational methodology for generating a pedagogical sequence through core learning goals extracted from a collection of resources which in this case, are resources from the Digital Library for Earth System Education (DLESE). This article describes how we use the technique of multi-document summarization to extract the core learning goals from the digital library resources and how we create a supervised classifier that performs a pair-wise classifi- cation of the core learning goals; the judgments from these classifi- cations are used to automatically generate pedagogical sequences. Results show that we can extract good core learning goals and make pair-wise classifications that are up to 76% similar to the pair-wise classifications generated from pedagogical sequences created by two science education experts. Thus we can dynamically gener- ate pedagogically meaningful learning paths through digital library resources. ", "authors": "Ifeyinwa Okoye Institute of Cognitive Science Department of Computer Science University of Colorado at Boulder okoye@colorado.edu Tamara Sumner Institute of Cognitive Science Department of Computer Science University of Colorado at Boulder sumner@colorado.edu Steven Bethard Institute of Cognitive Science Department of Computer Science University of Colorado at Boulder steven.bethard@colorado.edu ", "categories": " H.1.2 [Information Systems]: Models and Principles〞User/Machine Systems; I.2.7 [Computing Methodologies]: Artificial Intelligence〞 Natural Language Processing; L.3.6 [Science and Technology of Learning]: Methodology/Tools/Technology〞Technology Enhanced Learning ", "id": "13_p067", "keywords": " pedagogical sequence; core learning goal; digital libraries; machine learning; learning trajectory; learning pathway ", "title": "Automatic Extraction of Core Learning Goals and Generation of Pedagogical Sequences Through a Collection of Digital Library Resources\n"}, "13_p077": {"abstract": " Syllabi are rich educational resources. However, finding Computer Science syllabi on a generic search engine does not work well. Towards our goal of building a syllabus collection we have trained various Machine Learning classifiers to recognize Computer Science syllabi from other web pages and the discipline that they represent (AI or SE for instance) among other things. We have crawled 50 Computer Science departments in the US and gathered 100,000 candidate pages. Our best classifiers are more than 90% accurate at identifying syllabi from real-world data. The syllabus repository we created is live for public use [1] and contains more than 3000 syllabi that our classifiers filtered out from the crawl data. We present an analysis of the various feature selection methods and classifiers used.  ", "authors": "Syllabi Nakul Rathod , Lillian N. Cassel  Department of Computing Sciences Villanova University Villanova PA 19085 +1 610 519 7341 nakulrathod@gmail.com, lillian.cassel@villanova.edu   ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering. H.3.7 [Digital Libraries]:Collection. I.5.2 [Design Methodology]: Feature evaluation and selection, Classifier design and evaluation ", "id": "13_p077", "keywords": " Digital Libraries, Collections, Machine Learning, Text Mining, Web Mining, Web Crawling, Classification, Feature Selection. ", "title": "Building a Search Engine for Computer Science Course \n"}, "13_p087": {"abstract": " Expert search or recommendation involves the retrieval of people (experts) in response to a query and on occasion, a given set of constraints. In this paper, we address ex- pert recommendation in academic domains that are differ- ent from web and intranet environments studied in TREC. We propose and study graph-based models for expertise re- trieval with the objective of enabling search using either a topic (e.g. ※Information Extraction§) or a name (e.g. ※Bruce Croft§). We show that graph-based ranking schemes despite being ※generic§ perform on par with expert ranking models specific to topic-based and name-based querying. ", "authors": "Sujatha Das G. Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 USA gsdas@cse.psu.edu Prasenjit Mitra, C. Lee Giles Information Sciences and Technology Computer Science and Engineering The Pennsylvania State University University Park, PA 16802 USA {pmitra,giles}@ist.psu.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval Models ", "id": "13_p087", "keywords": " PageRank, Author-Document-Topic graphs, Expert Search, Similar Expert Finding ", "title": "Ranking Experts using Author-Document-Topic graphs\n"}, "13_p097": {"abstract": " The impact of scientific research has traditionally been quan- tified using productivity indices such as the well-known h- index. On the other hand, different research fields〞in fact, even different research areas within a single field〞may have very different publishing patterns, which may not be well described by a single, global index. In this paper, we argue that productivity indices should account for the singulari- ties of the publication patterns of different research areas, in order to produce an unbiased assessment of the impact of scientific research. Inspired by ranking aggregation ap- proaches in distributed information retrieval, we propose a novel approach for ranking researchers across multiple re- search areas. Our approach is generic and produces cross- area versions of any global productivity index, such as the volume of publications, citation count and even the h-index. Our thorough evaluation considering multiple areas within the broad field of Computer Science shows that our cross- area indices outperform their global counterparts when as- sessed against the official ranking produced by CNPq, the Brazilian National Research Council for Scientific and Tech- nological Development. As a result, this paper contributes a valuable mechanism to support the decisions of funding bodies and research agencies, for example, in any research assessment effort. ", "authors": "Harlley Lima, Thiago H. P. Silva, Mirella M. Moro, Rodrygo L. T. Santos, Wagner Meira Jr., Alberto H. F. Laender Universidade Federal de Minas Gerais Belo Horizonte, Brazil {harlley,thps,mirella,rodrygo,meira,laender}@dcc.ufmg.br ", "categories": " H.4 [Information Systems Applications]: Miscellaneous ", "id": "13_p097", "keywords": " Research performance; Bibliometric indicators; Ranking ag- gregation; Cross-disciplinarity ", "title": "Aggregating Productivity Indices for Ranking Researchers across Multiple Areas\n"}, "13_p107": {"abstract": " With the amount of digitalized documents increasing exponentially, it is more difficult for users to keep up to date with the knowledge in their domain. In this paper, we present a framework named IFME (Information Filtering by Multiple Examples) in a digital library environment to help users identify the literature related to their interests by leveraging the Positive Unlabeled learning (PU learning). Using a few relevant documents provided by a user and considering the documents in an online database as unlabeled data (called U), it ranks the documents in U using a PU learning algorithm. From the experimental results, we found that while the approach performed well when a large set of relevant feedback documents were available, it performed relatively poor when the relevant feedback documents were few. We improved IFME by combining PU learning with under-sampling to tune the performance. Using Mean Average Precision (MAP), our experimental results indicated that with under-sampling, the performance improved significantly even when the size of P was small. We believe the PU learning based IFME framework brings insights to develop more effective digital library systems.  ", "authors": "Mingzhu Zhu, Chao Xu, Yi-Fang Brook Wu Information Systems Department New Jersey Institute of Technology Newark, NJ 07102, USA {mz59, cx26, wu}@njit.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Information Retrieval General Terms Algorithms, Experimentation ", "id": "13_p107", "keywords": " Information Retrieval, Positive Unlabeled Learning, Text Classification, Search by Multiple Examples, Relevance Feedback ", "title": "IFME: Information Filtering by Multiple Examples with Under-Sampling in a Digital Library Environment \n"}, "13_p111": {"abstract": " Scientists continue to find challenges in the ever increasing amount of information that has been produced on a world wide scale, during the last decades. When writing a pa- per, an author searches for the most relevant citations that started or were the foundation of a particular topic, which would very likely explain the thinking or algorithms that are employed. The search is usually done using specific key- words submitted to literature search engines such as Google Scholar and CiteSeer. However, finding relevant citations is distinctive from producing articles that are only topically similar to an author＊s proposal. In this paper, we address the problem of citation recommendation using a singular value decomposition approach. The models are trained and evaluated on the Citeseer digital library. The results of our experiments show that the proposed approach achieves sig- nificant success when compared with collaborative filtering methods on the citation recommendation task. ", "authors": "Cornelia Caragea1, Adrian Silvescu2, Prasenjit Mitra3, C. Lee Giles3 1Department of Computer Science and Engineering, University of North Texas 2Naviance, Inc., Washington DC 3School of Information Sciences and Technology, The Pennsylvania State University ccaragea@unt.edu, silvescu@gmail.com, pmitra@ist.psu.edu, giles@ist.psu.edu ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval ", "id": "13_p111", "keywords": " citation recommendation; information filtering; collabora- tive filtering; singular value decomposition. ", "title": "Can＊t See the Forest for the Trees? A Citation Recommendation System\n"}, "13_p115": {"abstract": " Clifford Lynch describes the value of digital libraries as adding interpretive layers to collections of cultural heritage materials. However, standard forms of evaluation, which focus on the degree to which a system solves problems, are insufficient assessments of the expressive qualities that distinguish such interpretive content. This paper describes a form of comparative, structured appraisal that supplements the existing repertoire of assessment techniques. Comparative appraisal uses a situationally defined set of procedures to be followed by multiple assessors in examining a group of artifacts. While this approach aims for a goal of systematic comparison based on selected dimensions, it is grounded in the recognition that expressive qualities are not conventionally measurable and that absolute agreement between assessors is neither possible nor desirable. The conceptual basis for this comparative method is drawn from the literature of writing assessment.  ", "authors": "Melanie Feinberg School of Information The University of Texas at Austin Austin, TX USA  feinberg@ischool.utexas.edu    ", "categories": " H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous General Terms Design ", "id": "13_p115", "keywords": " Evaluation; criticism; assessment  ", "title": "Comparative Appraisal: Systematic Assessment of Expressive Qualities \n"}, "13_p125": {"abstract": " The digital library evaluation field has an evolving nature and it is characterized by a noteworthy proclivity to enfold various methodological orientations. Given the fact that the scientific literature in the specific domain is vast, researchers require tools that will exhibit either commonly acceptable practices, or areas for further investigation. In this paper, a data mining methodology is proposed to identify prominent patterns in the evaluation of digital libraries. Using Machine Learning techniques, all papers presented in the ECDL and JCDL conferences between the years 2001 and 2011 were categorized as relevant or non-relevant to the DL evaluation domain. Then, the relevant papers were semantically annotated according to the Digital Library Evaluation Ontology (DiLEO) vocabulary. The produced set of annotations was clustered to evaluation patterns for the most frequently used tools, methods and goals of the domain. Our findings highlight the expressive nature of DiLEO, place emphasis on semantic annotation as a necessary step in handling domain- centric corpora and underline the potential of the proposed methodology in the profiling of evaluation activities. ", "authors": "Eleni Afiontzi Department of Informatics, Athens University of Economics & Business, Athens, Greece afiontzhe@aueb.gr   Michalis Sfakakis Department of Archives & Library Science, Ionian University,  Corfu, Greece sfakakis@ionio.gr Giannis Kazadeis Department of Informatics, Athens University of Economics & Business, Athens, Greece kazadehsi@aueb.gr   Giannis Tsakonas Department of Archives & Library Science, Ionian University, Corfu, Greece gtsak@ionio.gr Leonidas Papachristopoulos Department of Archives and Library Science, Ionian University, Corfu, Greece l11papa@ionio.gr  Christos Papatheodorou Department of Archives & Library Science, Ionian University, Corfu, Greece papatheodor@ionio.gr  ", "categories": " H.3 [Information Storage and Retrieval]: H.3.7 Digital Libraries  ", "id": "13_p125", "keywords": " Digital library evaluation; ontologies; semantic annotation; data mining; research trends.  ", "title": "Charting the Digital Library Evaluation Domain with a Semantically Enhanced Mining Methodology\n"}, "13_p135": {"abstract": " In this paper, we studied interdisciplinary structures by looking into how online academic groups of different disciplines share members and followers. Results based on Mendeley online groups show clear interdisciplinary structures, indicating Mendeley online groups as a promising data source and a new perspective of disciplinarity and interdisciplinarity studies. ", "authors": "Jiepu Jiang School of Information Sciences,  University of Pittsburgh jiepu.jiang@gmail.com Chaoqun Ni School of Informatics and Computing,  Indiana University Bloomington chni@indiana.edu Daqing He, Wei Jeng School of Information Sciences,  University of Pittsburgh {dah44, wej9}@pitt.edu ", "categories": " H.2.8 [Database Applications]: Scientific Databases. General Terms Measurement, Verification. ", "id": "13_p135", "keywords": " Interdisciplinarity, disciplinarity, Mendeley, group, altmetrics. ", "title": "Mendeley Group as a New Source of Interdisciplinarity Study: How Do Disciplines Interact on Mendeley?\n"}, "13_p139": {"abstract": " Using bibliometric methods, this exploratory work shows evidence of transitions in the field of computer science since the emergence of HCI as a distinct sub-discipline. We mined the ACM Digital Library in order to expose relationships between sub-disciplines in computer science, focusing in particular on the transformational nature of the SIG Computer-Human Interaction (CHI) in relation to other SIGs. Our results suggest shifts in the field due to broader social, economic and political changes in computing research and are intended as a prolegomena to further investigations. ", "authors": "Shion Guha1, Stephanie Steinhardt2,  Syed Ishtiaque Ahmed1 1Department of Information Science 2Department of Communication Cornell University, Ithaca, NY 14850 Email: {sg648, sbg94, sa738}@cornell.edu Carl Lagoze School of Information University of Michigan Ann Arbor, MI 48109 Email: clagoze@umich.edu    ", "categories": " K2. History of: Theory. ", "id": "13_p139", "keywords": " scientometrics; CHI; digital libraries ", "title": "Following Bibliometric Footprints: The ACM Digital Library and the Evolution of Computer Science\n"}, "13_p143": {"abstract": " We propose a new theory to quantify information in proba- bility distributions and derive a new document representa- tion model for text clustering. By extending Shannon en- tropy to accommodate a non-linear relation between infor- mation and uncertainty, the proposed Least Information the- ory (LIT) provides insight into how terms can be weighted based on their probability distributions in documents vs. in the collection. We derive two basic quantities in the doc- ument clustering context: 1) LI Binary (LIB) which quan- tifies information due to the observation of a term＊s (bi- nary) occurrence in a document; and 2) LI Frequency (LIF) which measures information for the observation of a ran- domly picked term from the document. Both quantities are computed given term distributions in the document col- lection as prior knowledge and can be used separately or combined to represent documents for text clustering. Ex- periments on four benchmark text collections demonstrate strong performances of the proposed methods compared to classic TF*IDF. Particularly, the LIB*LIF weighting scheme, which combines LIB and LIF, consistently outperforms TF*IDF in terms of multiple evaluation metrics. The least informa- tion measure has a potentially broad range of applications beyond text clustering. ", "authors": "Weimao Ke Lab for Information Network & Computing Studies College of Information Science and Technology Drexel University, Philadelphia, PA 19104, U.S.A. wk@drexel.edu ", "categories": " H.3.1 [Information storage and retrieval]: Content Anal- ysis and Indexing; H.3.3 [Information storage and re- trieval]: Information Search and Retrieval〞Clustering General Terms Theory, Algorithms, Performance, Experimentation ", "id": "13_p143", "keywords": " term weighting, information measure, semantic information, document representation, text clustering ", "title": "Information-theoretic Term Weighting Schemes for Document Clustering\n"}, "13_p153": {"abstract": " To help generate relevant suggestions for researchers, recommen- dation systems have started to leverage the latent interests in the publication profiles of the researchers themselves. While using such a publication citation network has been shown to enhance performance, the network is often sparse, making recommendation difficult. To alleviate this sparsity, we identify ※potential citation papers§ through the use of collaborative filtering. Also, as differ- ent logical sections of a paper have different significance, as a sec- ondary contribution, we investigate which sections of papers can be leveraged to represent papers effectively. On a scholarly paper recommendation dataset, we show that rec- ommendation accuracy significantly outperforms state-of-the-art recommendation baselines as measured by nDCG and MRR, when we discover potential citation papers using imputed similarities via collaborative filtering and represent candidate papers using both the full text and assigning more weight to the conclusion sections. ", "authors": "Kazunari Sugiyama National University of Singapore Computing 1, 13 Computing Drive, Singapore 117417 sugiyama@comp.nus.edu.sg Min-Yen Kan1,2 1National University of Singapore 2NUS Interactive and Digital Media Institute Computing 1, 13 Computing Drive, Singapore 117417 kanmy@comp.nus.edu.sg ", "categories": " H.3.3 [Information Search and Retrieval]: Information filtering, Search process; H.3.7 [Digital Libraries]: Systems issues, User issues General Terms Algorithms, Experimentation, Performance ", "id": "13_p153", "keywords": " Digital library, Information retrieval, Recommendation, Citation analysis, Collaborative filtering ", "title": "Exploiting Potential Citation Papers in Scholarly Paper Recommendation\n"}, "13_p163": {"abstract": " Highly heterogeneous collections present difficulties to term weighting models that are informed by corpus-level frequen- cies. Collections which span multiple languages or large time periods do not provide realistic statistics on which words are interesting to a system. This paper presents a case where diverse corpora can frustrate term weighting and proposes a modification that weighs documents according to their class or cluster within the collection. In cases of diverse corpora, the proposed modification better represents the intuitions behind corpus-level document frequencies. ", "authors": "Peter Organisciak Graduate School of Library and Information Science University of Illinois at Urbana-Champaign 501 E. Daniel Street, MC-493 Champaign, IL, USA organis2@illinois.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Retrieval models ", "id": "13_p163", "keywords": " term weighting; diverse corpora ", "title": "Addressing Diverse Corpora With Cluster-Based Term Weighting\n"}, "13_p167": {"abstract": " Scatter/Gather is a document browsing and information re- trieval method based on document clustering. It is de- signed to facilitate user articulation of information needs through iterative clustering and interactive browsing. This paper reports on a study that investigated the effectiveness of Scatter/Gather browsing for information retrieval. We conducted a within-subject user study of 24 college students to investigate the utility of a Scatter/Gather system, to ex- amine its strengths and weaknesses, and to receive feedback from users on the system. Results show that the clustering- based Scatter/Gather method was more difficult to use than the classic information retrieval systems in terms of user perception. However, clustering helped the subjects accom- plish the tasks more efficiently. Scatter/Gather clustering was particularly useful in helping users finish tasks that they were less familiar with and allowed them to search with fewer words. Scatter/Gather tended to be more useful when it was more difficult for the user to do query specification for an in- formation need. Topic familiarity and specificity had signifi- cant influences on user perceived retrieval effectiveness. The influences appeared to be greater with the Scatter/Gather system compared to a classic search system. Topic familiar- ity also had significant influences on query formulation. ", "authors": "Xuemei Gong, Weimao Ke Lab for Info Network & Computing Studies College of Information Science and Technology The iSchool at Drexel, Drexel University 3141 Chest St, Philadelphia, PA 19104 xg45@drexel.edu, wk@drexel.edu Yan Zhang, Ramona Broussard School of Information University of Texas at Austin 1616 Guadalupe Street, Austin, TX 78701 yanz@ischool.utexas.edu, lindley.broussard@gmail.com ", "categories": " H.3.1 [Information storage and retrieval]: Content Anal- ysis and Indexing; H.3.3 [Information storage and re- trieval]: Information Search and Retrieval〞Clustering General Terms Algorithms, Performance, Experimentation ", "id": "13_p167", "keywords": " Text clustering, Search result presentation, Scatter/Gather, User interface, Exploratory search, Interaction, Relevance ", "title": "Interactive Search Result Clustering: A Study of User Behavior and Retrieval Effectiveness\n"}, "13_p171": {"abstract": " This paper explores the role of audio as a means to access books in a digital library while being at the location referred to in the books. The books are sourced from the digital library and can either be accompanied by pre-recorded audio or synthesized using text-to-speech. The paper details the functional requirements, design and implementation of Tipple. The concept was extensively tested in three field studies. ", "authors": "Annika Hinze University of Waikato, Hamilton, New Zealand hinze@cs.waikato.ac.nz David Bainbridge University of Waikato, Hamilton, New Zealand davidb@cs.waikato.ac.nz  ", "categories": " H.3.7 [Dissemination]: Digital Libraries Author ", "id": "13_p171", "keywords": " Design, Experimentation, Human Factors ", "title": "Tipple: Location-Triggered Mobile Access to a Digital Library for Audio Books \n"}, "13_p181": {"abstract": " Forensic document analysis has become an important aspect of investigation of many different kinds of crimes from money laundering to fraud and from cybercrime to smuggling. The current workflow for analysts includes powerful tools, such as Palantir and Analyst＊s Notebook, for moving from evidence to actionable intelligence and tools for finding documents among the millions of files on a hard disk, such as Forensic Toolkit (FTK). Analysts often leave the process of sorting through collections of seized documents to filter out noise from actual evidence to highly labor-intensive manual efforts. This paper presents the Redeye Analysis Workbench, a tool to help analysts move from manual sorting of a collection of documents to performing intelligent document triage over a digital library. We will discuss the tools and techniques we build upon in addition to an in-depth discussion of our tool and how it addresses two major use cases we observed analysts performing. Finally, we also include a new layout algorithm for radial graphs that is used to visualize clusters of documents in our system. ", "authors": "Paul Logasa Bogen II, Amber McKenzie, Rob Gillen Computational Data Analytics Group Oak Ridge National Laboratory Oak Ridge, TN redev@ornl.gov ", "categories": " H.3.7 [Digital Libraries]: Collection, Systems issues. I.7.5 [Document Capture]: Document analysis. ", "id": "13_p181", "keywords": " Redeye, Document Triage, Forensic Science ", "title": "Redeye: A Digital Library for Forensic Document Triage\n"}, "13_p191": {"abstract": " Digital collections of primary source materials have potential to change how citizen historians and scholars research and engage with local history. The problem at the heart of this study is how to evaluate local history coverage, particularly among large-scale, distributed collections and aggregations. As part of an effort to holistically evaluate one such national aggregation, the Institute of Museum and Library Services (IMLS) Digital Collections and Content (DCC), we conducted a national survey of reference service providers at academic and public libraries throughout the United States. In this paper, we report the results of this survey that appear relevant to local history and collection evaluation, and consider the implications for scalable evaluation of local history coverage in massive, aggregative digital libraries. ", "authors": "Katrina Fenlon Graduate School of Library and Information Science University of Illinois at  Urbana-Champaign 501 E. Daniel St. Champaign, IL 61820 Kfenlon2@illinois.edu Virgil E. Varvel Jr. Graduate School of Library and Information Science University of Illinois at  Urbana-Champaign 501 E. Daniel St. Champaign, IL 61820 Vvarvel@illinois.edu  ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 collection, user issues, dissemination. ", "id": "13_p191", "keywords": " Local history, collections, metadata, aggregations, evaluation ", "title": "Local Histories in Global Digital Libraries: Identifying Demand and Evaluating Coverage \n"}, "13_p195": {"abstract": " Because of the unique characteristics of music scores, search- ing bibliographical music collections using traditional library systems can be a challenge. In this paper, we present two specific search functionalities added to the Swiss RISM data- base and describe how they improve the user experience. The first is a search functionality for instrument and vocal part distribution that leverages coded information available in the MarcXML records of the database. It enables scores for precise ensemble distribution to be retrieved. The sec- ond is a search functionality of music notation excerpts tran- scribed from the beginning of the pieces, known as music in- cipits. The incipit search is achieved using a well-known mu- sic information retrieval (MIR) tool, Themefinder. A nov- elty of our implementation is that it can operate at three different levels (pitch, duration and metric), singularly or combined, and that it is performed through a specifically- developed intuitive graphical interface for note input and parameter selection. The two additions illustrate why it is important to take into consideration the particularities of music scores when designing a search system and how MIR tools can be beneficially integrated into existing heteroge- neous bibliographic score collections. ", "authors": "Laurent Pugin Swiss RISM Office Hallwylstrasse 15 / CH-3000 Bern laurent.pugin@rism-ch.org Rodolfo Zitellini Swiss RISM Office Hallwylstrasse 15 / CH-3000 Bern rodolfo.zitellini@rism-ch.org ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries〞User issues; J.5 [Computer Applications]: Arts and HumanitiesMusic ", "id": "13_p195", "keywords": " Music information retrieval, Music instruments, User inter- faces ", "title": "Instrument Distribution and Music Notation Search for Enhancing Bibliographic Music Score Retrieval\n"}, "13_p199": {"abstract": " This paper presents an approach for predicting the gender orientation of any given first name over time based on a set of search engine queries with the name prefixed by masculine and feminine markers (e.g., ※Uncle Taylor§). We hypothesize that these markers can capture the great majority of variability in gender orientation, including temporal changes. To test this hypothesis, we train a logistic regression model, with time- varying marker weights, using marker counts from Bing.com to predict male/female counts for 85,406 names in US Social Security Administration (SSA) data during 1880-2008. The model misclassifies 2.25% of the people in the SSA dataset (slightly worse than the 1.74% pure error rate) and provides accurate predictions for names beyond the SSA. The misclassification rate is higher in recent years (due to increasing name diversity), for general English words (e.g., Will), for names from certain countries (e.g., China), and for rare names. However, the model tends to err on the side of caution by predicting neutral/unknown rather than false positive. As hypothesized, the markers also capture temporal patterns of androgyny. For example, Daughter is a stronger female predictor for recent years while Grandfather is a stronger male predictor around the turn of the 20th century. The model has been implemented as a web-tool called Genni (available via http://abel.lis.illinois.edu/) that displays the predicted proportion of females vs. males over time for any given name. This should be a valuable resource for those who utilize names in order to discern gender on a large scale, e.g., to study the roles of gender and diversity in scholarly work based on digital libraries and bibliographic databases where the authors＊ names are listed. ", "authors": "Brittany N. Smith1, Mamta Singh2, and Vetle I. Torvik3 Graduate School of Library and Information Science University of Illinois at Urbana-Champaign Champaign, IL 61820, USA 1bnsmith3@illinois.edu, 2mamta2.singh@gmail.com, 3vtorvik@illinois.edu ", "categories": " I.5.1 [Pattern Recognition]: Models - Statistical; H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing 每 Linguistic processing.  General Terms Algorithms, Measurement, Experimentation. ", "id": "13_p199", "keywords": " Gender, androgyny, data mining, temporal prediction, bibliometrics, search engine, textual markers, semantic orientation ", "title": "A Search Engine Approach to Estimating Temporal Changes in Gender Orientation of First Names \n"}, "13_p209": {"abstract": " This paper presents a new name disambiguation method that exploits user feedback on ambiguous references across iterations. An unsupervised step is used to define pure train- ing samples, and a hybrid supervised step is employed to learn a classification model for assigning references to au- thors. Our classification scheme combines the Optimum- Path Forest (OPF) classifier with complex reference simi- larity functions generated by a Genetic Programming frame- work. Experiments demonstrate that the proposed method yields better results than state-of-the-art disambiguation me- thods on two traditional datasets. ", "authors": "Thiago A. Godoi, Ricardo da S. Torres, and Ariadne M. B. R. Carvalho Institute of Computing University of Campinas {thiago.godoi,rtorres, ariadne}@ic.unicamp.br Marcos Andr谷 Gon?alves Dept. of Computer Science Federal University of Minas Gerais mgoncalv@dcc.ufmg.br Anderson A. Ferreira Dept. of Computer Science Federal University of Ouro Preto ferreira@iceb.ufop.br Weiguo Fan and Edward A. Fox Dept. of Computer Science Virginia Tech {wfan,fox}@vt.edu ", "categories": " H.3.3 [Information Search and Retrieval]: Information Retrieval; I.5.2 [Pattern Recognition]: Classifier design and evaluation General Terms Algorithms, Experimentation ", "id": "13_p209", "keywords": " Name Disambiguation, Relevance Feedback, Genetic Pro- gramming, Optimum-Path Forest Classifier ", "title": "A Relevance Feedback Approach for the Author Name Disambiguation Problem\n"}, "13_p219": {"abstract": " We introduce Enlil, an information extraction system that discov- ers the institutional affiliations of authors in scholarly papers. Enlil consists of two steps: one that first identifies authors and affilia- tions using a conditional random field; and a second support vec- tor machine that connects authors to their affiliations. We bench- mark Enlil in three separate experiments drawn from three different sources: the ACL Anthology, the ACM Digital Library, and a set of cross-disciplinary scientific journal articles acquired by query- ing Google Scholar. Against a state-of-the-art production base- line, Enlil reports a statistically significant improvement in F1 of nearly 10% (p ? 0.01). In the case of multidisciplinary articles from Google Scholar, Enlil is benchmarked over both clean input (F1 > 90%) and automatically-acquired input (F1 > 80%). We have deployed Enlil in a case study involving Asian genomics research publication patterns to understand how government spon- sored collaborative links evolve. Enlil has enabled our team to construct and validate new metrics to quantify the facilitation of research as opposed to direct publication. ", "authors": "Huy Hoang Nhat Do1,2 Muthu Kumar Chandrasekaran2 Philip S. Cho2 Min每Yen Kan1,3?? 1Department of Computer Science, School of Computing 2Asia Research Institute 3NUS Interactive and Digital Media Institute National University of Singapore {a0079636,a0092669,aripcss,dcskmy}@nus.edu.sg ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries General Terms Algorithms, Experimentation ", "id": "13_p219", "keywords": " Metadata Extraction, Logical Structure Discovery, Conditional Ran- dom Fields, Support Vector Machine, Rich Document Features ?This work was supported in part by the National University of Singapore - Global Asia Institute Research Grant [AC-2010-1-004] and the Fetzer Franklin Trust project on Culture and Cognition. ?Contact Author. ", "title": "Extracting and Matching Authors and Affiliations in Scholarly Documents\n"}, "13_p229": {"abstract": " Video games and interactive media are increasingly becoming important part of our culture and everyday life, and subsequently, of archival and digital library collections. However, existing organizational systems often use vague or inconsistent terms to describe video games or attempt to use schemas designed for textual bibliographic resources. Our research aims to create a standardized metadata schema and encoding scheme that provides an intelligent and comprehensive way to represent video games. We conducted interviews with 24 gamers, focusing on their video game-related information needs and seeking behaviors. We also performed a domain analysis of current organizational systems used in catalog records and popular game websites, evaluating metadata elements used to describe games. With these results in mind, we created a list of elements which form a metadata schema for describing video games, with both a core set of 16 elements and an extended set of 46 elements providing more flexibility in expressing the nature of a game.  ", "authors": "Jin Ha Lee, Hyerim Cho, Violet Fox University of Washington Mary Gates Hall, Suite 370 Seattle, WA 98195 +1 206.685.0153 {jinhalee, chohr113, vfox}@uw.edu Andrew Perti Seattle Interactive Media Museum 305 Harrison St Seattle, WA 98109 +1 518.653.5864 andrew.perti@thesimm.org   ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries 每 Standards, K.8.0 [Personal Computing]: Games General Terms Design, Standardization, Theory ", "id": "13_p229", "keywords": " Video Games, Interactive Media, Cultural Artifacts, Metadata, Description, Seattle Interactive Media Museum  ", "title": "User-centered Approach in Creating a Metadata Schema for Video Games and Interactive Media \n"}, "13_p239": {"abstract": " The increase of the complexity and advancement in ecolog- ical and environmental sciences encourages scientists across the world to collect data from multiple places, times, and thematic scales to verify their hypotheses. Accumulated over time, such data not only increases in amount, but also in the diversity of the data sources spread around the world. This poses a huge challenge for scientists who have to man- ually search for information. To alleviate such problems, ONEMercury has recently been implemented as part of the DataONE project to serve as a portal for accessing envi- ronmental and observational data across the globe. ONE- Mercury harvests metadata from the data hosted by mul- tiple repositories and makes it searchable. However, har- vested metadata records sometimes are poorly annotated or lacking meaningful keywords, which could affect effective retrieval. Here, we develop algorithms for automatic anno- tation of metadata. We transform the problem into a tag recommendation problem with a controlled tag library, and propose two variants of an algorithm for recommending tags. Our experiments on four datasets of environmental science metadata records not only show great promises on the per- formance of our method, but also shed light on the different natures of the datasets. ", "authors": "Suppawong Tuarob Computer Science and Engineering Pennsylvania State University University Park, Pennsylvania suppawong@psu.edu Line C. Pouchard Scientific Data Group Computer Sciences and Mathematics Division Oak Ridge National Laboratory Oak Ridge, Tennessee pouchardlc@ornl.gov C. Lee Giles Information Sciences and Technology Computer Science and Engineering Pennsylvania State University University Park, Pennsylvania giles@ist.psu.edu ", "categories": " H.3.3 [Information Search and Retrieval] ", "id": "13_p239", "keywords": " Document Annotation, Tag Recommendation, Topic Model ", "title": "Automatic Tag Recommendation for Metadata Annotation Using Probabilistic Topic Modeling\n"}, "13_p249": {"abstract": " Digital libraries are supported by good quality metadata, and thus by the use of good quality metadata tools. The design of metadata tools can be supported by following user-centered design processes. In this paper we discuss the application and evaluation of several cognitively-based rules, derived from the work of Donald Norman, to the design of a metadata tool for administering Dublin Core metadata. One overall finding was that while the use of the rules supported users in their immediate interactions with the tool interface, they provided less support for the more cognitively intensive tasks associated with developing a wider conceptual understanding of the purpose of metadata. The findings have implications for the wider development of tools to support metadata work in digital libraries and allied contexts. ", "authors": "Catherine Hall, Michael Khoo College of Information Science & Technology, Drexel University 3141 Chestnut Street, Philadelphia PA 19104, USA +1 215 895 5912 {ceh48, khoo}@drexel.edu  ", "categories": " H.3.7 [Information Storage and retrieval]: Digital Libraries 每 collection, standards, user issues.  General Terms Management, standardization ", "id": "13_p249", "keywords": " Metadata tools, metadata generation, Dublin Core ", "title": "The User-Centered Development and Testing of a Dublin Core Metadata Tool \n"}, "13_p253": {"abstract": " Manga 每 a Japanese term meaning graphic novel or comic 每 has been globally accepted. In Japan, there are a huge number of monographs and magazines of manga published. The work entity defined in Functional Requirements of Bibliographic Records (FRBR) is useful to identify and find manga. This paper examines how to identify manga works in a set of bibliographic records maintained by Kyoto International Manga Museum. It is known that authority data is useful to identify works from the bibliographic records. However, the authority data of manga is not rich, because manga has been recognized as a sub-culture resource and is generally not included in library collections. In this study, we used DBpedia, which is a large Linked Open Data (LOD) resource created from Wikipedia, to identify FRBR manga entities in bibliographic records. The results of this study show that using LOD resources is a reasonable way to identify works from bibliographic records. It also shows the accuracy and efficiency of work identification depending on the quality of the LOD resources used. ", "authors": "Wenling He Graduate School of Library, Information and Media Studies, University of Tsukuba 1-2 Kasuga, Tsukuba, Ibaraki, 305-0821, Japan benlin@ slis.tsukuba.ac.jp Tetsuya Mihara Graduate School of Library, Information and Media Studies, University of Tsukuba 1-2 Kasuga, Tsukuba, Ibaraki, 305-0821, Japan mihara@ slis.tsukuba.ac.jp  Mitsuharu Nagamori Faculty of Library, Information and Media Science, University of Tsukuba 1-2 Kasuga, Tsukuba, Ibaraki, 305-0821, Japan nagamori@ slis.tsukuba.ac.jp Shigeo Sugimoto Faculty of Library, Information and Media Science, University of Tsukuba 1-2 Kasuga, Tsukuba, Ibaraki, 305-0821, Japan sugimoto@ slis.tsukuba.ac.jp  ", "categories": ": E.0 General ", "id": "13_p253", "keywords": ": Bibliographic Data of comic books, Work sets, FRBRization, Linked Open Data, DBpedia. ", "title": "Identification of Works of Manga Using LOD Resources - An Experimental FRBRization of Bibliographic Data of Comic Books - \n"}, "13_p257": {"abstract": " The web is trapped in the ※perpetual now§, and when users traverse from page to page, they are seeing the state of the web resource (i.e., the page) as it exists at the time of the click and not necessarily at the time when the link was made. Thus, a temporal discrepancy can arise between the resource at the time the page author created a link to it and the time when a reader follows the link. This is especially im- portant in the context of social media: the ease of sharing links in a tweet or Facebook post allows many people to au- thor web content, but the space constraints combined with poor awareness by authors often prevents sufficient context from being generated to determine the intent of the post. If the links are clicked as soon as they are shared, the tem- poral distance between sharing and clicking is so small that there is little to no difference in content. However, not all clicks occur immediately, and a delay of days or even hours can result in reading something other than what the author intended. We introduce the concept of a user＊s temporal intention upon publishing a link in social media. We inves- tigate the features that could be extracted from the post, the linked resource, and the patterns of social dissemination to model this user intention. Finally, we analyze the historical integrity of the shared resources in social media across time. In other words, how much is the knowledge of the author＊s intent beneficial in maintaining the consistency of the story being told through social posts and in enriching the archived content coverage and depth of vulnerable resources? ", "authors": "Hany M. SalahEldeen Old Dominion University Norfolk, VA, USA hany@cs.odu.edu Michael L. Nelson Old Dominion University Norfolk, VA, USA mln@cs.odu.edu ", "categories": " H.3.5 [Online Information Services]: Data sharing General Terms Human Factors, Experimentation, Measurement ", "id": "13_p257", "keywords": " Social Media, Archiving, Temporal User Intention, Model- ing, Memento ", "title": "Reading the Correct History? Modeling Temporal Intention in Resource Sharing\n"}, "13_p267": {"abstract": " As defined by the Memento Framework, TimeMaps are ma- chine-readable lists of time-specific copies 每 called ※memen- tos§ 每 of an archived original resource. In theory, as an archive acquires additional mementos over time, a TimeMap should be monotonically increasing. However, there are rea- sons why the number of mementos in a TimeMap would decrease, for example: archival redaction of some or all of the mementos, archival restructuring, and transient errors on the part of one or more archives. We study TimeMaps for 4,000 original resources over a three month period, note their change patterns, and develop a caching algorithm for TimeMaps suitable for a reverse proxy in front of a Memento aggregator. We show that TimeMap cardinality is constant or monotonically increasing for 80.2% of all TimeMap down- loads observed in the observation period. The goal of the caching algorithm is to exploit the ideally monotonically in- creasing nature of TimeMaps and not cache responses with fewer mementos than the already cached TimeMap. This new caching algorithm uses conditional cache replacement and a Time To Live (TTL) value to ensure the user has access to the most complete TimeMap available. Based on our empirical data, a TTL of 15 days will minimize the num- ber of mementos missed by users, and minimize the load on archives contributing to TimeMaps. ", "authors": "Justin F. Brunelle Old Dominion University Department of Computer Science Norfolk, Virginia, 23508 jbrunelle@cs.odu.edu Michael L. Nelson Old Dominion University Department of Computer Science Norfolk, Virginia, 23508 mln@cs.odu.edu ", "categories": " H.3.7 [Online Information Services]: Digital Libraries General Terms Design, Experimentation ", "id": "13_p267", "keywords": " Web Architecture, HTTP, Web Archiving, Digital Preserva- tion, Memento, TimeMaps ", "title": "An Evaluation of Caching Policies for Memento TimeMaps\n"}, "13_p277": {"abstract": " The documents used in the ResourceSync synchronization framework are based on the widely adopted document for- mat defined by the Sitemap protocol. In order to address requirements of the framework, extensions to the Sitemap format were necessary. This short paper describes the con- cerns we had about introducing such extensions, the tests we did to evaluate their validity, and aspects of the framework to address them. ", "authors": "Martin Klein Los Alamos National Laboratory NM, USA mklein@lanl.gov Herbert Van de Sompel Los Alamos National Laboratory NM, USA herbertv@lanl.gov ", "categories": " H.3.5 [Information Storage and Retrieval]: Online In- formation Science〞Data Sharing ", "id": "13_p277", "keywords": " Sitemaps, Resource Synchronization, ResourceSync ", "title": "Extending Sitemaps for ResourceSync\n"}, "13_p281": {"abstract": " We present a multimodal system for aligning scholarly docu- ments to corresponding presentations in a fine-grained man- ner (i.e., per presentation slide and per paper section). Our method improves upon a state-of-the-art baseline that em- ploys only textual similarity. Based on an analysis of base- line errors, we propose a three-pronged alignment system that combines textual, image, and ordering information to establish alignment. Our results show a statistically sig- nificant improvement of 25%, confirming the importance of visual content in improving alignment accuracy. ", "authors": "Bamdad Bahrani Department of Computer Science National University of Singapore bamdad.bahrani@nus.edu.sg Min-Yen Kan1,2 1Department of Computer Science 2NUS Interactive and Digital Media Institute National University of Singapore kanmy@comp.nus.edu.sg ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.7 [Information Storage and Retrieval]: Digital Libraries ", "id": "13_p281", "keywords": " Digital library, fine-grained document alignment, slide pre- sentation, slide image classification ", "title": "Multimodal Alignment of Scholarly Documents and Their Presentations\n"}, "13_p285": {"abstract": " Large amounts of multivariate data are collected in different areas of scientific research and industrial production. These data are collected, archived and made publicly available by research data repositories. In addition to meta-data based access, content-based approaches are highly desirable to effectively retrieve, discover and analyze data sets of interest. Several such methods, that allow users to search for particular curve progressions, have been proposed. However, a major challenge when providing content-based access -- interactive feedback during query formulation -- has not received much attention yet. This is important because it can substantially improve the user's search effectiveness. In this paper, we present a novel interactive feedback approach for content-based access to multivariate research data. Thereby, we enable query modalities that were not available for multivariate data before. We provide instant search results and highlight query patterns in the result set. Real-time search suggestions give an overview of important patterns to look for in the data repository. For this purpose, we develop a bag-of-words index for multivariate data as the back-end of our approach. We apply our method to a large repository of multivariate data from the climate research domain. We describe a use-case for the discovery of interesting patterns in maritime climate research using our new visual-interactive query tools.  ", "authors": " Maximilian Scherer \tTU Darmstadt, Darmstadt, Germany Tatiana von Landesberger \tTU Darmstadt, Darmstadt, Germany Tobias Schreck \tUniversity of Konstanz, Konstanz, Germany ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Libraries collection, dissemination, standards; H.3.1 [Information Storage and Retrieval]: Context Analysis and sIndexing-indexing methods ", "id": "13_p285", "keywords": " Research data repositories; content-based retrieval; bag-of-words; Query Interfaces; Multivariate data ", "title": "Visual-interactive querying for multivariate research data repositories using bag-of-words\n"}, "13_p295": {"abstract": " Field archaeology only recently developed centralized systems for data curation, management, and reuse. Data documentation guidelines, standards, and ontologies have yet to see wide adoption in this discipline. Moreover, repository practices have focused on supporting data collection, deposit, discovery, and access more than data reuse. In this paper we examine the needs of archaeological data reusers, particularly the context they need to understand, verify, and trust data others collect during field studies. We then apply our findings to the existing work on standards development. We find that archaeologists place the most importance on data collection procedures, but the reputation and scholarly affiliation of the archaeologists who conducted the original field studies, the wording and structure of the documentation created during field work, and the repository where the data are housed also inform reuse. While guidelines, standards, and ontologies address some aspects of the context data reusers need, they provide less guidance on others, especially those related to research design. We argue repositories need to address these missing dimensions of context to better support data reuse in archaeology. ", "authors": "Ixchel Faniel1, Eric Kansa2, Sarah Whitcher Kansa3, Julianna Barrera-Gomez1, and Elizabeth Yakel4 1 OCLC Research 2 University of California Berkeley, School of Information 3 The Alexandria Archive Institute 4 University of Michigan, School of Information  fanieli@oclc.org, ekansa@ischool.berkeley.edu, skansa@alexandriaarchive.org, barreraj@oclc.org, yakel@umich.edu  ", "categories": " H.3.5[Online Info Services]: Data Sharing, Web-based Services; H.3.7[Digital Libraries]: Dissemination, Standards, User Issues  ", "id": "13_p295", "keywords": " Archaeology, Data management, Data reuse, Data standards  ", "title": "The Challenges of Digging Data: A Study of Context in Archaeological Data Reuse\n"}, "13_p305": {"abstract": " Personal digital photo libraries embody a large amount of in- formation useful for research into photo organization, photo layout, and development of novel photo browser features. Even when anonymity can be ensured, amassing a sizable dataset from these libraries is still difficult due to the visi- bility and cost that would be required from such a study. We explore using the Mac App Store to reach more users to collect data from such personal digital photo libraries. More specifically, we compare and discuss how it differs from common data collection methods, e.g. Amazon Mechanical Turk, in terms of time, cost, quantity, and design of the data collection application. We have collected a large, openly available photo feature dataset using this manner. We illustrate the types of data that can be collected. In 60 days, we collected data from 20,778 photo sets (473,772 photos). Our study with the Mac App Store suggests that popular application distribu- tion channels is a viable means to acquire massive data col- lections for researchers. ", "authors": "Jesse Prabawa Gozali1,2? Min-Yen Kan1,2 Hari Sundaram3 1Department of Computer Science, National University of Singapore, Singapore 2NUS Interactive and Digital Media Institute, Singapore 3Arts Media & Engineering, Arizona State University, USA {jprabawa, kanmy}@comp.nus.edu.sg hari.sundaram@asu.edu ", "categories": " H.5.2 [Information Interfaces and Presentation]: User Interfaces General Terms Measurement, Human Factors ", "id": "13_p305", "keywords": " Personal digital library, Photography, Data collection, Ground truth, Crowd-sourcing ?This research is supported by the Singapore National Re- search Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. ", "title": "Constructing an Anonymous Dataset From the Personal Digital Photo Libraries of Mac App Store Users\n"}, "13_p309": {"abstract": " Digital repositories are grappling with an influx of scientific data brought about by the well publicized ※data deluge§ in science, business, and society. One particularly perplexing problem is the long-term archival and reuse of complex data sets. This paper presents an integrated approach to data discovery over heterogeneous data resources in social-ecological systems research. Social-ecological systems data is complex because the research draws from both social and natural sciences. Using a sample set of data resources from the domain, we explore an approach to discovery and representation of this data.  Specifically, we develop an ontology-based process of organization and visualization from a data-centric perspective. We define data resources broadly and identify six key categories of resources that include data collected from site visits to shared ecological resources, the structure of research instruments, domain concepts, research designs, publications, theories and models. We identify the underlying relationships and construct an ontology that captures these relationships using semantic web languages. The ontology and a NoSQL data store at the back end store the data resource instances. These are integrated into a portal architecture we refer to as the Integrated Visualization of Social-Ecological Resources (IViSER) that allows users to both browse the relationships captured in the ontology and easily visualize the granular details of data resources. ", "authors": "Miao Chen, Umashanthi Pavalanathan, Scott Jensen, Beth Plale School of Informatics and Computing Indiana University Bloomington, Indiana U.S.A {miaochen, umapaval, scjensen, plale}@indiana.edu ", "categories": " H.3.5 [Information Storage and Retrieval]: Online Information Services 每 data sharing. ", "id": "13_p309", "keywords": " Scientific Data, Ontology, Semantic Web, NoSQL Data Store. ", "title": "Modeling Heterogeneous Data Resources for Social-Ecological Research: A Data-Centric Perspective \n"}, "13_p313": {"abstract": " Mainstream approaches in the design of virtual libraries basically exploit the same ambient space as their physical twins. Our paper is an attempt to rather capture automati- cally the actual space on which the books live, and learn the virtual library as a non-linear book manifold. This tackles tantalizing questions, chief among which whether modeling should be static and book focused (e.g. using bag of words encoding) or dynamic and user focused (e.g. relying on what we define as a bag of readers encoding). Experiments on a real-world digital library display that the latter encod- ing is a serious challenger to the former. Our results also show that the geometric layers of the manifold learned bring sizeable advantages for retrieval and visualization purposes. For example, the topological layer of the manifold allows to craft Manifold association rules; experiments display that they bring dramatic improvements over conventional asso- ciation rules built from the discrete topology of book sets. Improvements embrace each of the following major stand- points on association rule mining: computational, support, confidence, lift, and leverage standpoint. ", "authors": "Richard Nock CEREGMIA 〞 Univ. Antilles-Guyane 97259 Schoelcher, France rnock@martinique.univ-ag.fr Frank Nielsen Sony Computer Science Laboratories, Inc. Tokyo 141-0022, Japan nielsen@csl.sony.co.jp Eric Briys CEREGMIA 〞 Univ. Antilles-Guyane 97259 Schoelcher, France eric.b@cyberlibris.com ", "categories": " H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval〞retrieval models ", "id": "13_p313", "keywords": " Non-linear manifold learning; Pattern mining; Visualization ", "title": "Non-Linear Book Manifolds: Learning from Associations the Dynamic Geometry of Digital Libraries\n"}, "13_p323": {"abstract": " Chinese calligraphy is the art of handwriting and is an important part of Chinese traditional culture. But due to the complexity of shape and styles of calligraphic characters, it is difficult for com- mon people to recognize them. So it would be great if a tool is provided to help users to recognize the unknown calligraphic characters. But the well-known OCR (Optical Character Recogni- tion) technology can hardly help people to recognize the unknown characters because of their deformation and complexity. Numer- ous collections of historical Chinese calligraphic works are digit- ized and stored in CADAL (China Academic Digital Associate Library) calligraphic system [1], and a huge database CCD (Calli- graphic Character Dictionary) is built, which contains character images labeled with semantic meaning. In this paper, a LSH- based large scale Chinese calligraphic character recognition method is proposed basing on CCD. In our method, GIST de- scriptor is used to represent the global features of the calligraphic character images, LSH (Locality-sensitive hashing) is used to search CCD to find the similar character images to the recognized calligraphic character image. The recognition is based on the se- mantic probability which is computed according to the ranks of retrieved images and their distances to the recognized image in the Gist feature space. Our experiments show that our method is ef- fective and efficient for recognizing Chinese calligraphic charac- ter image. ", "authors": "Yuan Lin College of Computer Science Zhejiang University Hangzhou, China lin_yuan@zju.edu.cn Jiangqin Wu*       College of Computer Science Zhejiang University Hangzhou, China wujq@zju.edu.cn  Pengcheng Gao    College of Computer Science Zhejiang University Hangzhou, China gaopeng- cheng@zju.edu.cn Yang Xia          College of Computer Sci- ence Zhejiang University Hangzhou, China 21121255@zju.edu.cn Tianjiao Mao      College of Com- puter Science Zhejiang University Hangzhou, China 21121260@zju.edu .cn ", "categories": " J.5 [Computer Application]: Arts and Humanities 每 Arts and Humanities General Terms: Algorithms, Experimentation, Performance ", "id": "13_p323", "keywords": " Calligraphy, LSH-based Search, Character Recognition ", "title": "LSH-Based Large Scale Chinese Calligraphic Character Recognition \n"}, "13_p331": {"abstract": " Geometric distortions are among the major challenging issues in the analysis of historical document images. Such distortions appear as arbitrary warping, folds and page curl, and have detrimental effects upon recognition (OCR) and readability. While there are many dewarping techniques discussed in the literature, there exists no standard method by which their performance can be evaluated against each other. In particular, there is not any satisfactory method capable of comparing the results of existing dewarping techniques on arbitrary wrapped documents. The existing methods either rely on the visual comparison of the output and input images or depend on the recognition rate of an OCR system. In the case of historical documents, OCR either is not available or does not generate an acceptable result. In this paper, an objective and automatic evaluation methodology for document image dewarping technique is presented. In the first step, all the baselines in the original distorted image as well as dewarped image are modelled precisely and automatically. Then based on the mathematical function of each line, a comprehensive metric which calculates the performance of a dewarping technique is introduced. The presented method does not require user interference in any stage of evaluation and therefore is quite objective. Experimental results, applied to two state-of-the art dewarping methods and an industry-standard commercial system, demonstrate the effectiveness of the proposed dewarping evaluation method.  ", "authors": "Maryam Rahnemoonfar, Beth Plale  School of Informatics and Computing, Indiana University maryrahn@indiana.edu ", "categories": " H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness); I.4.1 [Digitization and Image Capture]: Imaging geometry; I.4.3 [Enhancement]: Geometric correction   ", "id": "13_p331", "keywords": " Performance Evaluation, Arbitrary Warping, Large Scale Digitization   ", "title": "Automatic Performance Evaluation of Dewarping Methods in Large Scale Digitization of Historical Documents \n"}, "13_p335": {"abstract": " Early maps are a valuable resource for historical research, this is why digital libraries for early maps become a nec- essary tool for research support in the age of information. In this article we introduce the Referencing and Annotation Tool (RAT), designed to extract information about all places displayed in a map and link them to a place on a modern map. RAT automatically recognizes place markers in an early map according to a template specified by the user and estimates the position of the annotated place in the modern map, thus making georeferencing easier. After a brief sum- mary on related projects, we describe the functionality of the system. We discuss the most important implementation details and factors influencing recognition accuracy and per- formance. The advantages of our semiautomatic approach are high accuracy and a significant decrease of the user＊s cognitive load. ", "authors": "Winfried H?hn Dept. of Computer Science University of W邦rzburg, Germany winfried.hoehn@ informatik.uni-wuerzburg.de Dr. Hans-G邦nter Schmidt Dept. of Manuscripts and Early Printed Collections University Library of W邦rzburg, Germany hans-guenter.schmidt@ bibliothek.uni-wuerzburg.de Hendrik Sch?neberg Dept. of Computer Science University of W邦rzburg, Germany schoeneberg@ informatik.uni-wuerzburg.de ", "categories": " H.3.7 [Information Storage and Retrieval]: Digital Li- braries; H.3.1 [Information Storage and Retrieval]: Con- tent Analysis and Indexing; I.4.6 [Image Processing and Computer Vision]: Segmentation; I.7.5 [Image Process- ing and Computer Vision]: Document Capture〞Docu- ment analysis ", "id": "13_p335", "keywords": " Annotation; early maps; georeferencing; linked data ", "title": "Semiautomatic Recognition and Georeferencing of Places in Early Maps\n"}, "13_p339": {"abstract": " Although user access patterns on the live web are well- understood, there has been no corresponding study of how users, both humans and robots, access web archives. Based on samples from the Internet Archive＊s public Wayback Ma- chine, we propose a set of basic usage patterns: Dip (a sin- gle access), Slide (the same page at different archive times), Dive (different pages at approximately the same archive time), and Skim (lists of what pages are archived, i.e., Time- Maps). Robots are limited almost exclusively to Dips and Skims, but human accesses are more varied between all four types. Robots outnumber humans 10:1 in terms of sessions, 5:4 in terms of raw HTTP accesses, and 4:1 in terms of megabytes transferred. Robots almost always access Time- Maps (95% of accesses), but humans predominately access the archived web pages themselves (82% of accesses). In terms of unique archived web pages, there is no overall pref- erence for a particular time, but the recent past (within the last year) shows significant repeat accesses. ", "authors": "Yasmin AlNoamany, Michele C. Weigle, Michael L. Nelson Old Dominion University Norfolk, VA, USA {yasmin, mweigle, mln}@cs.odu.edu ", "categories": " H.3.7 [Digital Libraries]: Web Archives〞Retrieval models ", "id": "13_p339", "keywords": " Web Archiving, Web Server Logs, Web Usage Mining, User Access Patterns, Web Robot Detection ", "title": "Access Patterns for Robots and Humans in Web Archives\n"}, "13_p349": {"abstract": " Digital preservation is an active area of research, and re- cent years have brought forward an increasing number of characterisation tools for the object-level analysis of digi- tal content. However, there is a profound lack of objective, standardised and comparable metrics and benchmark col- lections to enable experimentation and validation of these tools. While fields such as Information Retrieval have for decades been able to rely on benchmark collections anno- tated with ground truth to enable systematic improvement of algorithms and systems along objective metrics, the digi- tal preservation field is yet unable to provide the necessary ground truth for such benchmarks. Objective indicators, however, are the key enabler for quantitative experimenta- tion and innovation. This paper presents a systematic model-driven benchmark generation framework that aims to provide realistic approx- imations of real-world digital information collections with fully known ground truth that enables systematic quantita- tive experimentation, measurement and improvement against objective indicators. We describe the key motivation and idea behind the framework, outline the technological build- ing blocks, and discuss results of the generation of page- based and hierarchical documents from a ground truth model. Based on a discussion of the benefits and challenges of the approach, we outline future work. ", "authors": "Christoph Becker Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/?becker Kresimir Duretec Vienna University of Technology Vienna, Austria www.ifs.tuwien.ac.at/?duretec ", "categories": " H.3 [Information Storage and Retrieval]: H.3.7 Digital Libraries ", "id": "13_p349", "keywords": " Repositories; Digital Preservation; Characterisation; Bench- mark; Data Set; Ground Truth; Corpora; Model Driven En- gineering General Terms Algorithms, Experimentation, Measurement, Performance ", "title": "Free Benchmark Corpora for Preservation Experiments: Using Model-Driven Engineering to Generate Data Sets\n"}, "13_p359": {"abstract": " Creating digital representations of ancient manuscripts, prints and maps is a challenging task due to the sources＊ fragile and heterogeneous natures. Digitization requires a very special- ized set of scanning hardware in order to cover the sources＊ diversity. The central task is obtaining the maximum re- production quality while minimizing the error rate, which is difficult to achieve due to the large amounts of image data re- sulting from digitization, putting huge computational loads on image processing modules, error-detection and informa- tion retrieval heuristics. As digital copies initially do not contain any information about their sources＊ semantics, additional efforts have to be made to extract semantic metadata. This is an error-prone, time-consuming manual process, which calls for automated mechanisms to support the user. This paper introduces a decentralized, event-driven work- flow system designed to overcome the above mentioned chal- lenges. It leverages dynamic routing between workflow com- ponents, thus being able to quickly adapt to the sources＊ unique requirements. It provides a scalable approach to soften out high computational loads on single units by using distributed computing and provides modules for automated image pre- / post-processing, error-detection heuristics, data mining, semantic analysis, metadata augmentation, quality assurance and an export functionality to established pub- lishing platforms or long-term storage facilites. ", "authors": "Hendrik Sch?neberg Dept. of Computer Science University of W邦rzburg, Germany schoeneberg@ informatik.uni-wuerzburg.de Dr. Hans-G邦nter Schmidt Department of Manuscripts and Early Printed Collections University Library of W邦rzburg, Germany hans-guenter.schmidt@ bibliothek.uni-wuerzburg.de Winfried H?hn Dept. of Computer Science University of W邦rzburg, Germany winfried.hoehn@ informatik.uni-wuerzburg.de ", "categories": " H.4.1 [Information Systems Applications]: Office Au- tomation〞workflow management ; H.3.7 [Information Stor- age and Retrieval]: Digital Libraries〞collection, dissem- ination, standards; H.3.1 [Information Storage and Re- trieval]: Context Analysis and Indexing〞linguistic process- ing ; H.3.4 [Information Storage and Retrieval]: Sys- tems and Software〞distributed systems; D.1.3 [Programm- ing Techniques]: Concurrent Programming〞distributed programming, parallel programming ", "id": "13_p359", "keywords": " Akka; data mining; digitization; digital library; distributed; dynamic computing; event-driven design; fault-tolerance; in- formation retrieval; metadata extraction; workflow ", "title": "A Scalable, Distributed and Dynamic Workflow System for Digitization Processes\n"}, "13_p363": {"abstract": " The use of map-based browser services is of great relevance in numerous digital libraries. The implementation of such services, however, demands the use of geocoded data collec- tions. This paper investigates the use of image content local representations in geocoding tasks. Performed experiments demonstrate that some of the evaluated descriptors yield ef- fective results in the task of geocoding VT building photos. This study is the first step to geocode multimedia material related to the VT April 16, 2007 school shooting tragedy. ", "authors": "Lin Tzy Li1,2, Ot芍vio A. B. Penatti1, Edward A. Fox3 and Ricardo da S. Torres1 1RECOD Lab, Institute of Computing, University of Campinas (UNICAMP), Campinas, SP 每 Brazil, 13083-852 2Telecommunications Res. & Dev. Center, CPqD Foundation, Campinas, SP 每 Brazil, 13086-902 3Digital Library Research Laboratory, Department of Computer Science, Virginia Tech, Blacksburg, VA 24061 {lintzyli, penatti, rtorres}@ic.unicamp.br, fox@vt.edu ", "categories": " H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; I.2.10 [Artificial Intelligence]: Vi- sion and Scene Understanding ", "id": "13_p363", "keywords": " geocoding; map-based browsing; content-based video retrieval ", "title": "Domain-specific Image Geocoding: a Case Study on Virginia Tech Building Photos\n"}};
	readArticlesJSON(articles_data);
}